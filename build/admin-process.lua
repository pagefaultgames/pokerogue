-- Bundled Lua file for AO Environment
-- Generated by custom-lua-bundler.sh
-- Entry point: ao-processes/admin/main.lua
-- Bundle timestamp: Fri Sep  5 17:51:28 EDT 2025

-- JSON require (allowed in AO environment)
local json = require('json')

-- Admin Process Main Entry Point
-- Administrative and monitoring process with elevated privileges for distributed system management

-- JSON handling for AO environment
local json = {}
local success, jsonModule = pcall(require, 'json')
if success then
    json = jsonModule
else
    -- Simple JSON implementation for AO environment
    json = {
        encode = function(obj)
            if type(obj) == "string" then
                return '"' .. obj:gsub('"', '\\"') .. '"'
            elseif type(obj) == "number" then
                return tostring(obj)
            elseif type(obj) == "boolean" then
                return obj and "true" or "false"
            elseif obj == nil then
                return "null"
            elseif type(obj) == "table" then
                local isArray = true
                local maxIndex = 0
                for k, v in pairs(obj) do
                    if type(k) ~= "number" then
                        isArray = false
                        break
                    end
                    maxIndex = math.max(maxIndex, k)
                end
                
                if isArray then
                    local result = "["
                    for i = 1, maxIndex do
                        if i > 1 then result = result .. "," end
                        result = result .. json.encode(obj[i])
                    end
                    return result .. "]"
                else
                    local result = "{"
                    local first = true
                    for k, v in pairs(obj) do
                        if not first then result = result .. "," end
                        result = result .. json.encode(tostring(k)) .. ":" .. json.encode(v)
                        first = false
                    end
                    return result .. "}"
                end
            else
                return "null"
            end
        end,
        decode = function(str)
            return {}
        end
    }
end

-- Load process coordination components from foundation

-- ===== MODULE: game-logic.process-coordination.message-correlator =====
-- File: ao-processes/game-logic/process-coordination/message-correlator.lua
-- Original require: local MessageCorrelator = require("game-logic.process-coordination.message-correlator")

-- Message Correlation System for Inter-Process Communication
-- Provides unique correlation ID generation and tracking across message chains


-- ===== MODULE: game-logic.rng.crypto-rng =====
-- File: ao-processes/game-logic/rng/crypto-rng.lua
-- Original require: local CryptoRNG = require("game-logic.rng.crypto-rng")

-- Cryptographically secure RNG wrapper for AO processes
-- Replaces non-deterministic math.random() with seedable crypto-based randomness

local CryptoRNG = {
    -- Battle RNG state for deterministic battles
    battleSeed = nil,
    battleCounter = 0,
    
    -- General RNG state for non-battle operations
    globalSeed = nil,
    globalCounter = 0
}

-- Initialize battle RNG with a specific seed for deterministic battles
function CryptoRNG.initBattleRNG(seed)
    if not seed or type(seed) ~= "string" then
        error("Battle RNG seed must be a string")
    end
    CryptoRNG.battleSeed = seed
    CryptoRNG.battleCounter = 0
end

-- Initialize global RNG with a seed (or generate one from ao.crypto)
function CryptoRNG.initGlobalRNG(seed, timestamp)
    if seed then
        CryptoRNG.globalSeed = seed
    else
        -- Use AO crypto to generate a random seed (with fallback for testing)
        if ao and ao.crypto and ao.crypto.cipher then
            CryptoRNG.globalSeed = ao.crypto.cipher.issuer()
        else
            -- Fallback for testing environment - use current time
            CryptoRNG.globalSeed = tostring(timestamp or 0)
        end
    end
    CryptoRNG.globalCounter = 0
end

-- Get deterministic random integer in battle context
function CryptoRNG.battleRandomInt(min, max)
    if not CryptoRNG.battleSeed then
        error("Battle RNG not initialized - call CryptoRNG.initBattleRNG(seed) first")
    end
    
    -- Increment counter for deterministic sequence
    CryptoRNG.battleCounter = CryptoRNG.battleCounter + 1
    
    -- Create deterministic input combining seed and counter
    local input = CryptoRNG.battleSeed .. ":" .. tostring(CryptoRNG.battleCounter)
    
    -- Use AO crypto to generate deterministic hash (with fallback)
    local hash
    if ao and ao.crypto and ao.crypto.utils then
        hash = ao.crypto.utils.hash(input)
    else
        -- Fallback hash function for testing using simple string hashing
        local hashNum = 0
        for i = 1, #input do
            hashNum = hashNum + string.byte(input, i) * (i * 31)
        end
        hash = tostring(math.abs(hashNum))
    end
    
    -- Convert hash to number and normalize to range
    local num = 0
    for i = 1, math.min(8, #hash) do
        num = num + string.byte(hash, i) * (256 ^ (i - 1))
    end
    
    -- Normalize to requested range
    if min and max then
        return min + (num % (max - min + 1))
    else
        return num % 100 + 1  -- Default 1-100 range
    end
end

-- Get random number in battle context (0-1 float)
function CryptoRNG.battleRandom()
    local randomInt = CryptoRNG.battleRandomInt(0, 999999)
    return randomInt / 999999
end

-- Get random integer in global context
function CryptoRNG.globalRandomInt(min, max)
    if not CryptoRNG.globalSeed then
        CryptoRNG.initGlobalRNG()
    end
    
    CryptoRNG.globalCounter = CryptoRNG.globalCounter + 1
    
    -- Create deterministic input
    local input = CryptoRNG.globalSeed .. ":" .. tostring(CryptoRNG.globalCounter)
    
    -- Use AO crypto for randomness (with fallback)
    local hash
    if ao and ao.crypto and ao.crypto.utils then
        hash = ao.crypto.utils.hash(input)
    else
        -- Fallback hash function for testing using simple string hashing
        local hashNum = 0
        for i = 1, #input do
            hashNum = hashNum + string.byte(input, i) * (i * 37)
        end
        hash = tostring(math.abs(hashNum))
    end
    
    -- Convert to number
    local num = 0
    for i = 1, math.min(8, #hash) do
        num = num + string.byte(hash, i) * (256 ^ (i - 1))
    end
    
    -- Normalize to range
    if min and max then
        return min + (num % (max - min + 1))
    else
        return num % 100 + 1
    end
end

-- Get random float in global context (0-1)
function CryptoRNG.globalRandom()
    local randomInt = CryptoRNG.globalRandomInt(0, 999999)
    return randomInt / 999999
end

-- Compatibility functions that match math.random() interface
function CryptoRNG.random(...)
    local args = {...}
    local argCount = #args
    
    if argCount == 0 then
        -- math.random() -> 0-1 float
        return CryptoRNG.globalRandom()
    elseif argCount == 1 then
        -- math.random(n) -> 1 to n
        return CryptoRNG.globalRandomInt(1, args[1])
    elseif argCount == 2 then
        -- math.random(m, n) -> m to n
        return CryptoRNG.globalRandomInt(args[1], args[2])
    else
        error("Invalid number of arguments to CryptoRNG.random()")
    end
end

-- Battle-specific random that follows the same interface
function CryptoRNG.battleRandomCompat(...)
    local args = {...}
    local argCount = #args
    
    if argCount == 0 then
        return CryptoRNG.battleRandom()
    elseif argCount == 1 then
        return CryptoRNG.battleRandomInt(1, args[1])
    elseif argCount == 2 then
        return CryptoRNG.battleRandomInt(args[1], args[2])
    else
        error("Invalid number of arguments to CryptoRNG.battleRandomCompat()")
    end
end

-- Reset battle RNG state (for new battles)
function CryptoRNG.resetBattleRNG()
    CryptoRNG.battleSeed = nil
    CryptoRNG.battleCounter = 0
end

-- Get current battle RNG state for debugging
function CryptoRNG.getBattleState()
    return {
        seed = CryptoRNG.battleSeed,
        counter = CryptoRNG.battleCounter
    }
end


-- ===== END MODULE: game-logic.rng.crypto-rng =====


local MessageCorrelator = {
    -- Correlation tracking storage
    activeCorrelations = {},
    correlationHistory = {},
    maxHistorySize = 10000
}

-- Correlation Types
MessageCorrelator.CORRELATION_TYPES = {
    INTER_PROCESS = "INTER_PROCESS",
    INTRA_PROCESS = "INTRA_PROCESS",
    CLIENT_REQUEST = "CLIENT_REQUEST"
}

-- Message Status
MessageCorrelator.MESSAGE_STATUS = {
    PENDING = "PENDING",
    PROCESSING = "PROCESSING", 
    COMPLETED = "COMPLETED",
    FAILED = "FAILED",
    TIMEOUT = "TIMEOUT"
}

-- Initialize the correlation system
function MessageCorrelator.initialize()
    MessageCorrelator.activeCorrelations = {}
    MessageCorrelator.correlationHistory = {}
    CryptoRNG.initGlobalRNG()
    print("[MessageCorrelator] Correlation system initialized")
end

-- Generate unique correlation ID using AO crypto module
function MessageCorrelator.generateCorrelationId(correlationType, timestamp)
    local currentTimestamp = timestamp or (msg and msg.Timestamp) or 0
    local baseTimestamp = currentTimestamp + CryptoRNG.random(0, 999)
    local randomSuffix = CryptoRNG.random(100000, 999999)
    local prefix = correlationType == MessageCorrelator.CORRELATION_TYPES.INTER_PROCESS and "ipc" or "cor"
    
    return prefix .. "_" .. baseTimestamp .. "_" .. randomSuffix
end

-- Create new correlation with full metadata
function MessageCorrelator.createCorrelation(originProcessId, targetProcessId, messageType, parentCorrelationId, timestamp)
    local correlationId = MessageCorrelator.generateCorrelationId(MessageCorrelator.CORRELATION_TYPES.INTER_PROCESS, timestamp)
    local currentTimestamp = timestamp or 0
    
    local correlation = {
        id = correlationId,
        parent = parentCorrelationId,
        origin = originProcessId,
        target = targetProcessId,
        messageType = messageType,
        status = MessageCorrelator.MESSAGE_STATUS.PENDING,
        created = currentTimestamp,
        lastUpdated = currentTimestamp,
        chain = {}
    }
    
    -- Add to parent chain if this is a nested operation
    if parentCorrelationId and MessageCorrelator.activeCorrelations[parentCorrelationId] then
        table.insert(MessageCorrelator.activeCorrelations[parentCorrelationId].chain, correlationId)
        correlation.depth = (MessageCorrelator.activeCorrelations[parentCorrelationId].depth or 0) + 1
    else
        correlation.depth = 0
    end
    
    MessageCorrelator.activeCorrelations[correlationId] = correlation
    
    return correlationId
end

-- Update correlation status
function MessageCorrelator.updateCorrelationStatus(correlationId, status, errorMessage, timestamp)
    local correlation = MessageCorrelator.activeCorrelations[correlationId]
    if not correlation then
        return false, "Correlation not found: " .. tostring(correlationId)
    end
    
    correlation.status = status
    correlation.lastUpdated = timestamp or 0
    
    if errorMessage then
        correlation.error = errorMessage
    end
    
    -- Move to history if completed or failed
    if status == MessageCorrelator.MESSAGE_STATUS.COMPLETED or 
       status == MessageCorrelator.MESSAGE_STATUS.FAILED or 
       status == MessageCorrelator.MESSAGE_STATUS.TIMEOUT then
        MessageCorrelator.moveToHistory(correlationId)
    end
    
    return true
end

-- Get correlation metadata
function MessageCorrelator.getCorrelation(correlationId)
    return MessageCorrelator.activeCorrelations[correlationId] or 
           MessageCorrelator.correlationHistory[correlationId]
end

-- Get all active correlations for a process
function MessageCorrelator.getProcessCorrelations(processId)
    local processCorrelations = {}
    
    for correlationId, correlation in pairs(MessageCorrelator.activeCorrelations) do
        if correlation.origin == processId or correlation.target == processId then
            processCorrelations[correlationId] = correlation
        end
    end
    
    return processCorrelations
end

-- Get correlation chain (parent and all children)
function MessageCorrelator.getCorrelationChain(correlationId)
    local correlation = MessageCorrelator.getCorrelation(correlationId)
    if not correlation then
        return nil
    end
    
    local chain = { correlation }
    
    -- Get parent chain
    local parent = correlation.parent
    while parent do
        local parentCorrelation = MessageCorrelator.getCorrelation(parent)
        if parentCorrelation then
            table.insert(chain, 1, parentCorrelation)
            parent = parentCorrelation.parent
        else
            break
        end
    end
    
    -- Get child chain
    local function addChildren(currentId)
        local current = MessageCorrelator.getCorrelation(currentId)
        if current and current.chain then
            for _, childId in ipairs(current.chain) do
                local childCorrelation = MessageCorrelator.getCorrelation(childId)
                if childCorrelation then
                    table.insert(chain, childCorrelation)
                    addChildren(childId)
                end
            end
        end
    end
    
    addChildren(correlationId)
    
    return chain
end

-- Move correlation to history and cleanup
function MessageCorrelator.moveToHistory(correlationId)
    local correlation = MessageCorrelator.activeCorrelations[correlationId]
    if not correlation then
        return false
    end
    
    -- Move to history
    MessageCorrelator.correlationHistory[correlationId] = correlation
    MessageCorrelator.activeCorrelations[correlationId] = nil
    
    -- Cleanup old history if at max size
    MessageCorrelator.cleanupHistory()
    
    return true
end

-- Cleanup old correlation history
function MessageCorrelator.cleanupHistory()
    local historySize = 0
    for _ in pairs(MessageCorrelator.correlationHistory) do
        historySize = historySize + 1
    end
    
    if historySize > MessageCorrelator.maxHistorySize then
        local oldestCorrelations = {}
        for correlationId, correlation in pairs(MessageCorrelator.correlationHistory) do
            table.insert(oldestCorrelations, {id = correlationId, lastUpdated = correlation.lastUpdated})
        end
        
        table.sort(oldestCorrelations, function(a, b) return a.lastUpdated < b.lastUpdated end)
        
        -- Remove oldest 20%
        local removeCount = math.floor(MessageCorrelator.maxHistorySize * 0.2)
        for i = 1, removeCount do
            MessageCorrelator.correlationHistory[oldestCorrelations[i].id] = nil
        end
    end
end

-- Create correlation metadata for message
function MessageCorrelator.createCorrelationMetadata(correlationId, originProcessId, targetProcessId, parentCorrelationId)
    return {
        id = correlationId,
        parent = parentCorrelationId,
        origin = originProcessId,
        target = targetProcessId
    }
end

-- Validate correlation metadata format
function MessageCorrelator.validateCorrelationMetadata(correlationMeta)
    if not correlationMeta or type(correlationMeta) ~= "table" then
        return false, "Correlation metadata must be a table"
    end
    
    if not correlationMeta.id or type(correlationMeta.id) ~= "string" then
        return false, "Correlation ID is required and must be a string"
    end
    
    if not correlationMeta.origin or type(correlationMeta.origin) ~= "string" then
        return false, "Origin process ID is required and must be a string"
    end
    
    if not correlationMeta.target or type(correlationMeta.target) ~= "string" then
        return false, "Target process ID is required and must be a string"
    end
    
    return true
end

-- Get correlation statistics
function MessageCorrelator.getStatistics()
    local activeCount = 0
    local historyCount = 0
    local statusCounts = {}
    
    for _ in pairs(MessageCorrelator.activeCorrelations) do
        activeCount = activeCount + 1
    end
    
    for _ in pairs(MessageCorrelator.correlationHistory) do
        historyCount = historyCount + 1
    end
    
    for _, correlation in pairs(MessageCorrelator.activeCorrelations) do
        statusCounts[correlation.status] = (statusCounts[correlation.status] or 0) + 1
    end
    
    for _, correlation in pairs(MessageCorrelator.correlationHistory) do
        statusCounts[correlation.status] = (statusCounts[correlation.status] or 0) + 1
    end
    
    return {
        activeCorrelations = activeCount,
        historyCorrelations = historyCount,
        totalCorrelations = activeCount + historyCount,
        statusBreakdown = statusCounts,
        maxHistorySize = MessageCorrelator.maxHistorySize
    }
end


-- ===== END MODULE: game-logic.process-coordination.message-correlator =====


-- ===== MODULE: game-logic.process-coordination.process-authenticator =====
-- File: ao-processes/game-logic/process-coordination/process-authenticator.lua
-- Original require: local ProcessAuthenticator = require("game-logic.process-coordination.process-authenticator")

-- Inter-Process Authentication Framework
-- Provides secure process identity validation and token-based authentication


-- ===== MODULE: game-logic.rng.crypto-rng =====
-- File: ao-processes/game-logic/rng/crypto-rng.lua
-- Original require: local CryptoRNG = require("game-logic.rng.crypto-rng")


-- ===== END MODULE: game-logic.rng.crypto-rng =====


local ProcessAuthenticator = {
    -- Process registry storage
    processRegistry = {},
    
    -- Authentication token storage (active tokens)
    activeTokens = {},
    
    -- Token configuration
    tokenExpirationTime = 3600, -- 1 hour in seconds
    maxTokensPerProcess = 5,
    
    -- Process types for capability-based authentication
    PROCESS_TYPES = {
        COORDINATOR = "coordinator",
        BATTLE = "battle", 
        POKEMON = "pokemon",
        SHOP = "shop",
        SECURITY = "security",
        ADMIN = "admin"
    },
    
    -- Authentication levels
    AUTH_LEVELS = {
        NONE = "none",
        BASIC = "basic", 
        ELEVATED = "elevated",
        ADMIN = "admin"
    }
}

-- Initialize the authentication system
function ProcessAuthenticator.initialize()
    ProcessAuthenticator.processRegistry = {}
    ProcessAuthenticator.activeTokens = {}
    CryptoRNG.initGlobalRNG()
    print("[ProcessAuthenticator] Authentication system initialized")
end

-- Register a process with identity validation
function ProcessAuthenticator.registerProcess(processId, processType, walletAddress, capabilities, timestamp)
    if not processId or type(processId) ~= "string" or processId == "" then
        return false, "Process ID is required and must be a non-empty string"
    end
    
    if not processType or not ProcessAuthenticator.PROCESS_TYPES[processType:upper()] then
        return false, "Invalid process type. Must be one of: " .. table.concat(ProcessAuthenticator._getProcessTypeList(), ", ")
    end
    
    if not walletAddress or type(walletAddress) ~= "string" or walletAddress == "" then
        return false, "Wallet address is required for process identity validation"
    end
    
    if not capabilities or type(capabilities) ~= "table" then
        return false, "Capabilities must be provided as a table"
    end
    
    -- Validate wallet address format (basic validation)
    if not ProcessAuthenticator._validateWalletAddress(walletAddress) then
        return false, "Invalid wallet address format"
    end
    
    -- Check if process is already registered
    if ProcessAuthenticator.processRegistry[processId] then
        return false, "Process already registered: " .. processId
    end
    
    local currentTime = timestamp or 0
    local processRecord = {
        id = processId,
        type = processType:lower(),
        walletAddress = walletAddress,
        capabilities = capabilities,
        authLevel = ProcessAuthenticator._determineAuthLevel(processType, capabilities),
        status = "active",
        registeredAt = currentTime,
        lastHeartbeat = currentTime,
        tokenCount = 0
    }
    
    ProcessAuthenticator.processRegistry[processId] = processRecord
    
    print(string.format("[ProcessAuthenticator] Process registered: %s (Type: %s, Auth: %s)", 
          processId, processType, processRecord.authLevel))
    
    return true
end

-- Generate authentication token for a registered process
function ProcessAuthenticator.generateAuthToken(processId, requestingWallet, expirationTime, timestamp)
    local processRecord = ProcessAuthenticator.processRegistry[processId]
    if not processRecord then
        return nil, "Process not registered: " .. tostring(processId)
    end
    
    -- Validate requesting wallet matches registered wallet
    if processRecord.walletAddress ~= requestingWallet then
        return nil, "Wallet address mismatch for process authentication"
    end
    
    if processRecord.status ~= "active" then
        return nil, "Process is not active: " .. processId
    end
    
    -- Check token limit
    if processRecord.tokenCount >= ProcessAuthenticator.maxTokensPerProcess then
        return nil, "Maximum tokens exceeded for process: " .. processId
    end
    
    local tokenExpiration = expirationTime or ProcessAuthenticator.tokenExpirationTime
    local currentTime = timestamp or 0
    
    -- Generate unique token
    local tokenId = ProcessAuthenticator._generateTokenId()
    local tokenSignature = ProcessAuthenticator._generateTokenSignature(processId, tokenId, currentTime)
    
    local token = {
        id = tokenId,
        processId = processId,
        walletAddress = requestingWallet,
        signature = tokenSignature,
        authLevel = processRecord.authLevel,
        capabilities = processRecord.capabilities,
        issuedAt = currentTime,
        expiresAt = currentTime + tokenExpiration,
        status = "active"
    }
    
    ProcessAuthenticator.activeTokens[tokenId] = token
    processRecord.tokenCount = processRecord.tokenCount + 1
    processRecord.lastHeartbeat = currentTime
    
    return {
        tokenId = tokenId,
        signature = tokenSignature,
        expiresAt = token.expiresAt,
        authLevel = token.authLevel
    }
end

-- Validate authentication token and return process context
function ProcessAuthenticator.validateAuthToken(tokenId, signature, timestamp)
    local token = ProcessAuthenticator.activeTokens[tokenId]
    if not token then
        return false, nil, "Invalid token: not found"
    end
    
    if token.status ~= "active" then
        return false, nil, "Token is not active"
    end
    
    if (timestamp or 0) > token.expiresAt then
        ProcessAuthenticator._expireToken(tokenId)
        return false, nil, "Token has expired"
    end
    
    if token.signature ~= signature then
        return false, nil, "Token signature validation failed"
    end
    
    -- Return process authentication context
    local authContext = {
        processId = token.processId,
        walletAddress = token.walletAddress,
        authLevel = token.authLevel,
        capabilities = token.capabilities,
        tokenExpiration = token.expiresAt
    }
    
    return true, authContext, nil
end

-- Revoke authentication token
function ProcessAuthenticator.revokeAuthToken(tokenId, requestingProcessId)
    local token = ProcessAuthenticator.activeTokens[tokenId]
    if not token then
        return false, "Token not found: " .. tostring(tokenId)
    end
    
    -- Only the token owner or admin process can revoke
    if token.processId ~= requestingProcessId then
        local requestingProcess = ProcessAuthenticator.processRegistry[requestingProcessId]
        if not requestingProcess or requestingProcess.authLevel ~= ProcessAuthenticator.AUTH_LEVELS.ADMIN then
            return false, "Insufficient privileges to revoke token"
        end
    end
    
    ProcessAuthenticator._expireToken(tokenId)
    return true
end

-- Validate process-to-process communication authorization
function ProcessAuthenticator.validateProcessAuth(sourceProcessId, targetProcessId, operation, authToken, timestamp)
    -- Validate source process token
    local isValidToken, authContext, tokenError = ProcessAuthenticator.validateAuthToken(authToken.tokenId, authToken.signature, timestamp)
    if not isValidToken then
        return false, "Source process authentication failed: " .. tostring(tokenError)
    end
    
    if authContext.processId ~= sourceProcessId then
        return false, "Token process ID mismatch"
    end
    
    -- Check if target process exists and is active
    local targetProcess = ProcessAuthenticator.processRegistry[targetProcessId]
    if not targetProcess then
        return false, "Target process not registered: " .. targetProcessId
    end
    
    if targetProcess.status ~= "active" then
        return false, "Target process is not active: " .. targetProcessId
    end
    
    -- Validate operation authorization based on capabilities
    if not ProcessAuthenticator._isOperationAuthorized(authContext.capabilities, operation) then
        return false, "Operation not authorized for source process capabilities"
    end
    
    return true
end

-- Update process heartbeat
function ProcessAuthenticator.updateProcessHeartbeat(processId, timestamp)
    local processRecord = ProcessAuthenticator.processRegistry[processId]
    if not processRecord then
        return false, "Process not registered: " .. processId
    end
    
    processRecord.lastHeartbeat = timestamp or 0
    return true
end

-- Get registered process information
function ProcessAuthenticator.getProcessInfo(processId)
    local processRecord = ProcessAuthenticator.processRegistry[processId]
    if not processRecord then
        return nil
    end
    
    return {
        id = processRecord.id,
        type = processRecord.type,
        capabilities = processRecord.capabilities,
        authLevel = processRecord.authLevel,
        status = processRecord.status,
        registeredAt = processRecord.registeredAt,
        lastHeartbeat = processRecord.lastHeartbeat
    }
end

-- List all registered processes
function ProcessAuthenticator.listRegisteredProcesses(filterByType, filterByAuthLevel)
    local processes = {}
    
    for processId, processRecord in pairs(ProcessAuthenticator.processRegistry) do
        local includeProcess = true
        
        if filterByType and processRecord.type ~= filterByType then
            includeProcess = false
        end
        
        if filterByAuthLevel and processRecord.authLevel ~= filterByAuthLevel then
            includeProcess = false
        end
        
        if includeProcess then
            processes[processId] = ProcessAuthenticator.getProcessInfo(processId)
        end
    end
    
    return processes
end

-- Clean up expired tokens and inactive processes
function ProcessAuthenticator.cleanup(timestamp)
    local currentTime = timestamp or 0
    local expiredTokens = 0
    local inactiveProcesses = 0
    
    -- Clean up expired tokens
    for tokenId, token in pairs(ProcessAuthenticator.activeTokens) do
        if currentTime > token.expiresAt then
            ProcessAuthenticator._expireToken(tokenId)
            expiredTokens = expiredTokens + 1
        end
    end
    
    -- Mark processes inactive if no heartbeat for too long (2x token expiration)
    local inactiveThreshold = ProcessAuthenticator.tokenExpirationTime * 2
    for processId, processRecord in pairs(ProcessAuthenticator.processRegistry) do
        if processRecord.status == "active" and 
           (currentTime - processRecord.lastHeartbeat) > inactiveThreshold then
            processRecord.status = "inactive"
            inactiveProcesses = inactiveProcesses + 1
        end
    end
    
    return {
        expiredTokens = expiredTokens,
        inactiveProcesses = inactiveProcesses
    }
end

-- Get authentication statistics
function ProcessAuthenticator.getStatistics()
    local registeredProcesses = 0
    local activeProcesses = 0
    local activeTokens = 0
    local processTypes = {}
    local authLevels = {}
    
    for _, processRecord in pairs(ProcessAuthenticator.processRegistry) do
        registeredProcesses = registeredProcesses + 1
        if processRecord.status == "active" then
            activeProcesses = activeProcesses + 1
        end
        
        processTypes[processRecord.type] = (processTypes[processRecord.type] or 0) + 1
        authLevels[processRecord.authLevel] = (authLevels[processRecord.authLevel] or 0) + 1
    end
    
    for _ in pairs(ProcessAuthenticator.activeTokens) do
        activeTokens = activeTokens + 1
    end
    
    return {
        registeredProcesses = registeredProcesses,
        activeProcesses = activeProcesses,
        inactiveProcesses = registeredProcesses - activeProcesses,
        activeTokens = activeTokens,
        maxTokensPerProcess = ProcessAuthenticator.maxTokensPerProcess,
        tokenExpirationTime = ProcessAuthenticator.tokenExpirationTime,
        processTypeBreakdown = processTypes,
        authLevelBreakdown = authLevels
    }
end

-- Private helper functions

function ProcessAuthenticator._validateWalletAddress(walletAddress)
    -- Basic validation: should be 43 characters and alphanumeric with specific chars
    if type(walletAddress) ~= "string" or #walletAddress ~= 43 then
        return false
    end
    
    -- Check for valid Arweave wallet address pattern (Base64URL)
    return string.match(walletAddress, "^[A-Za-z0-9_%-]+$") ~= nil
end

function ProcessAuthenticator._determineAuthLevel(processType, capabilities)
    local normalizedType = processType:lower()
    
    if normalizedType == ProcessAuthenticator.PROCESS_TYPES.ADMIN then
        return ProcessAuthenticator.AUTH_LEVELS.ADMIN
    elseif normalizedType == ProcessAuthenticator.PROCESS_TYPES.SECURITY or
           normalizedType == ProcessAuthenticator.PROCESS_TYPES.COORDINATOR then
        return ProcessAuthenticator.AUTH_LEVELS.ELEVATED
    else
        return ProcessAuthenticator.AUTH_LEVELS.BASIC
    end
end

function ProcessAuthenticator._generateTokenId()
    local timestamp = msg.Timestamp + CryptoRNG.random(0, 999)
    local randomSuffix = CryptoRNG.random(100000, 999999)
    return "token_" .. timestamp .. "_" .. randomSuffix
end

function ProcessAuthenticator._generateTokenSignature(processId, tokenId, timestamp)
    -- Generate signature using process ID, token ID, and timestamp
    local signatureBase = processId .. "|" .. tokenId .. "|" .. timestamp
    
    -- Use crypto module for signing (in real AO environment)
    -- For now, use a deterministic hash-like generation
    local signature = ""
    for i = 1, #signatureBase do
        local char = string.sub(signatureBase, i, i)
        signature = signature .. string.format("%02x", string.byte(char))
    end
    
    -- Add random suffix using CryptoRNG
    local randomSuffix = CryptoRNG.random(1000000, 9999999)
    return signature .. "_" .. randomSuffix
end

function ProcessAuthenticator._expireToken(tokenId)
    local token = ProcessAuthenticator.activeTokens[tokenId]
    if token then
        -- Decrease token count for the process
        local processRecord = ProcessAuthenticator.processRegistry[token.processId]
        if processRecord then
            processRecord.tokenCount = math.max(0, processRecord.tokenCount - 1)
        end
        
        -- Remove token from active tokens
        ProcessAuthenticator.activeTokens[tokenId] = nil
    end
end

function ProcessAuthenticator._isOperationAuthorized(capabilities, operation)
    if not capabilities or type(capabilities) ~= "table" then
        return false
    end
    
    -- Check if operation is in capabilities list
    for _, capability in ipairs(capabilities) do
        if capability == operation or capability == "*" then
            return true
        end
    end
    
    return false
end

function ProcessAuthenticator._getProcessTypeList()
    local types = {}
    for _, processType in pairs(ProcessAuthenticator.PROCESS_TYPES) do
        table.insert(types, processType:upper())
    end
    return types
end


-- ===== END MODULE: game-logic.process-coordination.process-authenticator =====


-- ===== MODULE: game-logic.process-coordination.message-router =====
-- File: ao-processes/game-logic/process-coordination/message-router.lua
-- Original require: local MessageRouter = require("game-logic.process-coordination.message-router")

-- Message Routing Layer for Inter-Process Communication
-- Routes messages based on operation type and maintains routing tables


-- ===== MODULE: game-logic.process-coordination.process-authenticator =====
-- File: ao-processes/game-logic/process-coordination/process-authenticator.lua
-- Original require: local ProcessAuthenticator = require("game-logic.process-coordination.process-authenticator")


-- ===== END MODULE: game-logic.process-coordination.process-authenticator =====


-- ===== MODULE: game-logic.process-coordination.message-correlator =====
-- File: ao-processes/game-logic/process-coordination/message-correlator.lua
-- Original require: local MessageCorrelator = require("game-logic.process-coordination.message-correlator")


-- ===== END MODULE: game-logic.process-coordination.message-correlator =====


local MessageRouter = {
    -- Routing table mapping operation types to process types
    operationRoutes = {},
    
    -- Process capability routing cache
    processCapabilities = {},
    
    -- Load balancing state for multiple processes of same type
    loadBalancingState = {},
    
    -- Routing statistics
    routingStats = {
        totalRoutes = 0,
        successfulRoutes = 0,
        failedRoutes = 0,
        routesByOperation = {},
        routesByProcessType = {}
    }
}

-- Operation types for routing classification
MessageRouter.OPERATION_TYPES = {
    -- Battle operations
    BATTLE_RESOLUTION = "BATTLE_RESOLUTION",
    BATTLE_START = "BATTLE_START",
    BATTLE_END = "BATTLE_END",
    MOVE_EXECUTION = "MOVE_EXECUTION",
    
    -- Pokemon operations  
    POKEMON_UPDATE = "POKEMON_UPDATE",
    POKEMON_EVOLUTION = "POKEMON_EVOLUTION",
    STAT_CALCULATION = "STAT_CALCULATION",
    POKEMON_CAPTURE = "POKEMON_CAPTURE",
    
    -- Shop operations
    SHOP_TRANSACTION = "SHOP_TRANSACTION", 
    SHOP_INVENTORY = "SHOP_INVENTORY",
    ITEM_PURCHASE = "ITEM_PURCHASE",
    ITEM_SALE = "ITEM_SALE",
    
    -- Game state operations
    SAVE_GAME = "SAVE_GAME",
    LOAD_GAME = "LOAD_GAME",
    SYNC_STATE = "SYNC_STATE",
    
    -- Admin operations
    PROCESS_HEALTH = "PROCESS_HEALTH",
    SYSTEM_STATUS = "SYSTEM_STATUS",
    CONFIGURATION_UPDATE = "CONFIGURATION_UPDATE"
}

-- Default routing table
MessageRouter.DEFAULT_ROUTES = {
    -- Battle operations route to battle processes
    [MessageRouter.OPERATION_TYPES.BATTLE_RESOLUTION] = ProcessAuthenticator.PROCESS_TYPES.BATTLE,
    [MessageRouter.OPERATION_TYPES.BATTLE_START] = ProcessAuthenticator.PROCESS_TYPES.BATTLE,
    [MessageRouter.OPERATION_TYPES.BATTLE_END] = ProcessAuthenticator.PROCESS_TYPES.BATTLE,
    [MessageRouter.OPERATION_TYPES.MOVE_EXECUTION] = ProcessAuthenticator.PROCESS_TYPES.BATTLE,
    
    -- Pokemon operations route to pokemon processes
    [MessageRouter.OPERATION_TYPES.POKEMON_UPDATE] = ProcessAuthenticator.PROCESS_TYPES.POKEMON,
    [MessageRouter.OPERATION_TYPES.POKEMON_EVOLUTION] = ProcessAuthenticator.PROCESS_TYPES.POKEMON,
    [MessageRouter.OPERATION_TYPES.STAT_CALCULATION] = ProcessAuthenticator.PROCESS_TYPES.POKEMON,
    [MessageRouter.OPERATION_TYPES.POKEMON_CAPTURE] = ProcessAuthenticator.PROCESS_TYPES.POKEMON,
    
    -- Shop operations route to shop processes
    [MessageRouter.OPERATION_TYPES.SHOP_TRANSACTION] = ProcessAuthenticator.PROCESS_TYPES.SHOP,
    [MessageRouter.OPERATION_TYPES.SHOP_INVENTORY] = ProcessAuthenticator.PROCESS_TYPES.SHOP,
    [MessageRouter.OPERATION_TYPES.ITEM_PURCHASE] = ProcessAuthenticator.PROCESS_TYPES.SHOP,
    [MessageRouter.OPERATION_TYPES.ITEM_SALE] = ProcessAuthenticator.PROCESS_TYPES.SHOP,
    
    -- Game state operations route to coordinator processes
    [MessageRouter.OPERATION_TYPES.SAVE_GAME] = ProcessAuthenticator.PROCESS_TYPES.COORDINATOR,
    [MessageRouter.OPERATION_TYPES.LOAD_GAME] = ProcessAuthenticator.PROCESS_TYPES.COORDINATOR,
    [MessageRouter.OPERATION_TYPES.SYNC_STATE] = ProcessAuthenticator.PROCESS_TYPES.COORDINATOR,
    
    -- Admin operations route to admin processes
    [MessageRouter.OPERATION_TYPES.PROCESS_HEALTH] = ProcessAuthenticator.PROCESS_TYPES.ADMIN,
    [MessageRouter.OPERATION_TYPES.SYSTEM_STATUS] = ProcessAuthenticator.PROCESS_TYPES.ADMIN,
    [MessageRouter.OPERATION_TYPES.CONFIGURATION_UPDATE] = ProcessAuthenticator.PROCESS_TYPES.ADMIN
}

-- Routing strategies
MessageRouter.ROUTING_STRATEGIES = {
    ROUND_ROBIN = "round_robin",
    LEAST_LOADED = "least_loaded",
    CAPABILITY_MATCH = "capability_match",
    RANDOM = "random"
}

-- Initialize the message router
function MessageRouter.initialize()
    -- Copy default routes to active routing table
    MessageRouter.operationRoutes = {}
    for operation, processType in pairs(MessageRouter.DEFAULT_ROUTES) do
        MessageRouter.operationRoutes[operation] = processType
    end
    
    MessageRouter.processCapabilities = {}
    MessageRouter.loadBalancingState = {}
    MessageRouter.routingStats = {
        totalRoutes = 0,
        successfulRoutes = 0,
        failedRoutes = 0,
        routesByOperation = {},
        routesByProcessType = {}
    }
    
    print("[MessageRouter] Message routing system initialized")
end

-- Add or update routing rule
function MessageRouter.addRoute(operationType, targetProcessType, priority)
    if not operationType or not targetProcessType then
        return false, "Operation type and target process type are required"
    end
    
    if not MessageRouter.OPERATION_TYPES[operationType] and not operationType then
        return false, "Invalid operation type: " .. tostring(operationType)
    end
    
    local validProcessTypes = ProcessAuthenticator._getProcessTypeList()
    local isValidProcessType = false
    for _, processType in ipairs(validProcessTypes) do
        if processType:lower() == targetProcessType:lower() then
            isValidProcessType = true
            break
        end
    end
    
    if not isValidProcessType then
        return false, "Invalid target process type: " .. tostring(targetProcessType)
    end
    
    MessageRouter.operationRoutes[operationType] = {
        processType = targetProcessType:lower(),
        priority = priority or "NORMAL",
        addedAt = timestamp or 0
    }
    
    return true
end

-- Remove routing rule
function MessageRouter.removeRoute(operationType)
    if not operationType then
        return false, "Operation type is required"
    end
    
    if MessageRouter.operationRoutes[operationType] then
        MessageRouter.operationRoutes[operationType] = nil
        return true
    end
    
    return false, "Route not found for operation: " .. tostring(operationType)
end

-- Route a message to appropriate process based on operation type
function MessageRouter.routeMessage(operationType, messageData, routingStrategy)
    MessageRouter.routingStats.totalRoutes = MessageRouter.routingStats.totalRoutes + 1
    MessageRouter.routingStats.routesByOperation[operationType] = (MessageRouter.routingStats.routesByOperation[operationType] or 0) + 1
    
    local strategy = routingStrategy or MessageRouter.ROUTING_STRATEGIES.CAPABILITY_MATCH
    
    -- Get target process type from routing table
    local routeInfo = MessageRouter.operationRoutes[operationType]
    if not routeInfo then
        MessageRouter.routingStats.failedRoutes = MessageRouter.routingStats.failedRoutes + 1
        return nil, "No route found for operation: " .. tostring(operationType)
    end
    
    local targetProcessType = type(routeInfo) == "table" and routeInfo.processType or routeInfo
    
    -- Get available processes for target type
    local availableProcesses = ProcessAuthenticator.listRegisteredProcesses(targetProcessType)
    if not availableProcesses or MessageRouter._getTableSize(availableProcesses) == 0 then
        MessageRouter.routingStats.failedRoutes = MessageRouter.routingStats.failedRoutes + 1
        return nil, "No available processes of type: " .. targetProcessType
    end
    
    -- Select target process based on routing strategy
    local targetProcessId = MessageRouter._selectTargetProcess(availableProcesses, strategy, operationType)
    if not targetProcessId then
        MessageRouter.routingStats.failedRoutes = MessageRouter.routingStats.failedRoutes + 1
        return nil, "Failed to select target process for operation: " .. operationType
    end
    
    -- Create routing context
    local routingContext = {
        operationType = operationType,
        targetProcessId = targetProcessId,
        targetProcessType = targetProcessType,
        routingStrategy = strategy,
        routedAt = timestamp or 0,
        messageData = messageData
    }
    
    MessageRouter.routingStats.successfulRoutes = MessageRouter.routingStats.successfulRoutes + 1
    MessageRouter.routingStats.routesByProcessType[targetProcessType] = (MessageRouter.routingStats.routesByProcessType[targetProcessType] or 0) + 1
    
    return routingContext
end

-- Get routing information for operation type
function MessageRouter.getRouteInfo(operationType)
    local routeInfo = MessageRouter.operationRoutes[operationType]
    if not routeInfo then
        return nil
    end
    
    local targetProcessType = type(routeInfo) == "table" and routeInfo.processType or routeInfo
    local availableProcesses = ProcessAuthenticator.listRegisteredProcesses(targetProcessType)
    
    return {
        operationType = operationType,
        targetProcessType = targetProcessType,
        priority = type(routeInfo) == "table" and routeInfo.priority or "NORMAL",
        availableProcessCount = MessageRouter._getTableSize(availableProcesses),
        availableProcessIds = MessageRouter._getProcessIds(availableProcesses)
    }
end

-- Validate message routing capability
function MessageRouter.validateRouting(operationType, sourceProcessId, targetProcessId)
    -- Check if operation type has a valid route
    local routeInfo = MessageRouter.getRouteInfo(operationType)
    if not routeInfo then
        return false, "No route configured for operation: " .. tostring(operationType)
    end
    
    -- Check if target process exists and is active
    local targetProcess = ProcessAuthenticator.getProcessInfo(targetProcessId)
    if not targetProcess then
        return false, "Target process not found: " .. tostring(targetProcessId)
    end
    
    if targetProcess.status ~= "active" then
        return false, "Target process is not active: " .. targetProcessId
    end
    
    -- Check if target process type matches route
    if targetProcess.type ~= routeInfo.targetProcessType then
        return false, string.format("Process type mismatch. Expected: %s, Got: %s", 
                                   routeInfo.targetProcessType, targetProcess.type)
    end
    
    -- Check if target process has required capability
    if not MessageRouter._processHasCapability(targetProcess.capabilities, operationType) then
        return false, "Target process lacks required capability for operation: " .. operationType
    end
    
    return true
end

-- Update process capabilities cache
function MessageRouter.updateProcessCapabilities(processId, capabilities)
    if not processId or not capabilities then
        return false
    end
    
    MessageRouter.processCapabilities[processId] = {
        capabilities = capabilities,
        lastUpdated = timestamp or 0
    }
    
    return true
end

-- Get all configured routes
function MessageRouter.getAllRoutes()
    local routes = {}
    
    for operationType, routeInfo in pairs(MessageRouter.operationRoutes) do
        local targetProcessType = type(routeInfo) == "table" and routeInfo.processType or routeInfo
        local priority = type(routeInfo) == "table" and routeInfo.priority or "NORMAL"
        
        routes[operationType] = {
            targetProcessType = targetProcessType,
            priority = priority,
            availableProcesses = MessageRouter._getTableSize(ProcessAuthenticator.listRegisteredProcesses(targetProcessType))
        }
    end
    
    return routes
end

-- Get routing statistics
function MessageRouter.getRoutingStatistics()
    return {
        totalRoutes = MessageRouter.routingStats.totalRoutes,
        successfulRoutes = MessageRouter.routingStats.successfulRoutes,
        failedRoutes = MessageRouter.routingStats.failedRoutes,
        successRate = MessageRouter.routingStats.totalRoutes > 0 and 
                     (MessageRouter.routingStats.successfulRoutes / MessageRouter.routingStats.totalRoutes) or 0,
        routesByOperation = MessageRouter.routingStats.routesByOperation,
        routesByProcessType = MessageRouter.routingStats.routesByProcessType,
        configuredRoutes = MessageRouter._getTableSize(MessageRouter.operationRoutes)
    }
end

-- Reset routing statistics
function MessageRouter.resetStatistics()
    MessageRouter.routingStats = {
        totalRoutes = 0,
        successfulRoutes = 0,
        failedRoutes = 0,
        routesByOperation = {},
        routesByProcessType = {}
    }
end

-- Private helper functions

function MessageRouter._selectTargetProcess(availableProcesses, strategy, operationType)
    if MessageRouter._getTableSize(availableProcesses) == 0 then
        return nil
    end
    
    local processIds = MessageRouter._getProcessIds(availableProcesses)
    
    if strategy == MessageRouter.ROUTING_STRATEGIES.ROUND_ROBIN then
        return MessageRouter._roundRobinSelection(processIds, operationType)
        
    elseif strategy == MessageRouter.ROUTING_STRATEGIES.CAPABILITY_MATCH then
        return MessageRouter._capabilityMatchSelection(availableProcesses, operationType)
        
    elseif strategy == MessageRouter.ROUTING_STRATEGIES.RANDOM then
        return MessageRouter._randomSelection(processIds)
        
    elseif strategy == MessageRouter.ROUTING_STRATEGIES.LEAST_LOADED then
        -- For now, fallback to round robin (load tracking would be implemented later)
        return MessageRouter._roundRobinSelection(processIds, operationType)
        
    else
        -- Default to first available process
        return processIds[1]
    end
end

function MessageRouter._roundRobinSelection(processIds, operationType)
    if not MessageRouter.loadBalancingState[operationType] then
        MessageRouter.loadBalancingState[operationType] = 0
    end
    
    local index = (MessageRouter.loadBalancingState[operationType] % #processIds) + 1
    MessageRouter.loadBalancingState[operationType] = MessageRouter.loadBalancingState[operationType] + 1
    
    return processIds[index]
end

function MessageRouter._capabilityMatchSelection(availableProcesses, operationType)
    -- Select process with best capability match
    for processId, processInfo in pairs(availableProcesses) do
        if MessageRouter._processHasCapability(processInfo.capabilities, operationType) then
            return processId
        end
    end
    
    -- Fallback to first available if no perfect match
    local processIds = MessageRouter._getProcessIds(availableProcesses)
    return processIds[1]
end

function MessageRouter._randomSelection(processIds)
    local randomIndex = math.random(1, #processIds)
    return processIds[randomIndex]
end

function MessageRouter._processHasCapability(capabilities, operationType)
    if not capabilities or type(capabilities) ~= "table" then
        return false
    end
    
    for _, capability in ipairs(capabilities) do
        if capability == "*" or capability == operationType or 
           MessageRouter._isRelatedCapability(capability, operationType) then
            return true
        end
    end
    
    return false
end

function MessageRouter._isRelatedCapability(capability, operationType)
    -- Check if capability covers the operation type
    local capabilityMappings = {
        ["battle-resolution"] = {"BATTLE_RESOLUTION", "BATTLE_START", "BATTLE_END", "MOVE_EXECUTION"},
        ["pokemon-management"] = {"POKEMON_UPDATE", "POKEMON_EVOLUTION", "STAT_CALCULATION", "POKEMON_CAPTURE"},
        ["shop-operations"] = {"SHOP_TRANSACTION", "SHOP_INVENTORY", "ITEM_PURCHASE", "ITEM_SALE"},
        ["game-state"] = {"SAVE_GAME", "LOAD_GAME", "SYNC_STATE"},
        ["admin-operations"] = {"PROCESS_HEALTH", "SYSTEM_STATUS", "CONFIGURATION_UPDATE"}
    }
    
    local relatedOperations = capabilityMappings[capability]
    if relatedOperations then
        for _, operation in ipairs(relatedOperations) do
            if operation == operationType then
                return true
            end
        end
    end
    
    return false
end

function MessageRouter._getProcessIds(processes)
    local ids = {}
    for processId, _ in pairs(processes) do
        table.insert(ids, processId)
    end
    return ids
end

function MessageRouter._getTableSize(tbl)
    local count = 0
    for _ in pairs(tbl) do
        count = count + 1
    end
    return count
end


-- ===== END MODULE: game-logic.process-coordination.message-router =====


-- ===== MODULE: game-logic.process-coordination.backward-compatibility =====
-- File: ao-processes/game-logic/process-coordination/backward-compatibility.lua
-- Original require: local BackwardCompatibility = require("game-logic.process-coordination.backward-compatibility")

-- Backward Compatibility Layer for Single-Process to Multi-Process Migration
-- Provides compatibility shims for existing single-process message formats


-- ===== MODULE: game-logic.process-coordination.message-correlator =====
-- File: ao-processes/game-logic/process-coordination/message-correlator.lua
-- Original require: local MessageCorrelator = require("game-logic.process-coordination.message-correlator")


-- ===== END MODULE: game-logic.process-coordination.message-correlator =====


-- ===== MODULE: game-logic.process-coordination.process-authenticator =====
-- File: ao-processes/game-logic/process-coordination/process-authenticator.lua
-- Original require: local ProcessAuthenticator = require("game-logic.process-coordination.process-authenticator")


-- ===== END MODULE: game-logic.process-coordination.process-authenticator =====


local BackwardCompatibility = {
    -- Legacy message format mappings
    legacyOperationMappings = {},
    
    -- Compatibility statistics
    compatibilityStats = {
        legacyMessagesProcessed = 0,
        adaptedMessages = 0,
        incompatibleMessages = 0,
        byOperationType = {}
    }
}

-- Legacy operation types to new operation type mappings
BackwardCompatibility.LEGACY_OPERATION_MAPPINGS = {
    -- Battle legacy mappings
    ["battle"] = "BATTLE_RESOLUTION",
    ["start-battle"] = "BATTLE_START", 
    ["end-battle"] = "BATTLE_END",
    ["execute-move"] = "MOVE_EXECUTION",
    
    -- Pokemon legacy mappings
    ["update-pokemon"] = "POKEMON_UPDATE",
    ["evolve-pokemon"] = "POKEMON_EVOLUTION", 
    ["calculate-stats"] = "STAT_CALCULATION",
    ["catch-pokemon"] = "POKEMON_CAPTURE",
    
    -- Shop legacy mappings
    ["shop-buy"] = "ITEM_PURCHASE",
    ["shop-sell"] = "ITEM_SALE",
    ["shop-inventory"] = "SHOP_INVENTORY",
    ["shop-transaction"] = "SHOP_TRANSACTION",
    
    -- Game state legacy mappings
    ["save"] = "SAVE_GAME",
    ["load"] = "LOAD_GAME",
    ["sync"] = "SYNC_STATE",
    
    -- Admin legacy mappings  
    ["get-info"] = "PROCESS_INFO",
    ["admin"] = "ADMIN_COMMAND"
}

-- Initialize the backward compatibility system
function BackwardCompatibility.initialize()
    BackwardCompatibility.legacyOperationMappings = BackwardCompatibility.LEGACY_OPERATION_MAPPINGS
    
    -- Initialize statistics tracking
    for legacyOp, newOp in pairs(BackwardCompatibility.legacyOperationMappings) do
        BackwardCompatibility.compatibilityStats.byOperationType[legacyOp] = {
            processed = 0,
            adapted = 0,
            failed = 0
        }
    end
    
    return true
end

-- Detect if a message uses legacy format
function BackwardCompatibility.isLegacyMessage(messageData)
    if type(messageData) ~= "table" then
        return false
    end
    
    -- Check for new inter-process message structure
    if messageData.correlation and messageData.auth and messageData.operation then
        return false -- This is a new format message
    end
    
    -- Check for common legacy patterns
    local hasLegacyPatterns = (
        messageData.action or 
        messageData.command or 
        messageData.operation or
        messageData.type
    )
    
    return hasLegacyPatterns ~= nil
end

-- Convert legacy message format to new inter-process format
function BackwardCompatibility.adaptLegacyMessage(messageData, fromProcessId, toProcessId, timestamp)
    BackwardCompatibility.compatibilityStats.legacyMessagesProcessed = BackwardCompatibility.compatibilityStats.legacyMessagesProcessed + 1
    
    if not BackwardCompatibility.isLegacyMessage(messageData) then
        return messageData -- Already new format, no adaptation needed
    end
    
    -- Extract legacy operation type
    local legacyOperationType = messageData.action or messageData.command or messageData.operation or messageData.type
    if not legacyOperationType then
        BackwardCompatibility.compatibilityStats.incompatibleMessages = BackwardCompatibility.compatibilityStats.incompatibleMessages + 1
        return nil, "Cannot determine operation type from legacy message"
    end
    
    -- Map to new operation type
    local newOperationType = BackwardCompatibility.legacyOperationMappings[legacyOperationType]
    if not newOperationType then
        BackwardCompatibility.compatibilityStats.incompatibleMessages = BackwardCompatibility.compatibilityStats.incompatibleMessages + 1
        return nil, "No mapping found for legacy operation: " .. tostring(legacyOperationType)
    end
    
    -- Generate correlation ID
    local correlationId = MessageCorrelator.generateCorrelationId()
    
    -- Create authentication context (use process authenticator if available)
    local authToken = "legacy-compat-token"
    if ProcessAuthenticator.generateProcessToken then
        authToken = ProcessAuthenticator.generateProcessToken(fromProcessId or "legacy-process") or authToken
    end
    
    -- Build new format message
    local adaptedMessage = {
        correlation = {
            id = correlationId,
            parent = nil, -- Legacy messages don't have parent correlations
            origin = fromProcessId or "legacy-process",
            target = toProcessId or "coordinator"
        },
        auth = {
            processId = fromProcessId or "legacy-process", 
            token = authToken,
            timestamp = timestamp or 0
        },
        operation = {
            type = newOperationType,
            priority = messageData.priority or "NORMAL",
            retryable = messageData.retryable ~= false -- Default to retryable
        },
        payload = {
            -- Include original message data as payload
            originalData = messageData,
            legacyOperation = legacyOperationType,
            adaptedBy = "BackwardCompatibility",
            adaptedAt = timestamp or 0
        },
        _compatibility = {
            isAdapted = true,
            originalFormat = "legacy",
            adaptedFrom = legacyOperationType
        }
    }
    
    -- Update statistics
    BackwardCompatibility.compatibilityStats.adaptedMessages = BackwardCompatibility.compatibilityStats.adaptedMessages + 1
    if BackwardCompatibility.compatibilityStats.byOperationType[legacyOperationType] then
        BackwardCompatibility.compatibilityStats.byOperationType[legacyOperationType].processed = 
            BackwardCompatibility.compatibilityStats.byOperationType[legacyOperationType].processed + 1
        BackwardCompatibility.compatibilityStats.byOperationType[legacyOperationType].adapted = 
            BackwardCompatibility.compatibilityStats.byOperationType[legacyOperationType].adapted + 1
    end
    
    return adaptedMessage
end

-- Convert new format response back to legacy format for backward compatibility
function BackwardCompatibility.adaptResponseToLegacy(responseData, originalLegacyMessage, timestamp)
    if not responseData then
        return nil
    end
    
    -- If original message wasn't legacy, return response as-is
    if not BackwardCompatibility.isLegacyMessage(originalLegacyMessage) then
        return responseData
    end
    
    -- Extract key information for legacy response
    local legacyResponse = {
        success = responseData.success or true,
        result = responseData.payload or responseData.result,
        timestamp = responseData.timestamp or timestamp or 0,
        correlationId = responseData.correlationId or (responseData.correlation and responseData.correlation.id),
        processedBy = responseData.targetProcessId or "unknown"
    }
    
    -- Include error information if present
    if responseData.error then
        legacyResponse.success = false
        legacyResponse.error = responseData.error
        legacyResponse.message = responseData.message
    end
    
    -- Mark as adapted response
    legacyResponse._adapted = {
        from = "inter-process",
        to = "legacy",
        adaptedAt = timestamp or 0
    }
    
    return legacyResponse
end

-- Add custom legacy operation mapping
function BackwardCompatibility.addLegacyMapping(legacyOperation, newOperation)
    if not legacyOperation or not newOperation then
        return false, "Both legacy and new operation types are required"
    end
    
    BackwardCompatibility.legacyOperationMappings[legacyOperation] = newOperation
    
    -- Initialize statistics tracking
    BackwardCompatibility.compatibilityStats.byOperationType[legacyOperation] = {
        processed = 0,
        adapted = 0, 
        failed = 0
    }
    
    return true
end

-- Remove legacy operation mapping
function BackwardCompatibility.removeLegacyMapping(legacyOperation)
    if BackwardCompatibility.legacyOperationMappings[legacyOperation] then
        BackwardCompatibility.legacyOperationMappings[legacyOperation] = nil
        BackwardCompatibility.compatibilityStats.byOperationType[legacyOperation] = nil
        return true
    end
    return false
end

-- Get compatibility statistics
function BackwardCompatibility.getCompatibilityStats()
    return BackwardCompatibility.compatibilityStats
end

-- Get available legacy mappings
function BackwardCompatibility.getLegacyMappings()
    return BackwardCompatibility.legacyOperationMappings
end

-- Validate legacy message compatibility
function BackwardCompatibility.validateLegacyCompatibility(messageData)
    if not BackwardCompatibility.isLegacyMessage(messageData) then
        return true, "Message uses new format - no compatibility issues"
    end
    
    local legacyOperationType = messageData.action or messageData.command or messageData.operation or messageData.type
    if not legacyOperationType then
        return false, "Cannot determine operation type from legacy message"
    end
    
    local newOperationType = BackwardCompatibility.legacyOperationMappings[legacyOperationType]
    if not newOperationType then
        return false, "No mapping available for legacy operation: " .. tostring(legacyOperationType)
    end
    
    return true, "Legacy operation '" .. legacyOperationType .. "' can be mapped to '" .. newOperationType .. "'"
end

-- Initialize on module load
BackwardCompatibility.initialize()


-- ===== END MODULE: game-logic.process-coordination.backward-compatibility =====


-- ===== MODULE: game-logic.process-coordination.performance-monitor =====
-- File: ao-processes/game-logic/process-coordination/performance-monitor.lua
-- Original require: local PerformanceMonitor = require("game-logic.process-coordination.performance-monitor")

-- Performance Monitoring and Benchmarking System
-- Provides baseline performance metrics and inter-process communication monitoring

local PerformanceMonitor = {
    -- Performance metrics storage
    metrics = {
        totalOperations = 0,
        totalLatency = 0,
        minLatency = nil,
        maxLatency = nil,
        averageLatency = 0,
        
        -- Operation-specific metrics
        operationMetrics = {},
        
        -- Process-specific metrics  
        processMetrics = {},
        
        -- Throughput tracking
        operationsPerSecond = 0,
        lastThroughputUpdate = 0,
        currentSecondOperations = 0,
        
        -- Memory and resource usage
        memoryUsage = {},
        
        -- Error rate tracking
        totalErrors = 0,
        errorRate = 0
    },
    
    -- Benchmark baselines for comparison
    baselines = {
        monolithicLatency = 0, -- To be measured
        maxAcceptableLatency = 100, -- milliseconds
        targetThroughput = 100, -- operations per second
        maxMemoryUsage = 1024 * 1024 * 50 -- 50MB in bytes
    },
    
    -- Active performance measurements
    activeMeasurements = {}
}

-- Initialize performance monitoring system
function PerformanceMonitor.initialize(timestamp)
    PerformanceMonitor.metrics.totalOperations = 0
    PerformanceMonitor.metrics.totalLatency = 0
    PerformanceMonitor.metrics.averageLatency = 0
    PerformanceMonitor.metrics.lastThroughputUpdate = timestamp or 0
    
    return true
end

-- Start measuring operation performance
function PerformanceMonitor.startMeasurement(operationId, operationType, processId, timestamp)
    if not operationId then
        return false, "Operation ID is required for performance measurement"
    end
    
    local startTime = os.clock() * 1000 -- Convert to milliseconds
    local startMemory = collectgarbage("count") * 1024 -- Convert KB to bytes
    
    PerformanceMonitor.activeMeasurements[operationId] = {
        operationType = operationType,
        processId = processId,
        startTime = startTime,
        startMemory = startMemory,
        timestamp = timestamp or 0
    }
    
    return true
end

-- End measuring operation performance and record metrics
function PerformanceMonitor.endMeasurement(operationId, success, errorCode)
    local measurement = PerformanceMonitor.activeMeasurements[operationId]
    if not measurement then
        return false, "No active measurement found for operation: " .. tostring(operationId)
    end
    
    local endTime = os.clock() * 1000 -- Convert to milliseconds
    local endMemory = collectgarbage("count") * 1024 -- Convert KB to bytes
    
    local latency = endTime - measurement.startTime
    local memoryDelta = endMemory - measurement.startMemory
    
    -- Update global metrics
    PerformanceMonitor.metrics.totalOperations = PerformanceMonitor.metrics.totalOperations + 1
    PerformanceMonitor.metrics.totalLatency = PerformanceMonitor.metrics.totalLatency + latency
    PerformanceMonitor.metrics.averageLatency = PerformanceMonitor.metrics.totalLatency / PerformanceMonitor.metrics.totalOperations
    
    -- Update min/max latency
    if not PerformanceMonitor.metrics.minLatency or latency < PerformanceMonitor.metrics.minLatency then
        PerformanceMonitor.metrics.minLatency = latency
    end
    if not PerformanceMonitor.metrics.maxLatency or latency > PerformanceMonitor.metrics.maxLatency then
        PerformanceMonitor.metrics.maxLatency = latency
    end
    
    -- Update operation-specific metrics
    local opType = measurement.operationType or "unknown"
    if not PerformanceMonitor.metrics.operationMetrics[opType] then
        PerformanceMonitor.metrics.operationMetrics[opType] = {
            count = 0,
            totalLatency = 0,
            averageLatency = 0,
            minLatency = nil,
            maxLatency = nil,
            successCount = 0,
            errorCount = 0,
            memoryUsage = { total = 0, average = 0, min = nil, max = nil }
        }
    end
    
    local opMetrics = PerformanceMonitor.metrics.operationMetrics[opType]
    opMetrics.count = opMetrics.count + 1
    opMetrics.totalLatency = opMetrics.totalLatency + latency
    opMetrics.averageLatency = opMetrics.totalLatency / opMetrics.count
    
    if not opMetrics.minLatency or latency < opMetrics.minLatency then
        opMetrics.minLatency = latency
    end
    if not opMetrics.maxLatency or latency > opMetrics.maxLatency then
        opMetrics.maxLatency = latency
    end
    
    if success then
        opMetrics.successCount = opMetrics.successCount + 1
    else
        opMetrics.errorCount = opMetrics.errorCount + 1
        PerformanceMonitor.metrics.totalErrors = PerformanceMonitor.metrics.totalErrors + 1
    end
    
    -- Track memory usage
    opMetrics.memoryUsage.total = opMetrics.memoryUsage.total + memoryDelta
    opMetrics.memoryUsage.average = opMetrics.memoryUsage.total / opMetrics.count
    if not opMetrics.memoryUsage.min or memoryDelta < opMetrics.memoryUsage.min then
        opMetrics.memoryUsage.min = memoryDelta
    end
    if not opMetrics.memoryUsage.max or memoryDelta > opMetrics.memoryUsage.max then
        opMetrics.memoryUsage.max = memoryDelta
    end
    
    -- Update process-specific metrics
    local processId = measurement.processId or "unknown"
    if not PerformanceMonitor.metrics.processMetrics[processId] then
        PerformanceMonitor.metrics.processMetrics[processId] = {
            operationCount = 0,
            totalLatency = 0,
            averageLatency = 0,
            errorCount = 0
        }
    end
    
    local procMetrics = PerformanceMonitor.metrics.processMetrics[processId]
    procMetrics.operationCount = procMetrics.operationCount + 1
    procMetrics.totalLatency = procMetrics.totalLatency + latency
    procMetrics.averageLatency = procMetrics.totalLatency / procMetrics.operationCount
    
    if not success then
        procMetrics.errorCount = procMetrics.errorCount + 1
    end
    
    -- Update throughput metrics
    PerformanceMonitor.updateThroughputMetrics()
    
    -- Update error rate
    PerformanceMonitor.metrics.errorRate = PerformanceMonitor.metrics.totalErrors / PerformanceMonitor.metrics.totalOperations
    
    -- Clean up active measurement
    PerformanceMonitor.activeMeasurements[operationId] = nil
    
    return {
        operationId = operationId,
        operationType = opType,
        processId = processId,
        latency = latency,
        memoryDelta = memoryDelta,
        success = success,
        errorCode = errorCode,
        timestamp = timestamp or 0
    }
end

-- Update throughput metrics (operations per second)
function PerformanceMonitor.updateThroughputMetrics(timestamp)
    local currentTime = timestamp or 0
    local timeDiff = currentTime - PerformanceMonitor.metrics.lastThroughputUpdate
    
    if timeDiff >= 1 then -- Update every second
        PerformanceMonitor.metrics.operationsPerSecond = PerformanceMonitor.metrics.currentSecondOperations / timeDiff
        PerformanceMonitor.metrics.currentSecondOperations = 0
        PerformanceMonitor.metrics.lastThroughputUpdate = currentTime
    end
    
    PerformanceMonitor.metrics.currentSecondOperations = PerformanceMonitor.metrics.currentSecondOperations + 1
end

-- Get current performance metrics
function PerformanceMonitor.getMetrics()
    return PerformanceMonitor.metrics
end

-- Get performance metrics for specific operation type
function PerformanceMonitor.getOperationMetrics(operationType)
    return PerformanceMonitor.metrics.operationMetrics[operationType]
end

-- Get performance metrics for specific process
function PerformanceMonitor.getProcessMetrics(processId)
    return PerformanceMonitor.metrics.processMetrics[processId]
end

-- Set performance baseline for comparison
function PerformanceMonitor.setBaseline(baselineType, value)
    if not baselineType or not value then
        return false, "Baseline type and value are required"
    end
    
    PerformanceMonitor.baselines[baselineType] = value
    return true
end

-- Get performance baselines
function PerformanceMonitor.getBaselines()
    return PerformanceMonitor.baselines
end

-- Compare current performance against baselines
function PerformanceMonitor.compareToBaselines()
    local comparison = {
        latencyComparison = {},
        throughputComparison = {},
        memoryComparison = {},
        performanceRegression = false,
        recommendations = {}
    }
    
    -- Latency comparison
    local avgLatency = PerformanceMonitor.metrics.averageLatency
    local baselineLatency = PerformanceMonitor.baselines.monolithicLatency
    
    if baselineLatency > 0 then
        local latencyRatio = avgLatency / baselineLatency
        comparison.latencyComparison = {
            current = avgLatency,
            baseline = baselineLatency,
            ratio = latencyRatio,
            degradation = latencyRatio > 1.1, -- 10% tolerance
            improvement = latencyRatio < 0.9
        }
        
        if latencyRatio > 1.2 then -- 20% degradation threshold
            comparison.performanceRegression = true
            table.insert(comparison.recommendations, "Latency degradation detected: " .. math.floor((latencyRatio - 1) * 100) .. "% slower than baseline")
        end
    end
    
    -- Throughput comparison
    local currentThroughput = PerformanceMonitor.metrics.operationsPerSecond
    local targetThroughput = PerformanceMonitor.baselines.targetThroughput
    
    comparison.throughputComparison = {
        current = currentThroughput,
        target = targetThroughput,
        meetingTarget = currentThroughput >= targetThroughput * 0.9 -- 10% tolerance
    }
    
    if not comparison.throughputComparison.meetingTarget then
        table.insert(comparison.recommendations, "Throughput below target: " .. currentThroughput .. " vs " .. targetThroughput .. " ops/sec")
    end
    
    -- Memory comparison
    local currentMemory = collectgarbage("count") * 1024
    local maxMemory = PerformanceMonitor.baselines.maxMemoryUsage
    
    comparison.memoryComparison = {
        current = currentMemory,
        maximum = maxMemory,
        withinLimits = currentMemory <= maxMemory
    }
    
    if not comparison.memoryComparison.withinLimits then
        comparison.performanceRegression = true
        table.insert(comparison.recommendations, "Memory usage exceeds limits: " .. math.floor(currentMemory/1024/1024) .. "MB vs " .. math.floor(maxMemory/1024/1024) .. "MB limit")
    end
    
    return comparison
end

-- Generate performance report
function PerformanceMonitor.generatePerformanceReport()
    local metrics = PerformanceMonitor.getMetrics()
    local baselines = PerformanceMonitor.getBaselines()
    local comparison = PerformanceMonitor.compareToBaselines()
    
    return {
        summary = {
            totalOperations = metrics.totalOperations,
            averageLatency = metrics.averageLatency,
            minLatency = metrics.minLatency,
            maxLatency = metrics.maxLatency,
            throughput = metrics.operationsPerSecond,
            errorRate = metrics.errorRate,
            memoryUsage = collectgarbage("count") * 1024
        },
        baselines = baselines,
        comparison = comparison,
        operationBreakdown = metrics.operationMetrics,
        processBreakdown = metrics.processMetrics,
        recommendations = comparison.recommendations,
        generatedAt = timestamp or 0
    }
end

-- Reset performance metrics (useful for testing)
function PerformanceMonitor.resetMetrics(timestamp)
    PerformanceMonitor.metrics = {
        totalOperations = 0,
        totalLatency = 0,
        minLatency = nil,
        maxLatency = nil,
        averageLatency = 0,
        operationMetrics = {},
        processMetrics = {},
        operationsPerSecond = 0,
        lastThroughputUpdate = timestamp or 0,
        currentSecondOperations = 0,
        memoryUsage = {},
        totalErrors = 0,
        errorRate = 0
    }
    PerformanceMonitor.activeMeasurements = {}
    return true
end

-- Clean up stale measurements (measurements older than 5 minutes)
function PerformanceMonitor.cleanupStaleMeasurements(timestamp)
    local currentTime = timestamp or 0
    local cleanedCount = 0
    
    for operationId, measurement in pairs(PerformanceMonitor.activeMeasurements) do
        if (currentTime - measurement.timestamp) > 300 then -- 5 minutes
            PerformanceMonitor.activeMeasurements[operationId] = nil
            cleanedCount = cleanedCount + 1
        end
    end
    
    return cleanedCount
end

-- Initialize on module load
PerformanceMonitor.initialize()


-- ===== END MODULE: game-logic.process-coordination.performance-monitor =====


-- Load admin-specific components

-- ===== MODULE: admin.components.health-monitor =====
-- File: ao-processes/admin/components/health-monitor.lua
-- Original require: local HealthMonitor = require("admin.components.health-monitor")

-- Health Monitor Component
-- Provides comprehensive process health tracking and monitoring capabilities


-- ===== MODULE: game-logic.process-coordination.message-correlator =====
-- File: ao-processes/game-logic/process-coordination/message-correlator.lua
-- Original require: local MessageCorrelator = require("game-logic.process-coordination.message-correlator")


-- ===== END MODULE: game-logic.process-coordination.message-correlator =====


-- ===== MODULE: game-logic.process-coordination.process-authenticator =====
-- File: ao-processes/game-logic/process-coordination/process-authenticator.lua
-- Original require: local ProcessAuthenticator = require("game-logic.process-coordination.process-authenticator")


-- ===== END MODULE: game-logic.process-coordination.process-authenticator =====


-- ===== MODULE: game-logic.process-coordination.message-router =====
-- File: ao-processes/game-logic/process-coordination/message-router.lua
-- Original require: local MessageRouter = require("game-logic.process-coordination.message-router")


-- ===== END MODULE: game-logic.process-coordination.message-router =====


local HealthMonitor = {
    -- Monitored processes registry
    monitoredProcesses = {},
    
    -- Health check configuration
    config = {
        healthCheckIntervalSeconds = 30,
        healthTimeoutMs = 5000,
        maxConsecutiveFailures = 3,
        alertThresholds = {
            responseTimeMs = 5000,
            memoryUsagePercent = 85,
            cpuUsagePercent = 90,
            errorRate = 0.1
        }
    },
    
    -- Health status tracking
    healthStatistics = {
        totalHealthChecks = 0,
        successfulChecks = 0,
        failedChecks = 0,
        averageResponseTime = 0,
        lastSystemHealthCheck = 0
    },
    
    -- Health status constants
    HEALTH_STATUS = {
        HEALTHY = "HEALTHY",
        DEGRADED = "DEGRADED", 
        UNHEALTHY = "UNHEALTHY",
        OFFLINE = "OFFLINE",
        UNKNOWN = "UNKNOWN"
    }
}

-- Initialize health monitoring system
function HealthMonitor.initialize()
    HealthMonitor.monitoredProcesses = {}
    HealthMonitor.healthStatistics = {
        totalHealthChecks = 0,
        successfulChecks = 0,
        failedChecks = 0,
        averageResponseTime = 0,
        lastSystemHealthCheck = 0
    }
    print("[HealthMonitor] Health monitoring system initialized")
end

-- Register a process for health monitoring
function HealthMonitor.registerProcess(processId, processType, healthConfig)
    if not processId or type(processId) ~= "string" or processId == "" then
        return { success = false, error = "Process ID is required" }
    end
    
    local healthRecord = {
        processId = processId,
        processType = processType or "UNKNOWN",
        healthStatus = HealthMonitor.HEALTH_STATUS.UNKNOWN,
        lastHealthCheck = 0,
        lastSuccessfulCheck = 0,
        consecutiveFailures = 0,
        healthMetrics = {
            uptime = 0,
            memoryUsage = 0,
            cpuUsage = 0,
            responseTime = 0,
            errorCount = 0,
            errorRate = 0
        },
        healthConfig = healthConfig or {},
        registeredAt = 0,
        alertsGenerated = 0,
        healthHistory = {}
    }
    
    HealthMonitor.monitoredProcesses[processId] = healthRecord
    
    print("[HealthMonitor] Process registered for monitoring: " .. processId .. " (" .. processType .. ")")
    return { success = true, processId = processId }
end

-- Unregister a process from health monitoring
function HealthMonitor.unregisterProcess(processId)
    if HealthMonitor.monitoredProcesses[processId] then
        HealthMonitor.monitoredProcesses[processId] = nil
        print("[HealthMonitor] Process unregistered from monitoring: " .. processId)
        return { success = true }
    else
        return { success = false, error = "Process not found in monitoring registry" }
    end
end

-- Perform health check on specific process
function HealthMonitor.performHealthCheck(processId)
    local processRecord = HealthMonitor.monitoredProcesses[processId]
    if not processRecord then
        return { success = false, error = "Process not registered for monitoring" }
    end
    
    local correlationId = MessageCorrelator.generateId()
    local startTime = msg.Timestamp
    
    -- Send health check message to process
    local healthCheckMessage = {
        correlation = {
            id = correlationId,
            requestType = "HEALTH_CHECK"
        },
        healthQuery = {
            queryType = "FULL_HEALTH",
            includeMetrics = true,
            timestamp = startTime
        }
    }
    
    -- Route health check message
    local routingResult = MessageRouter.routeMessage(
        "HEALTH_CHECK",
        healthCheckMessage,
        "DIRECT_ROUTE"
    )
    
    HealthMonitor.healthStatistics.totalHealthChecks = HealthMonitor.healthStatistics.totalHealthChecks + 1
    
    if routingResult.success then
        -- Health check sent successfully, record metrics when response is received
        processRecord.lastHealthCheck = startTime
        return { success = true, correlationId = correlationId, startTime = startTime }
    else
        -- Health check failed to send
        processRecord.consecutiveFailures = processRecord.consecutiveFailures + 1
        processRecord.healthStatus = HealthMonitor._determineHealthStatus(processRecord)
        HealthMonitor.healthStatistics.failedChecks = HealthMonitor.healthStatistics.failedChecks + 1
        
        return { success = false, error = routingResult.error }
    end
end

-- Process health response from monitored process
function HealthMonitor.processHealthResponse(processId, healthResponse, requestStartTime)
    local processRecord = HealthMonitor.monitoredProcesses[processId]
    if not processRecord then
        return { success = false, error = "Process not registered for monitoring" }
    end
    
    local responseTime = (0 - requestStartTime) * 1000 -- Convert to milliseconds
    local healthData = healthResponse.healthData
    
    if healthData then
        -- Update process health metrics
        processRecord.healthMetrics = {
            uptime = healthData.healthMetrics and healthData.healthMetrics.uptime or 0,
            memoryUsage = healthData.healthMetrics and healthData.healthMetrics.memoryUsage or 0,
            cpuUsage = healthData.healthMetrics and healthData.healthMetrics.cpuUsage or 0,
            responseTime = responseTime,
            errorCount = healthData.recentErrors and healthData.recentErrors.errorCount or 0,
            errorRate = healthData.performanceMetrics and healthData.performanceMetrics.errorRate or 0
        }
        
        -- Reset consecutive failures on successful health check
        processRecord.consecutiveFailures = 0
        processRecord.lastSuccessfulCheck = 0
        
        -- Determine health status based on metrics
        processRecord.healthStatus = HealthMonitor._determineHealthStatus(processRecord)
        
        -- Record health history
        HealthMonitor._recordHealthHistory(processId, processRecord)
        
        -- Update statistics
        HealthMonitor.healthStatistics.successfulChecks = HealthMonitor.healthStatistics.successfulChecks + 1
        HealthMonitor._updateAverageResponseTime(responseTime)
        
        return { success = true, healthStatus = processRecord.healthStatus }
    else
        -- Invalid health response
        processRecord.consecutiveFailures = processRecord.consecutiveFailures + 1
        processRecord.healthStatus = HealthMonitor._determineHealthStatus(processRecord)
        HealthMonitor.healthStatistics.failedChecks = HealthMonitor.healthStatistics.failedChecks + 1
        
        return { success = false, error = "Invalid health response data" }
    end
end

-- Perform system-wide health check
function HealthMonitor.performSystemHealthCheck()
    local results = {
        timestamp = msg.Timestamp,
        overallHealth = HealthMonitor.HEALTH_STATUS.HEALTHY,
        processCount = 0,
        healthyProcesses = 0,
        degradedProcesses = 0,
        unhealthyProcesses = 0,
        offlineProcesses = 0,
        processResults = {}
    }
    
    for processId, processRecord in pairs(HealthMonitor.monitoredProcesses) do
        local healthCheckResult = HealthMonitor.performHealthCheck(processId)
        
        results.processCount = results.processCount + 1
        results.processResults[processId] = {
            processId = processId,
            processType = processRecord.processType,
            healthStatus = processRecord.healthStatus,
            responseTime = processRecord.healthMetrics.responseTime,
            lastCheck = processRecord.lastHealthCheck,
            consecutiveFailures = processRecord.consecutiveFailures
        }
        
        -- Count process health status distribution
        if processRecord.healthStatus == HealthMonitor.HEALTH_STATUS.HEALTHY then
            results.healthyProcesses = results.healthyProcesses + 1
        elseif processRecord.healthStatus == HealthMonitor.HEALTH_STATUS.DEGRADED then
            results.degradedProcesses = results.degradedProcesses + 1
        elseif processRecord.healthStatus == HealthMonitor.HEALTH_STATUS.UNHEALTHY then
            results.unhealthyProcesses = results.unhealthyProcesses + 1
        elseif processRecord.healthStatus == HealthMonitor.HEALTH_STATUS.OFFLINE then
            results.offlineProcesses = results.offlineProcesses + 1
        end
    end
    
    -- Determine overall system health
    if results.unhealthyProcesses > 0 or results.offlineProcesses > results.processCount * 0.5 then
        results.overallHealth = HealthMonitor.HEALTH_STATUS.UNHEALTHY
    elseif results.degradedProcesses > results.processCount * 0.25 then
        results.overallHealth = HealthMonitor.HEALTH_STATUS.DEGRADED
    end
    
    HealthMonitor.healthStatistics.lastSystemHealthCheck = 0
    
    print("[HealthMonitor] System health check completed - Overall: " .. results.overallHealth .. 
          " (" .. results.healthyProcesses .. "/" .. results.processCount .. " healthy)")
    
    return results
end

-- Get health status for specific process
function HealthMonitor.getProcessHealth(processId)
    local processRecord = HealthMonitor.monitoredProcesses[processId]
    if not processRecord then
        return nil
    end
    
    return {
        processId = processId,
        processType = processRecord.processType,
        healthStatus = processRecord.healthStatus,
        healthMetrics = processRecord.healthMetrics,
        lastHealthCheck = processRecord.lastHealthCheck,
        lastSuccessfulCheck = processRecord.lastSuccessfulCheck,
        consecutiveFailures = processRecord.consecutiveFailures,
        registeredAt = processRecord.registeredAt,
        alertsGenerated = processRecord.alertsGenerated
    }
end

-- Get health status for all monitored processes
function HealthMonitor.getAllProcessHealth()
    local allProcessHealth = {}
    
    for processId, processRecord in pairs(HealthMonitor.monitoredProcesses) do
        allProcessHealth[processId] = HealthMonitor.getProcessHealth(processId)
    end
    
    return allProcessHealth
end

-- Get process summary for dashboard display
function HealthMonitor.getProcessSummary()
    local summary = {
        totalProcesses = 0,
        healthyProcesses = 0,
        degradedProcesses = 0,
        unhealthyProcesses = 0,
        offlineProcesses = 0,
        processTypes = {}
    }
    
    for processId, processRecord in pairs(HealthMonitor.monitoredProcesses) do
        summary.totalProcesses = summary.totalProcesses + 1
        
        -- Count by health status
        if processRecord.healthStatus == HealthMonitor.HEALTH_STATUS.HEALTHY then
            summary.healthyProcesses = summary.healthyProcesses + 1
        elseif processRecord.healthStatus == HealthMonitor.HEALTH_STATUS.DEGRADED then
            summary.degradedProcesses = summary.degradedProcesses + 1
        elseif processRecord.healthStatus == HealthMonitor.HEALTH_STATUS.UNHEALTHY then
            summary.unhealthyProcesses = summary.unhealthyProcesses + 1
        elseif processRecord.healthStatus == HealthMonitor.HEALTH_STATUS.OFFLINE then
            summary.offlineProcesses = summary.offlineProcesses + 1
        end
        
        -- Count by process type
        local processType = processRecord.processType
        if not summary.processTypes[processType] then
            summary.processTypes[processType] = 0
        end
        summary.processTypes[processType] = summary.processTypes[processType] + 1
    end
    
    return summary
end

-- Get overall system health status
function HealthMonitor.getOverallHealthStatus()
    local summary = HealthMonitor.getProcessSummary()
    
    if summary.totalProcesses == 0 then
        return HealthMonitor.HEALTH_STATUS.UNKNOWN
    end
    
    local unhealthyRatio = (summary.unhealthyProcesses + summary.offlineProcesses) / summary.totalProcesses
    local degradedRatio = summary.degradedProcesses / summary.totalProcesses
    
    if unhealthyRatio > 0.5 then
        return HealthMonitor.HEALTH_STATUS.UNHEALTHY
    elseif unhealthyRatio > 0.25 or degradedRatio > 0.5 then
        return HealthMonitor.HEALTH_STATUS.DEGRADED
    else
        return HealthMonitor.HEALTH_STATUS.HEALTHY
    end
end

-- Get count of monitored processes
function HealthMonitor.getMonitoredProcessCount()
    local count = 0
    for _ in pairs(HealthMonitor.monitoredProcesses) do
        count = count + 1
    end
    return count
end

-- Update health monitoring thresholds
function HealthMonitor.updateThresholds(newThresholds)
    if not newThresholds or type(newThresholds) ~= "table" then
        return { success = false, error = "Invalid threshold configuration" }
    end
    
    for key, value in pairs(newThresholds) do
        if HealthMonitor.config.alertThresholds[key] then
            HealthMonitor.config.alertThresholds[key] = value
        end
    end
    
    print("[HealthMonitor] Health thresholds updated")
    return { success = true, thresholds = HealthMonitor.config.alertThresholds }
end

-- Get health monitoring statistics
function HealthMonitor.getStatistics()
    return {
        healthStatistics = HealthMonitor.healthStatistics,
        monitoredProcessCount = HealthMonitor.getMonitoredProcessCount(),
        overallHealthStatus = HealthMonitor.getOverallHealthStatus(),
        configuration = HealthMonitor.config,
        processSummary = HealthMonitor.getProcessSummary()
    }
end

-- Private helper functions

function HealthMonitor._determineHealthStatus(processRecord)
    local metrics = processRecord.healthMetrics
    local config = HealthMonitor.config.alertThresholds
    
    -- Check if process is offline (too many consecutive failures)
    if processRecord.consecutiveFailures >= HealthMonitor.config.maxConsecutiveFailures then
        return HealthMonitor.HEALTH_STATUS.OFFLINE
    end
    
    -- Check for unhealthy conditions
    if (metrics.responseTime > config.responseTimeMs) or
       (metrics.memoryUsage > config.memoryUsagePercent) or
       (metrics.cpuUsage > config.cpuUsagePercent) or
       (metrics.errorRate > config.errorRate) then
        return HealthMonitor.HEALTH_STATUS.UNHEALTHY
    end
    
    -- Check for degraded conditions (warning levels)
    if (metrics.responseTime > config.responseTimeMs * 0.7) or
       (metrics.memoryUsage > config.memoryUsagePercent * 0.8) or
       (metrics.cpuUsage > config.cpuUsagePercent * 0.8) or
       (metrics.errorRate > config.errorRate * 0.5) then
        return HealthMonitor.HEALTH_STATUS.DEGRADED
    end
    
    return HealthMonitor.HEALTH_STATUS.HEALTHY
end

function HealthMonitor._recordHealthHistory(processId, processRecord)
    if not processRecord.healthHistory then
        processRecord.healthHistory = {}
    end
    
    -- Keep only last 24 health history entries (configurable)
    local maxHistoryEntries = 24
    if #processRecord.healthHistory >= maxHistoryEntries then
        table.remove(processRecord.healthHistory, 1)
    end
    
    table.insert(processRecord.healthHistory, {
        timestamp = msg.Timestamp,
        healthStatus = processRecord.healthStatus,
        responseTime = processRecord.healthMetrics.responseTime,
        memoryUsage = processRecord.healthMetrics.memoryUsage,
        cpuUsage = processRecord.healthMetrics.cpuUsage,
        errorRate = processRecord.healthMetrics.errorRate
    })
end

function HealthMonitor._updateAverageResponseTime(newResponseTime)
    local currentAvg = HealthMonitor.healthStatistics.averageResponseTime
    local totalChecks = HealthMonitor.healthStatistics.totalHealthChecks
    
    if totalChecks <= 1 then
        HealthMonitor.healthStatistics.averageResponseTime = newResponseTime
    else
        HealthMonitor.healthStatistics.averageResponseTime = 
            ((currentAvg * (totalChecks - 1)) + newResponseTime) / totalChecks
    end
end


-- ===== END MODULE: admin.components.health-monitor =====


-- ===== MODULE: admin.components.admin-command-processor =====
-- File: ao-processes/admin/components/admin-command-processor.lua
-- Original require: local AdminCommandProcessor = require("admin.components.admin-command-processor")

-- Admin Command Processor Component
-- Handles execution and coordination of administrative commands across distributed processes


-- ===== MODULE: game-logic.process-coordination.message-correlator =====
-- File: ao-processes/game-logic/process-coordination/message-correlator.lua
-- Original require: local MessageCorrelator = require("game-logic.process-coordination.message-correlator")


-- ===== END MODULE: game-logic.process-coordination.message-correlator =====


-- ===== MODULE: game-logic.process-coordination.process-authenticator =====
-- File: ao-processes/game-logic/process-coordination/process-authenticator.lua
-- Original require: local ProcessAuthenticator = require("game-logic.process-coordination.process-authenticator")


-- ===== END MODULE: game-logic.process-coordination.process-authenticator =====


-- ===== MODULE: game-logic.process-coordination.message-router =====
-- File: ao-processes/game-logic/process-coordination/message-router.lua
-- Original require: local MessageRouter = require("game-logic.process-coordination.message-router")


-- ===== END MODULE: game-logic.process-coordination.message-router =====


local AdminCommandProcessor = {
    -- Active commands registry
    activeCommands = {},
    
    -- Command execution history
    commandHistory = {},
    
    -- Command execution statistics
    statistics = {
        totalCommands = 0,
        successfulCommands = 0,
        failedCommands = 0,
        rolledBackCommands = 0,
        averageExecutionTime = 0
    },
    
    -- Command types and their configurations
    COMMAND_TYPES = {
        SHUTDOWN = {
            name = "SHUTDOWN",
            requiresElevated = true,
            rollbackSupported = false,
            maxExecutionTime = 300 -- 5 minutes
        },
        RESTART = {
            name = "RESTART", 
            requiresElevated = true,
            rollbackSupported = true,
            maxExecutionTime = 600 -- 10 minutes
        },
        MAINTENANCE = {
            name = "MAINTENANCE",
            requiresElevated = true,
            rollbackSupported = true,
            maxExecutionTime = 1800 -- 30 minutes
        },
        DEPLOY = {
            name = "DEPLOY",
            requiresElevated = true,
            rollbackSupported = true,
            maxExecutionTime = 3600 -- 60 minutes
        },
        ROLLBACK = {
            name = "ROLLBACK",
            requiresElevated = true,
            rollbackSupported = false,
            maxExecutionTime = 900 -- 15 minutes
        },
        CONFIG_UPDATE = {
            name = "CONFIG_UPDATE",
            requiresElevated = false,
            rollbackSupported = true,
            maxExecutionTime = 180 -- 3 minutes
        }
    },
    
    -- Execution modes
    EXECUTION_MODES = {
        IMMEDIATE = "IMMEDIATE",
        SCHEDULED = "SCHEDULED",
        COORDINATED = "COORDINATED"
    },
    
    -- Command execution statuses
    EXECUTION_STATUS = {
        PENDING = "PENDING",
        EXECUTING = "EXECUTING",
        COMPLETED = "COMPLETED",
        FAILED = "FAILED",
        ROLLED_BACK = "ROLLED_BACK",
        TIMEOUT = "TIMEOUT"
    }
}

-- Initialize the admin command processor
function AdminCommandProcessor.initialize()
    AdminCommandProcessor.activeCommands = {}
    AdminCommandProcessor.commandHistory = {}
    AdminCommandProcessor.statistics = {
        totalCommands = 0,
        successfulCommands = 0,
        failedCommands = 0,
        rolledBackCommands = 0,
        averageExecutionTime = 0
    }
    print("[AdminCommandProcessor] Command processor initialized")
end

-- Execute administrative command
function AdminCommandProcessor.executeCommand(commandRequest)
    if not commandRequest or not commandRequest.commandType then
        return { success = false, error = "Command type is required" }
    end
    
    local commandType = commandRequest.commandType
    local commandId = commandRequest.commandId or MessageCorrelator.generateId()
    local targetProcesses = commandRequest.targetProcesses or {}
    local executionMode = commandRequest.executionMode or AdminCommandProcessor.EXECUTION_MODES.IMMEDIATE
    local commandParams = commandRequest.commandParams or {}
    local adminUserId = commandRequest.adminUserId
    
    -- Validate command type
    local commandConfig = AdminCommandProcessor.COMMAND_TYPES[commandType]
    if not commandConfig then
        return { success = false, error = "Unsupported command type: " .. commandType }
    end
    
    -- Create command execution record
    local commandRecord = {
        commandId = commandId,
        commandType = commandType,
        targetProcesses = targetProcesses,
        executionMode = executionMode,
        commandParams = commandParams,
        adminUserId = adminUserId,
        correlationId = commandRequest.correlationId,
        status = AdminCommandProcessor.EXECUTION_STATUS.PENDING,
        startTime = 0,
        executionDetails = {
            stepsCompleted = 0,
            totalSteps = #targetProcesses,
            processResults = {},
            rollbackData = {}
        },
        rollbackAvailable = commandConfig.rollbackSupported
    }
    
    -- Register active command
    AdminCommandProcessor.activeCommands[commandId] = commandRecord
    AdminCommandProcessor.statistics.totalCommands = AdminCommandProcessor.statistics.totalCommands + 1
    
    -- Execute command based on mode
    local executionResult = {}
    if executionMode == AdminCommandProcessor.EXECUTION_MODES.IMMEDIATE then
        executionResult = AdminCommandProcessor._executeImmediateCommand(commandRecord)
    elseif executionMode == AdminCommandProcessor.EXECUTION_MODES.SCHEDULED then
        executionResult = AdminCommandProcessor._scheduleCommand(commandRecord)
    elseif executionMode == AdminCommandProcessor.EXECUTION_MODES.COORDINATED then
        executionResult = AdminCommandProcessor._executeCoordinatedCommand(commandRecord)
    else
        executionResult = { success = false, error = "Unsupported execution mode: " .. executionMode }
    end
    
    -- Update command status
    if executionResult.success then
        commandRecord.status = AdminCommandProcessor.EXECUTION_STATUS.EXECUTING
        AdminCommandProcessor.statistics.successfulCommands = AdminCommandProcessor.statistics.successfulCommands + 1
    else
        commandRecord.status = AdminCommandProcessor.EXECUTION_STATUS.FAILED
        commandRecord.error = executionResult.error
        AdminCommandProcessor.statistics.failedCommands = AdminCommandProcessor.statistics.failedCommands + 1
    end
    
    print("[AdminCommandProcessor] Command '" .. commandType .. "' (" .. commandId .. ") " .. 
          (executionResult.success and "initiated" or "failed"))
    
    return {
        success = executionResult.success,
        commandId = commandId,
        status = commandRecord.status,
        affectedProcesses = targetProcesses,
        details = commandRecord.executionDetails,
        rollbackAvailable = commandRecord.rollbackAvailable,
        error = executionResult.error
    }
end

-- Get status of specific command
function AdminCommandProcessor.getCommandStatus(commandId)
    local commandRecord = AdminCommandProcessor.activeCommands[commandId]
    if not commandRecord then
        -- Check command history
        for _, historicalCommand in ipairs(AdminCommandProcessor.commandHistory) do
            if historicalCommand.commandId == commandId then
                return historicalCommand
            end
        end
        return nil
    end
    
    return {
        commandId = commandRecord.commandId,
        commandType = commandRecord.commandType,
        status = commandRecord.status,
        executionMode = commandRecord.executionMode,
        targetProcesses = commandRecord.targetProcesses,
        startTime = commandRecord.startTime,
        executionDetails = commandRecord.executionDetails,
        rollbackAvailable = commandRecord.rollbackAvailable,
        adminUserId = commandRecord.adminUserId
    }
end

-- Get all active commands
function AdminCommandProcessor.getActiveCommands()
    local activeCommandsList = {}
    for commandId, commandRecord in pairs(AdminCommandProcessor.activeCommands) do
        table.insert(activeCommandsList, {
            commandId = commandId,
            commandType = commandRecord.commandType,
            status = commandRecord.status,
            startTime = commandRecord.startTime,
            targetProcesses = commandRecord.targetProcesses,
            adminUserId = commandRecord.adminUserId
        })
    end
    return activeCommandsList
end

-- Get recent command history
function AdminCommandProcessor.getRecentCommands(limit)
    local recentCommands = {}
    local count = 0
    local maxLimit = limit or 20
    
    -- Get from command history (most recent first)
    for i = #AdminCommandProcessor.commandHistory, 1, -1 do
        if count >= maxLimit then break end
        table.insert(recentCommands, AdminCommandProcessor.commandHistory[i])
        count = count + 1
    end
    
    return recentCommands
end

-- Rollback specific command
function AdminCommandProcessor.rollbackCommand(commandId, rollbackOptions)
    local commandRecord = AdminCommandProcessor.activeCommands[commandId]
    
    -- Check if command exists and supports rollback
    if not commandRecord then
        -- Check if command is in history
        for _, historicalCommand in ipairs(AdminCommandProcessor.commandHistory) do
            if historicalCommand.commandId == commandId and historicalCommand.rollbackAvailable then
                commandRecord = historicalCommand
                break
            end
        end
    end
    
    if not commandRecord then
        return { success = false, error = "Command not found: " .. commandId }
    end
    
    if not commandRecord.rollbackAvailable then
        return { success = false, error = "Command does not support rollback: " .. commandRecord.commandType }
    end
    
    -- Create rollback command
    local rollbackCommandId = MessageCorrelator.generateId()
    local rollbackResult = AdminCommandProcessor.executeCommand({
        commandId = rollbackCommandId,
        commandType = "ROLLBACK",
        targetProcesses = commandRecord.targetProcesses,
        commandParams = {
            originalCommandId = commandId,
            rollbackData = commandRecord.executionDetails.rollbackData,
            adminUserId = rollbackOptions.adminUserId,
            reason = rollbackOptions.reason
        },
        adminUserId = rollbackOptions.adminUserId
    })
    
    if rollbackResult.success then
        -- Update original command status
        commandRecord.status = AdminCommandProcessor.EXECUTION_STATUS.ROLLED_BACK
        commandRecord.rollbackCommandId = rollbackCommandId
        commandRecord.rollbackTime = 0
        
        AdminCommandProcessor.statistics.rolledBackCommands = 
            AdminCommandProcessor.statistics.rolledBackCommands + 1
        
        print("[AdminCommandProcessor] Command '" .. commandId .. "' rolled back successfully")
        return {
            success = true,
            commandId = commandId,
            rollbackCommandId = rollbackCommandId,
            status = AdminCommandProcessor.EXECUTION_STATUS.ROLLED_BACK,
            affectedProcesses = commandRecord.targetProcesses,
            details = rollbackResult.details
        }
    else
        return {
            success = false,
            error = "Rollback execution failed: " .. (rollbackResult.error or "unknown error"),
            commandId = commandId
        }
    end
end

-- Complete command execution (called when all steps are done)
function AdminCommandProcessor.completeCommand(commandId, completionResult)
    local commandRecord = AdminCommandProcessor.activeCommands[commandId]
    if not commandRecord then
        return { success = false, error = "Command not found: " .. commandId }
    end
    
    -- Update command completion details
    commandRecord.status = completionResult.success and 
        AdminCommandProcessor.EXECUTION_STATUS.COMPLETED or 
        AdminCommandProcessor.EXECUTION_STATUS.FAILED
    commandRecord.completionTime = 0
    commandRecord.executionTime = commandRecord.completionTime - commandRecord.startTime
    commandRecord.executionDetails = completionResult.details or commandRecord.executionDetails
    
    -- Update statistics
    AdminCommandProcessor._updateExecutionTimeStatistics(commandRecord.executionTime)
    
    -- Move to history
    table.insert(AdminCommandProcessor.commandHistory, commandRecord)
    AdminCommandProcessor.activeCommands[commandId] = nil
    
    -- Keep history manageable (keep last 100 commands)
    if #AdminCommandProcessor.commandHistory > 100 then
        table.remove(AdminCommandProcessor.commandHistory, 1)
    end
    
    print("[AdminCommandProcessor] Command '" .. commandRecord.commandType .. "' (" .. commandId .. ") completed: " .. 
          commandRecord.status)
    
    return { success = true, commandStatus = commandRecord.status }
end

-- Get command processor statistics
function AdminCommandProcessor.getStatistics()
    return {
        statistics = AdminCommandProcessor.statistics,
        activeCommandCount = AdminCommandProcessor._getTableSize(AdminCommandProcessor.activeCommands),
        historyCount = #AdminCommandProcessor.commandHistory,
        supportedCommandTypes = AdminCommandProcessor.COMMAND_TYPES,
        executionModes = AdminCommandProcessor.EXECUTION_MODES
    }
end

-- Private helper functions

function AdminCommandProcessor._executeImmediateCommand(commandRecord)
    local results = {}
    
    for _, processId in ipairs(commandRecord.targetProcesses) do
        local commandMessage = {
            correlation = {
                id = commandRecord.correlationId or MessageCorrelator.generateId(),
                requestType = "ADMIN_COMMAND"
            },
            adminCommand = {
                commandType = commandRecord.commandType,
                commandId = commandRecord.commandId,
                commandParams = commandRecord.commandParams,
                executionMode = commandRecord.executionMode
            },
            processAuth = {
                sourceProcessId = "admin-process",
                adminUserId = commandRecord.adminUserId
            }
        }
        
        -- Route command to target process
        local routingResult = MessageRouter.routeMessage(
            "ADMIN_COMMAND",
            commandMessage,
            "DIRECT_ROUTE"
        )
        
        results[processId] = {
            processId = processId,
            routed = routingResult.success,
            error = routingResult.error
        }
        
        if routingResult.success then
            commandRecord.executionDetails.stepsCompleted = 
                commandRecord.executionDetails.stepsCompleted + 1
        end
    end
    
    commandRecord.executionDetails.processResults = results
    
    local successCount = 0
    for _, result in pairs(results) do
        if result.routed then
            successCount = successCount + 1
        end
    end
    
    return { 
        success = successCount == #commandRecord.targetProcesses,
        processResults = results,
        successCount = successCount,
        totalProcesses = #commandRecord.targetProcesses
    }
end

function AdminCommandProcessor._scheduleCommand(commandRecord)
    -- Placeholder for scheduled command execution
    -- This would integrate with a scheduler system
    return { success = true, scheduled = true }
end

function AdminCommandProcessor._executeCoordinatedCommand(commandRecord)
    -- Placeholder for coordinated command execution
    -- This would coordinate execution order based on dependencies
    return AdminCommandProcessor._executeImmediateCommand(commandRecord)
end

function AdminCommandProcessor._updateExecutionTimeStatistics(executionTime)
    local currentAvg = AdminCommandProcessor.statistics.averageExecutionTime
    local totalCommands = AdminCommandProcessor.statistics.totalCommands
    
    if totalCommands <= 1 then
        AdminCommandProcessor.statistics.averageExecutionTime = executionTime
    else
        AdminCommandProcessor.statistics.averageExecutionTime = 
            ((currentAvg * (totalCommands - 1)) + executionTime) / totalCommands
    end
end

function AdminCommandProcessor._getTableSize(tbl)
    local count = 0
    for _ in pairs(tbl) do
        count = count + 1
    end
    return count
end


-- ===== END MODULE: admin.components.admin-command-processor =====


-- ===== MODULE: admin.components.performance-aggregator =====
-- File: ao-processes/admin/components/performance-aggregator.lua
-- Original require: local PerformanceAggregator = require("admin.components.performance-aggregator")

-- Performance Aggregator Component
-- Collects and analyzes system-wide performance metrics across distributed processes


-- ===== MODULE: game-logic.process-coordination.message-correlator =====
-- File: ao-processes/game-logic/process-coordination/message-correlator.lua
-- Original require: local MessageCorrelator = require("game-logic.process-coordination.message-correlator")


-- ===== END MODULE: game-logic.process-coordination.message-correlator =====


-- ===== MODULE: game-logic.process-coordination.message-router =====
-- File: ao-processes/game-logic/process-coordination/message-router.lua
-- Original require: local MessageRouter = require("game-logic.process-coordination.message-router")


-- ===== END MODULE: game-logic.process-coordination.message-router =====


-- ===== MODULE: game-logic.process-coordination.performance-monitor =====
-- File: ao-processes/game-logic/process-coordination/performance-monitor.lua
-- Original require: local PerformanceMonitor = require("game-logic.process-coordination.performance-monitor")


-- ===== END MODULE: game-logic.process-coordination.performance-monitor =====


-- ===== MODULE: game-logic.process-coordination.process-authenticator =====
-- File: ao-processes/game-logic/process-coordination/process-authenticator.lua
-- Original require: local ProcessAuthenticator = require("game-logic.process-coordination.process-authenticator")


-- ===== END MODULE: game-logic.process-coordination.process-authenticator =====


local PerformanceAggregator = {
    -- Performance metrics storage
    processMetrics = {},
    
    -- System-wide performance data
    systemMetrics = {
        overallLatency = { min = 0, max = 0, avg = 0 },
        overallThroughput = 0,
        systemLoad = 0,
        totalErrors = 0,
        errorRate = 0,
        resourceUtilization = {
            cpu = { min = 0, max = 0, avg = 0 },
            memory = { min = 0, max = 0, avg = 0 }
        }
    },
    
    -- Performance history for trend analysis
    performanceHistory = {},
    
    -- Aggregation configuration
    config = {
        aggregationIntervalSeconds = 60,
        metricRetentionHours = 24,
        bottleneckThresholds = {
            latencyMs = 1000,
            throughputRps = 100,
            errorRate = 0.05,
            cpuUsage = 80,
            memoryUsage = 85
        },
        trendAnalysisWindow = 3600 -- 1 hour
    },
    
    -- Performance statistics
    statistics = {
        totalMetricCollections = 0,
        lastCollectionTime = 0,
        metricsCollectedCount = 0,
        bottlenecksDetected = 0,
        trendsAnalyzed = 0
    },
    
    -- Performance status levels
    PERFORMANCE_STATUS = {
        OPTIMAL = "OPTIMAL",
        GOOD = "GOOD",
        DEGRADED = "DEGRADED",
        POOR = "POOR",
        CRITICAL = "CRITICAL"
    }
}

-- Initialize performance aggregation system
function PerformanceAggregator.initialize()
    PerformanceAggregator.processMetrics = {}
    PerformanceAggregator.performanceHistory = {}
    PerformanceAggregator.statistics = {
        totalMetricCollections = 0,
        lastCollectionTime = 0,
        metricsCollectedCount = 0,
        bottlenecksDetected = 0,
        trendsAnalyzed = 0
    }
    PerformanceAggregator.systemMetrics = {
        overallLatency = { min = 0, max = 0, avg = 0 },
        overallThroughput = 0,
        systemLoad = 0,
        totalErrors = 0,
        errorRate = 0,
        resourceUtilization = {
            cpu = { min = 0, max = 0, avg = 0 },
            memory = { min = 0, max = 0, avg = 0 }
        }
    }
    print("[PerformanceAggregator] Performance aggregation system initialized")
end

-- Collect performance metrics from all processes
function PerformanceAggregator.collectSystemMetrics()
    local collectionStartTime = 0
    local collectionResults = {
        timestamp = collectionStartTime,
        status = PerformanceAggregator.PERFORMANCE_STATUS.OPTIMAL,
        processMetrics = {},
        systemSummary = {},
        bottlenecks = {},
        errors = {}
    }
    
    -- Get process registry from ProcessAuthenticator to know which processes to query
    local processRegistry = ProcessAuthenticator.processRegistry or {}
    
    for processId, processInfo in pairs(processRegistry) do
        if processInfo.status == "active" then
            local metricsResult = PerformanceAggregator._collectProcessMetrics(processId)
            
            if metricsResult.success then
                PerformanceAggregator.processMetrics[processId] = metricsResult.metrics
                collectionResults.processMetrics[processId] = metricsResult.metrics
                PerformanceAggregator.statistics.metricsCollectedCount = 
                    PerformanceAggregator.statistics.metricsCollectedCount + 1
            else
                table.insert(collectionResults.errors, {
                    processId = processId,
                    error = metricsResult.error
                })
            end
        end
    end
    
    -- Aggregate system-wide metrics
    collectionResults.systemSummary = PerformanceAggregator._aggregateSystemMetrics()
    
    -- Detect performance bottlenecks
    collectionResults.bottlenecks = PerformanceAggregator.identifyBottlenecks()
    
    -- Determine overall system performance status
    collectionResults.status = PerformanceAggregator._determineSystemPerformanceStatus(collectionResults)
    
    -- Record performance history
    PerformanceAggregator._recordPerformanceHistory(collectionResults)
    
    -- Update statistics
    PerformanceAggregator.statistics.totalMetricCollections = 
        PerformanceAggregator.statistics.totalMetricCollections + 1
    PerformanceAggregator.statistics.lastCollectionTime = collectionStartTime
    
    if #collectionResults.bottlenecks > 0 then
        PerformanceAggregator.statistics.bottlenecksDetected = 
            PerformanceAggregator.statistics.bottlenecksDetected + #collectionResults.bottlenecks
    end
    
    print("[PerformanceAggregator] System metrics collection completed - Status: " .. 
          collectionResults.status .. " (" .. 
          PerformanceAggregator._getTableSize(collectionResults.processMetrics) .. " processes)")
    
    return collectionResults
end

-- Get performance metrics for specific process
function PerformanceAggregator.getProcessMetrics(processId, metricType, timeRange)
    local processMetrics = PerformanceAggregator.processMetrics[processId]
    if not processMetrics then
        return nil
    end
    
    local result = {
        processId = processId,
        currentMetrics = processMetrics,
        metricType = metricType or "ALL",
        timeRange = timeRange
    }
    
    -- Filter metrics by type if specified
    if metricType and metricType ~= "ALL" then
        result.filteredMetrics = PerformanceAggregator._filterMetricsByType(processMetrics, metricType)
    end
    
    -- Get historical data if time range is specified
    if timeRange then
        result.historicalMetrics = PerformanceAggregator._getHistoricalMetrics(processId, timeRange)
    end
    
    return result
end

-- Get system-wide performance metrics
function PerformanceAggregator.getSystemMetrics(metricType, timeRange)
    local systemMetrics = {
        timestamp = msg.Timestamp,
        systemMetrics = PerformanceAggregator.systemMetrics,
        metricType = metricType or "ALL",
        processCount = PerformanceAggregator._getTableSize(PerformanceAggregator.processMetrics),
        collectionStatistics = PerformanceAggregator.statistics
    }
    
    -- Include historical data if time range specified
    if timeRange then
        systemMetrics.historicalData = PerformanceAggregator._getSystemHistoricalMetrics(timeRange)
        systemMetrics.trends = PerformanceAggregator.getTrendAnalysis(timeRange)
    end
    
    return systemMetrics
end

-- Identify performance bottlenecks across the system
function PerformanceAggregator.identifyBottlenecks()
    local bottlenecks = {}
    local thresholds = PerformanceAggregator.config.bottleneckThresholds
    
    -- Check system-wide bottlenecks
    if PerformanceAggregator.systemMetrics.overallLatency.avg > thresholds.latencyMs then
        table.insert(bottlenecks, {
            type = "SYSTEM_LATENCY",
            severity = "HIGH",
            metric = "Average Latency",
            value = PerformanceAggregator.systemMetrics.overallLatency.avg,
            threshold = thresholds.latencyMs,
            impact = "System response times are above acceptable limits"
        })
    end
    
    if PerformanceAggregator.systemMetrics.overallThroughput < thresholds.throughputRps then
        table.insert(bottlenecks, {
            type = "SYSTEM_THROUGHPUT",
            severity = "MEDIUM",
            metric = "System Throughput",
            value = PerformanceAggregator.systemMetrics.overallThroughput,
            threshold = thresholds.throughputRps,
            impact = "System throughput is below expected levels"
        })
    end
    
    if PerformanceAggregator.systemMetrics.errorRate > thresholds.errorRate then
        table.insert(bottlenecks, {
            type = "SYSTEM_ERROR_RATE",
            severity = "CRITICAL",
            metric = "Error Rate",
            value = PerformanceAggregator.systemMetrics.errorRate,
            threshold = thresholds.errorRate,
            impact = "System error rate exceeds acceptable limits"
        })
    end
    
    -- Check individual process bottlenecks
    for processId, metrics in pairs(PerformanceAggregator.processMetrics) do
        if metrics.resourceUsage then
            if metrics.resourceUsage.cpuUsage > thresholds.cpuUsage then
                table.insert(bottlenecks, {
                    type = "PROCESS_CPU",
                    severity = "HIGH",
                    processId = processId,
                    metric = "CPU Usage",
                    value = metrics.resourceUsage.cpuUsage,
                    threshold = thresholds.cpuUsage,
                    impact = "Process CPU usage is critically high"
                })
            end
            
            if metrics.resourceUsage.memoryUsage > thresholds.memoryUsage then
                table.insert(bottlenecks, {
                    type = "PROCESS_MEMORY",
                    severity = "HIGH",
                    processId = processId,
                    metric = "Memory Usage",
                    value = metrics.resourceUsage.memoryUsage,
                    threshold = thresholds.memoryUsage,
                    impact = "Process memory usage is critically high"
                })
            end
        end
    end
    
    return bottlenecks
end

-- Perform trend analysis on performance metrics
function PerformanceAggregator.getTrendAnalysis(timeRange)
    local analysisWindow = timeRange or PerformanceAggregator.config.trendAnalysisWindow
    local currentTime = 0
    local startTime = currentTime - analysisWindow
    
    local trends = {
        timestamp = currentTime,
        analysisWindow = analysisWindow,
        latencyTrend = "STABLE",
        throughputTrend = "STABLE", 
        errorRateTrend = "STABLE",
        resourceUtilizationTrend = "STABLE",
        predictions = {},
        recommendations = {}
    }
    
    -- Analyze historical data for trends
    local relevantHistory = PerformanceAggregator._getHistoryInTimeRange(startTime, currentTime)
    
    if #relevantHistory >= 3 then
        -- Analyze latency trend
        trends.latencyTrend = PerformanceAggregator._analyzeTrend(relevantHistory, "latency")
        
        -- Analyze throughput trend
        trends.throughputTrend = PerformanceAggregator._analyzeTrend(relevantHistory, "throughput")
        
        -- Analyze error rate trend
        trends.errorRateTrend = PerformanceAggregator._analyzeTrend(relevantHistory, "errorRate")
        
        -- Generate predictions and recommendations
        trends.predictions = PerformanceAggregator._generatePredictions(relevantHistory)
        trends.recommendations = PerformanceAggregator._generateRecommendations(trends)
    end
    
    PerformanceAggregator.statistics.trendsAnalyzed = 
        PerformanceAggregator.statistics.trendsAnalyzed + 1
    
    return trends
end

-- Get optimization recommendations based on performance data
function PerformanceAggregator.getOptimizationRecommendations()
    local recommendations = {}
    local bottlenecks = PerformanceAggregator.identifyBottlenecks()
    
    for _, bottleneck in ipairs(bottlenecks) do
        if bottleneck.type == "SYSTEM_LATENCY" then
            table.insert(recommendations, {
                type = "OPTIMIZATION",
                priority = "HIGH",
                recommendation = "Consider load balancing optimization or process scaling",
                rationale = "High system latency detected",
                estimatedImpact = "20-40% latency reduction"
            })
        elseif bottleneck.type == "PROCESS_CPU" then
            table.insert(recommendations, {
                type = "RESOURCE",
                priority = "HIGH", 
                processId = bottleneck.processId,
                recommendation = "Scale process resources or optimize CPU-intensive operations",
                rationale = "High CPU usage in process: " .. bottleneck.processId,
                estimatedImpact = "Prevent process throttling and improve response times"
            })
        elseif bottleneck.type == "SYSTEM_ERROR_RATE" then
            table.insert(recommendations, {
                type = "RELIABILITY",
                priority = "CRITICAL",
                recommendation = "Investigate error sources and implement error handling improvements",
                rationale = "Elevated system error rate detected",
                estimatedImpact = "Improve system reliability and user experience"
            })
        end
    end
    
    return recommendations
end

-- Get system performance status
function PerformanceAggregator.getSystemPerformanceStatus()
    local latencyStatus = PerformanceAggregator._getLatencyStatus()
    local throughputStatus = PerformanceAggregator._getThroughputStatus()
    local errorRateStatus = PerformanceAggregator._getErrorRateStatus()
    
    -- Determine overall status (worst case)
    local statusLevels = {
        [PerformanceAggregator.PERFORMANCE_STATUS.CRITICAL] = 5,
        [PerformanceAggregator.PERFORMANCE_STATUS.POOR] = 4,
        [PerformanceAggregator.PERFORMANCE_STATUS.DEGRADED] = 3,
        [PerformanceAggregator.PERFORMANCE_STATUS.GOOD] = 2,
        [PerformanceAggregator.PERFORMANCE_STATUS.OPTIMAL] = 1
    }
    
    local worstStatus = PerformanceAggregator.PERFORMANCE_STATUS.OPTIMAL
    local worstLevel = 1
    
    for _, status in ipairs({latencyStatus, throughputStatus, errorRateStatus}) do
        if statusLevels[status] > worstLevel then
            worstStatus = status
            worstLevel = statusLevels[status]
        end
    end
    
    return worstStatus
end

-- Update performance thresholds
function PerformanceAggregator.updateThresholds(newThresholds)
    if not newThresholds or type(newThresholds) ~= "table" then
        return { success = false, error = "Invalid threshold configuration" }
    end
    
    for key, value in pairs(newThresholds) do
        if PerformanceAggregator.config.bottleneckThresholds[key] then
            PerformanceAggregator.config.bottleneckThresholds[key] = value
        end
    end
    
    print("[PerformanceAggregator] Performance thresholds updated")
    return { success = true, thresholds = PerformanceAggregator.config.bottleneckThresholds }
end

-- Get performance aggregation statistics
function PerformanceAggregator.getStatistics()
    return {
        statistics = PerformanceAggregator.statistics,
        configuration = PerformanceAggregator.config,
        systemMetrics = PerformanceAggregator.systemMetrics,
        monitoredProcessCount = PerformanceAggregator._getTableSize(PerformanceAggregator.processMetrics),
        historyLength = #PerformanceAggregator.performanceHistory
    }
end

-- Private helper functions

function PerformanceAggregator._collectProcessMetrics(processId)
    -- This would send a performance query to the specific process
    local performanceQuery = {
        correlation = {
            id = MessageCorrelator.generateId(),
            requestType = "PERFORMANCE_QUERY"
        },
        performanceQuery = {
            queryType = "CURRENT_METRICS",
            includeResourceUsage = true,
            includeLatencyMetrics = true
        }
    }
    
    local routingResult = MessageRouter.routeMessage(
        "PERFORMANCE_QUERY",
        performanceQuery,
        "DIRECT_ROUTE"
    )
    
    if routingResult.success then
        -- In a real implementation, this would wait for and process the response
        -- For now, we'll return placeholder metrics
        return {
            success = true,
            metrics = {
                latency = { min = 10, max = 100, avg = 50 },
                throughput = 150,
                errorRate = 0.02,
                resourceUsage = {
                    cpuUsage = 45,
                    memoryUsage = 60
                },
                timestamp = 0
            }
        }
    else
        return { success = false, error = routingResult.error }
    end
end

function PerformanceAggregator._aggregateSystemMetrics()
    local aggregatedMetrics = {
        timestamp = msg.Timestamp,
        processCount = PerformanceAggregator._getTableSize(PerformanceAggregator.processMetrics),
        totalLatencies = {},
        totalThroughput = 0,
        totalErrors = 0,
        resourceUsageSummary = {
            cpuUsages = {},
            memoryUsages = {}
        }
    }
    
    -- Aggregate metrics from all processes
    for processId, metrics in pairs(PerformanceAggregator.processMetrics) do
        if metrics.latency then
            table.insert(aggregatedMetrics.totalLatencies, metrics.latency.avg)
        end
        
        if metrics.throughput then
            aggregatedMetrics.totalThroughput = aggregatedMetrics.totalThroughput + metrics.throughput
        end
        
        if metrics.errorRate then
            aggregatedMetrics.totalErrors = aggregatedMetrics.totalErrors + metrics.errorRate
        end
        
        if metrics.resourceUsage then
            table.insert(aggregatedMetrics.resourceUsageSummary.cpuUsages, metrics.resourceUsage.cpuUsage)
            table.insert(aggregatedMetrics.resourceUsageSummary.memoryUsages, metrics.resourceUsage.memoryUsage)
        end
    end
    
    -- Calculate system-wide averages
    if #aggregatedMetrics.totalLatencies > 0 then
        PerformanceAggregator.systemMetrics.overallLatency = 
            PerformanceAggregator._calculateMinMaxAvg(aggregatedMetrics.totalLatencies)
    end
    
    PerformanceAggregator.systemMetrics.overallThroughput = aggregatedMetrics.totalThroughput
    PerformanceAggregator.systemMetrics.errorRate = 
        aggregatedMetrics.processCount > 0 and (aggregatedMetrics.totalErrors / aggregatedMetrics.processCount) or 0
    
    if #aggregatedMetrics.resourceUsageSummary.cpuUsages > 0 then
        PerformanceAggregator.systemMetrics.resourceUtilization.cpu = 
            PerformanceAggregator._calculateMinMaxAvg(aggregatedMetrics.resourceUsageSummary.cpuUsages)
    end
    
    if #aggregatedMetrics.resourceUsageSummary.memoryUsages > 0 then
        PerformanceAggregator.systemMetrics.resourceUtilization.memory = 
            PerformanceAggregator._calculateMinMaxAvg(aggregatedMetrics.resourceUsageSummary.memoryUsages)
    end
    
    return PerformanceAggregator.systemMetrics
end

function PerformanceAggregator._determineSystemPerformanceStatus(collectionResults)
    local bottleneckCount = #collectionResults.bottlenecks
    local errorCount = #collectionResults.errors
    local processCount = PerformanceAggregator._getTableSize(collectionResults.processMetrics)
    
    if errorCount > processCount * 0.5 or bottleneckCount >= 3 then
        return PerformanceAggregator.PERFORMANCE_STATUS.CRITICAL
    elseif errorCount > processCount * 0.25 or bottleneckCount >= 2 then
        return PerformanceAggregator.PERFORMANCE_STATUS.POOR
    elseif bottleneckCount >= 1 then
        return PerformanceAggregator.PERFORMANCE_STATUS.DEGRADED
    elseif errorCount == 0 and bottleneckCount == 0 then
        return PerformanceAggregator.PERFORMANCE_STATUS.OPTIMAL
    else
        return PerformanceAggregator.PERFORMANCE_STATUS.GOOD
    end
end

function PerformanceAggregator._recordPerformanceHistory(collectionResults)
    table.insert(PerformanceAggregator.performanceHistory, {
        timestamp = collectionResults.timestamp,
        status = collectionResults.status,
        systemMetrics = PerformanceAggregator.systemMetrics,
        bottleneckCount = #collectionResults.bottlenecks,
        processCount = PerformanceAggregator._getTableSize(collectionResults.processMetrics)
    })
    
    -- Maintain history size (keep last 24 hours worth)
    local maxHistoryEntries = PerformanceAggregator.config.metricRetentionHours
    if #PerformanceAggregator.performanceHistory > maxHistoryEntries then
        table.remove(PerformanceAggregator.performanceHistory, 1)
    end
end

function PerformanceAggregator._calculateMinMaxAvg(values)
    if #values == 0 then
        return { min = 0, max = 0, avg = 0 }
    end
    
    local min = values[1]
    local max = values[1] 
    local sum = 0
    
    for _, value in ipairs(values) do
        if value < min then min = value end
        if value > max then max = value end
        sum = sum + value
    end
    
    return {
        min = min,
        max = max,
        avg = sum / #values
    }
end

function PerformanceAggregator._getTableSize(tbl)
    local count = 0
    for _ in pairs(tbl) do
        count = count + 1
    end
    return count
end

function PerformanceAggregator._getLatencyStatus()
    local avgLatency = PerformanceAggregator.systemMetrics.overallLatency.avg
    local threshold = PerformanceAggregator.config.bottleneckThresholds.latencyMs
    
    if avgLatency > threshold * 2 then
        return PerformanceAggregator.PERFORMANCE_STATUS.CRITICAL
    elseif avgLatency > threshold then
        return PerformanceAggregator.PERFORMANCE_STATUS.POOR
    elseif avgLatency > threshold * 0.7 then
        return PerformanceAggregator.PERFORMANCE_STATUS.DEGRADED
    else
        return PerformanceAggregator.PERFORMANCE_STATUS.OPTIMAL
    end
end

function PerformanceAggregator._getThroughputStatus()
    local throughput = PerformanceAggregator.systemMetrics.overallThroughput
    local threshold = PerformanceAggregator.config.bottleneckThresholds.throughputRps
    
    if throughput < threshold * 0.5 then
        return PerformanceAggregator.PERFORMANCE_STATUS.CRITICAL
    elseif throughput < threshold then
        return PerformanceAggregator.PERFORMANCE_STATUS.DEGRADED
    else
        return PerformanceAggregator.PERFORMANCE_STATUS.OPTIMAL
    end
end

function PerformanceAggregator._getErrorRateStatus()
    local errorRate = PerformanceAggregator.systemMetrics.errorRate
    local threshold = PerformanceAggregator.config.bottleneckThresholds.errorRate
    
    if errorRate > threshold * 2 then
        return PerformanceAggregator.PERFORMANCE_STATUS.CRITICAL
    elseif errorRate > threshold then
        return PerformanceAggregator.PERFORMANCE_STATUS.POOR
    elseif errorRate > threshold * 0.5 then
        return PerformanceAggregator.PERFORMANCE_STATUS.DEGRADED
    else
        return PerformanceAggregator.PERFORMANCE_STATUS.OPTIMAL
    end
end

function PerformanceAggregator._filterMetricsByType(metrics, metricType)
    -- Placeholder implementation for metric filtering
    return metrics
end

function PerformanceAggregator._getHistoricalMetrics(processId, timeRange)
    -- Placeholder implementation for historical metrics
    return {}
end

function PerformanceAggregator._getSystemHistoricalMetrics(timeRange)
    -- Placeholder implementation for system historical metrics
    return {}
end

function PerformanceAggregator._getHistoryInTimeRange(startTime, endTime)
    local relevantHistory = {}
    
    for _, entry in ipairs(PerformanceAggregator.performanceHistory) do
        if entry.timestamp >= startTime and entry.timestamp <= endTime then
            table.insert(relevantHistory, entry)
        end
    end
    
    return relevantHistory
end

function PerformanceAggregator._analyzeTrend(history, metricType)
    -- Simple trend analysis implementation
    if #history < 3 then
        return "INSUFFICIENT_DATA"
    end
    
    -- For simplicity, compare first and last values
    local firstValue = history[1].systemMetrics.overallLatency.avg
    local lastValue = history[#history].systemMetrics.overallLatency.avg
    
    local percentageChange = ((lastValue - firstValue) / firstValue) * 100
    
    if percentageChange > 10 then
        return "INCREASING"
    elseif percentageChange < -10 then
        return "DECREASING" 
    else
        return "STABLE"
    end
end

function PerformanceAggregator._generatePredictions(history)
    -- Placeholder for prediction algorithms
    return {
        "Performance levels expected to remain stable",
        "No significant trends detected in current window"
    }
end

function PerformanceAggregator._generateRecommendations(trends)
    local recommendations = {}
    
    if trends.latencyTrend == "INCREASING" then
        table.insert(recommendations, "Consider load balancing optimization")
    end
    
    if trends.errorRateTrend == "INCREASING" then
        table.insert(recommendations, "Investigate error sources and improve error handling")
    end
    
    return recommendations
end


-- ===== END MODULE: admin.components.performance-aggregator =====


-- ===== MODULE: admin.components.log-aggregator =====
-- File: ao-processes/admin/components/log-aggregator.lua
-- Original require: local LogAggregator = require("admin.components.log-aggregator")

-- Log Aggregator Component
-- Provides centralized logging collection, correlation, and analysis across distributed processes


-- ===== MODULE: game-logic.process-coordination.message-correlator =====
-- File: ao-processes/game-logic/process-coordination/message-correlator.lua
-- Original require: local MessageCorrelator = require("game-logic.process-coordination.message-correlator")


-- ===== END MODULE: game-logic.process-coordination.message-correlator =====


local LogAggregator = {
    -- Centralized log storage
    logEntries = {},
    
    -- Log streaming subscriptions
    streamSubscriptions = {},
    
    -- Log correlation tracking
    correlationMap = {},
    
    -- Aggregation configuration
    config = {
        maxLogEntries = 10000,
        logRetentionHours = 48,
        correlationTimeWindow = 3600, -- 1 hour
        streamBufferSize = 100,
        autoArchiveEnabled = true,
        compressionEnabled = true
    },
    
    -- Log levels
    LOG_LEVELS = {
        TRACE = 0,
        DEBUG = 1,
        INFO = 2,
        WARN = 3,
        ERROR = 4,
        FATAL = 5
    },
    
    -- Aggregation statistics
    statistics = {
        totalLogsCollected = 0,
        logsByLevel = {
            TRACE = 0,
            DEBUG = 0,
            INFO = 0,
            WARN = 0,
            ERROR = 0,
            FATAL = 0
        },
        correlatedLogs = 0,
        streamingSubscribers = 0,
        lastLogTime = 0,
        archivedLogCount = 0
    }
}

-- Initialize log aggregation system
function LogAggregator.initialize()
    LogAggregator.logEntries = {}
    LogAggregator.streamSubscriptions = {}
    LogAggregator.correlationMap = {}
    LogAggregator.statistics = {
        totalLogsCollected = 0,
        logsByLevel = {
            TRACE = 0,
            DEBUG = 0,
            INFO = 0,
            WARN = 0,
            ERROR = 0,
            FATAL = 0
        },
        correlatedLogs = 0,
        streamingSubscribers = 0,
        lastLogTime = 0,
        archivedLogCount = 0
    }
    print("[LogAggregator] Log aggregation system initialized")
end

-- Log an event to the aggregated log system
function LogAggregator.logEvent(logEvent)
    if not logEvent or not logEvent.message then
        return { success = false, error = "Log message is required" }
    end
    
    local timestamp = 0
    local logEntry = {
        id = MessageCorrelator.generateId(),
        timestamp = timestamp,
        level = logEvent.level or "INFO",
        component = logEvent.component or "UNKNOWN",
        processId = logEvent.processId or "admin-process",
        message = logEvent.message,
        correlationId = logEvent.correlationId,
        adminUserId = logEvent.adminUserId,
        metadata = logEvent.metadata or {},
        context = logEvent.context or {}
    }
    
    -- Add to log storage
    table.insert(LogAggregator.logEntries, logEntry)
    
    -- Update statistics
    LogAggregator.statistics.totalLogsCollected = LogAggregator.statistics.totalLogsCollected + 1
    LogAggregator.statistics.logsByLevel[logEntry.level] = 
        (LogAggregator.statistics.logsByLevel[logEntry.level] or 0) + 1
    LogAggregator.statistics.lastLogTime = timestamp
    
    -- Handle correlation tracking
    if logEvent.correlationId then
        LogAggregator._trackLogCorrelation(logEntry)
    end
    
    -- Stream to subscribers
    LogAggregator._streamLogToSubscribers(logEntry)
    
    -- Manage log storage size
    LogAggregator._manageLogSize()
    
    return { success = true, logId = logEntry.id }
end

-- Get recent logs with optional filtering
function LogAggregator.getRecentLogs(limit, filters)
    local maxLimit = limit or 100
    local recentLogs = {}
    local count = 0
    
    -- Iterate through logs in reverse order (most recent first)
    for i = #LogAggregator.logEntries, 1, -1 do
        if count >= maxLimit then break end
        
        local logEntry = LogAggregator.logEntries[i]
        
        -- Apply filters
        if LogAggregator._matchesFilters(logEntry, filters) then
            table.insert(recentLogs, logEntry)
            count = count + 1
        end
    end
    
    return recentLogs
end

-- Get correlated logs based on correlation ID
function LogAggregator.getCorrelatedLogs(correlationId, options)
    local correlatedLogs = {}
    local includeChildren = options and options.includeChildren or false
    local timeRange = options and options.timeRange
    
    -- Direct correlation lookup
    local directLogs = LogAggregator.correlationMap[correlationId] or {}
    
    for _, logEntry in ipairs(directLogs) do
        if LogAggregator._inTimeRange(logEntry.timestamp, timeRange) then
            table.insert(correlatedLogs, logEntry)
        end
    end
    
    -- Include child correlations if requested
    if includeChildren then
        local childCorrelations = LogAggregator._findChildCorrelations(correlationId)
        for _, childId in ipairs(childCorrelations) do
            local childLogs = LogAggregator.correlationMap[childId] or {}
            for _, logEntry in ipairs(childLogs) do
                if LogAggregator._inTimeRange(logEntry.timestamp, timeRange) then
                    table.insert(correlatedLogs, logEntry)
                end
            end
        end
    end
    
    -- Sort by timestamp
    table.sort(correlatedLogs, function(a, b) return a.timestamp < b.timestamp end)
    
    return correlatedLogs
end

-- Get error logs with optional filtering
function LogAggregator.getErrorLogs(limit, filters)
    local errorFilters = filters or {}
    errorFilters.logLevel = "ERROR,FATAL"
    
    return LogAggregator.getRecentLogs(limit, errorFilters)
end

-- Search logs by message content
function LogAggregator.searchLogs(searchQuery, options)
    local matchingLogs = {}
    local caseSensitive = options and options.caseSensitive or false
    local timeRange = options and options.timeRange
    local limit = options and options.limit or 100
    local count = 0
    
    local searchTerm = caseSensitive and searchQuery or string.lower(searchQuery)
    
    for i = #LogAggregator.logEntries, 1, -1 do
        if count >= limit then break end
        
        local logEntry = LogAggregator.logEntries[i]
        local messageToSearch = caseSensitive and logEntry.message or string.lower(logEntry.message)
        
        if string.find(messageToSearch, searchTerm, 1, true) and 
           LogAggregator._inTimeRange(logEntry.timestamp, timeRange) then
            table.insert(matchingLogs, logEntry)
            count = count + 1
        end
    end
    
    return matchingLogs
end

-- Subscribe to log streaming
function LogAggregator.subscribeToLogStream(streamConfig)
    if not streamConfig or not streamConfig.subscriberId then
        return { success = false, error = "Subscriber ID is required" }
    end
    
    local subscriptionId = MessageCorrelator.generateId()
    local subscription = {
        subscriptionId = subscriptionId,
        subscriberId = streamConfig.subscriberId,
        logLevel = streamConfig.logLevel,
        component = streamConfig.component,
        processId = streamConfig.processId,
        includeCorrelation = streamConfig.includeCorrelation or false,
        bufferSize = streamConfig.bufferSize or LogAggregator.config.streamBufferSize,
        buffer = {},
        subscribedAt = 0
    }
    
    LogAggregator.streamSubscriptions[streamConfig.subscriberId] = subscription
    LogAggregator.statistics.streamingSubscribers = 
        LogAggregator._getTableSize(LogAggregator.streamSubscriptions)
    
    print("[LogAggregator] Log stream subscription created for " .. streamConfig.subscriberId)
    return { success = true, subscriptionId = subscriptionId }
end

-- Unsubscribe from log streaming
function LogAggregator.unsubscribeFromLogStream(subscriberId)
    if LogAggregator.streamSubscriptions[subscriberId] then
        LogAggregator.streamSubscriptions[subscriberId] = nil
        LogAggregator.statistics.streamingSubscribers = 
            LogAggregator._getTableSize(LogAggregator.streamSubscriptions)
        
        print("[LogAggregator] Log stream subscription removed for " .. subscriberId)
        return { success = true }
    else
        return { success = false, error = "Subscription not found" }
    end
end

-- Get stream status for subscriber
function LogAggregator.getStreamStatus(subscriberId)
    local subscription = LogAggregator.streamSubscriptions[subscriberId]
    if not subscription then
        return { subscribed = false }
    end
    
    return {
        subscribed = true,
        subscriptionId = subscription.subscriptionId,
        subscribedAt = subscription.subscribedAt,
        bufferSize = #subscription.buffer,
        maxBufferSize = subscription.bufferSize,
        logLevel = subscription.logLevel,
        component = subscription.component
    }
end

-- Perform trend analysis on logs
function LogAggregator.performTrendAnalysis(analysisOptions)
    local timeRange = analysisOptions and analysisOptions.timeRange
    local processId = analysisOptions and analysisOptions.processId
    local metricTypes = analysisOptions and analysisOptions.metricTypes or {"ERROR_RATE", "LOG_VOLUME"}
    
    local analysis = {
        timestamp = msg.Timestamp,
        timeRange = timeRange,
        processId = processId,
        metrics = {}
    }
    
    for _, metricType in ipairs(metricTypes) do
        if metricType == "ERROR_RATE" then
            analysis.metrics.errorRate = LogAggregator._analyzeErrorRate(timeRange, processId)
        elseif metricType == "LOG_VOLUME" then
            analysis.metrics.logVolume = LogAggregator._analyzeLogVolume(timeRange, processId)
        elseif metricType == "COMPONENT_ACTIVITY" then
            analysis.metrics.componentActivity = LogAggregator._analyzeComponentActivity(timeRange, processId)
        end
    end
    
    return analysis
end

-- Perform error analysis
function LogAggregator.performErrorAnalysis(analysisOptions)
    local timeRange = analysisOptions and analysisOptions.timeRange
    local processId = analysisOptions and analysisOptions.processId
    local groupByError = analysisOptions and analysisOptions.groupByError or false
    
    local errorLogs = LogAggregator.getErrorLogs(1000, {
        timeRange = timeRange,
        processId = processId
    })
    
    local analysis = {
        timestamp = msg.Timestamp,
        timeRange = timeRange,
        processId = processId,
        totalErrors = #errorLogs,
        errorsByComponent = {},
        errorsByType = {},
        errorTimeline = {}
    }
    
    -- Analyze error distribution
    for _, logEntry in ipairs(errorLogs) do
        -- Count by component
        local component = logEntry.component or "UNKNOWN"
        analysis.errorsByComponent[component] = (analysis.errorsByComponent[component] or 0) + 1
        
        -- Group by error type if requested
        if groupByError then
            local errorType = LogAggregator._extractErrorType(logEntry.message)
            analysis.errorsByType[errorType] = (analysis.errorsByType[errorType] or 0) + 1
        end
        
        -- Build error timeline
        local timeWindow = math.floor(logEntry.timestamp / 300) * 300 -- 5-minute windows
        analysis.errorTimeline[timeWindow] = (analysis.errorTimeline[timeWindow] or 0) + 1
    end
    
    return analysis
end

-- Perform performance analysis based on logs
function LogAggregator.performPerformanceAnalysis(analysisOptions)
    local timeRange = analysisOptions and analysisOptions.timeRange
    local processId = analysisOptions and analysisOptions.processId
    
    local performanceLogs = LogAggregator.getRecentLogs(5000, {
        timeRange = timeRange,
        processId = processId,
        component = "PERFORMANCE"
    })
    
    local analysis = {
        timestamp = msg.Timestamp,
        timeRange = timeRange,
        processId = processId,
        performanceMetrics = {
            averageResponseTime = 0,
            maxResponseTime = 0,
            minResponseTime = 999999,
            totalOperations = 0
        },
        slowOperations = {},
        performanceTrends = {}
    }
    
    -- Analyze performance metrics from logs
    local responseTimes = {}
    
    for _, logEntry in ipairs(performanceLogs) do
        -- Extract performance data from log metadata
        if logEntry.metadata and logEntry.metadata.responseTime then
            local responseTime = logEntry.metadata.responseTime
            table.insert(responseTimes, responseTime)
            
            if responseTime > analysis.performanceMetrics.maxResponseTime then
                analysis.performanceMetrics.maxResponseTime = responseTime
            end
            if responseTime < analysis.performanceMetrics.minResponseTime then
                analysis.performanceMetrics.minResponseTime = responseTime
            end
            
            -- Track slow operations
            if responseTime > 1000 then -- > 1 second
                table.insert(analysis.slowOperations, {
                    timestamp = logEntry.timestamp,
                    operation = logEntry.metadata.operation,
                    responseTime = responseTime,
                    processId = logEntry.processId
                })
            end
        end
    end
    
    -- Calculate average
    if #responseTimes > 0 then
        local sum = 0
        for _, time in ipairs(responseTimes) do
            sum = sum + time
        end
        analysis.performanceMetrics.averageResponseTime = sum / #responseTimes
        analysis.performanceMetrics.totalOperations = #responseTimes
    end
    
    return analysis
end

-- Perform correlation analysis
function LogAggregator.performCorrelationAnalysis(analysisOptions)
    local correlationId = analysisOptions.correlationId
    local timeRange = analysisOptions and analysisOptions.timeRange
    
    if not correlationId then
        return { success = false, error = "Correlation ID is required" }
    end
    
    local correlatedLogs = LogAggregator.getCorrelatedLogs(correlationId, {
        timeRange = timeRange,
        includeChildren = true
    })
    
    local analysis = {
        timestamp = msg.Timestamp,
        correlationId = correlationId,
        timeRange = timeRange,
        totalCorrelatedLogs = #correlatedLogs,
        logsByLevel = {},
        logsByComponent = {},
        timeline = {},
        correlationFlow = {}
    }
    
    -- Analyze correlated logs
    for _, logEntry in ipairs(correlatedLogs) do
        -- Count by level
        local level = logEntry.level
        analysis.logsByLevel[level] = (analysis.logsByLevel[level] or 0) + 1
        
        -- Count by component
        local component = logEntry.component
        analysis.logsByComponent[component] = (analysis.logsByComponent[component] or 0) + 1
        
        -- Build timeline
        local timeWindow = math.floor(logEntry.timestamp / 60) * 60 -- 1-minute windows
        if not analysis.timeline[timeWindow] then
            analysis.timeline[timeWindow] = 0
        end
        analysis.timeline[timeWindow] = analysis.timeline[timeWindow] + 1
        
        -- Build correlation flow
        table.insert(analysis.correlationFlow, {
            timestamp = logEntry.timestamp,
            component = logEntry.component,
            processId = logEntry.processId,
            level = logEntry.level,
            message = logEntry.message
        })
    end
    
    return analysis
end

-- Update log retention policy
function LogAggregator.updateRetentionPolicy(retentionPolicy)
    if not retentionPolicy or type(retentionPolicy) ~= "table" then
        return { success = false, error = "Invalid retention policy" }
    end
    
    if retentionPolicy.maxLogEntries then
        LogAggregator.config.maxLogEntries = retentionPolicy.maxLogEntries
    end
    
    if retentionPolicy.logRetentionHours then
        LogAggregator.config.logRetentionHours = retentionPolicy.logRetentionHours
    end
    
    if retentionPolicy.autoArchiveEnabled ~= nil then
        LogAggregator.config.autoArchiveEnabled = retentionPolicy.autoArchiveEnabled
    end
    
    print("[LogAggregator] Log retention policy updated")
    return { success = true, policy = LogAggregator.config }
end

-- Update aggregation settings
function LogAggregator.updateAggregationSettings(aggregationSettings)
    if not aggregationSettings or type(aggregationSettings) ~= "table" then
        return { success = false, error = "Invalid aggregation settings" }
    end
    
    for key, value in pairs(aggregationSettings) do
        if LogAggregator.config[key] then
            LogAggregator.config[key] = value
        end
    end
    
    print("[LogAggregator] Aggregation settings updated")
    return { success = true, settings = LogAggregator.config }
end

-- Update correlation settings
function LogAggregator.updateCorrelationSettings(correlationSettings)
    if not correlationSettings or type(correlationSettings) ~= "table" then
        return { success = false, error = "Invalid correlation settings" }
    end
    
    if correlationSettings.correlationTimeWindow then
        LogAggregator.config.correlationTimeWindow = correlationSettings.correlationTimeWindow
    end
    
    print("[LogAggregator] Correlation settings updated")
    return { success = true, settings = LogAggregator.config }
end

-- Update log alert rules
function LogAggregator.updateLogAlertRules(alertRules)
    if not alertRules or type(alertRules) ~= "table" then
        return { success = false, error = "Invalid alert rules" }
    end
    
    LogAggregator.config.alertRules = alertRules
    
    print("[LogAggregator] Log alert rules updated")
    return { success = true, rules = alertRules }
end

-- Export logs to various formats
function LogAggregator.exportLogs(exportOptions)
    local format = exportOptions.format or "JSON"
    local timeRange = exportOptions.timeRange
    local filters = exportOptions.filters or {}
    local compression = exportOptions.compression or false
    
    local logsToExport = LogAggregator.getRecentLogs(LogAggregator.config.maxLogEntries, filters)
    
    -- Filter by time range
    if timeRange then
        local filteredLogs = {}
        for _, logEntry in ipairs(logsToExport) do
            if LogAggregator._inTimeRange(logEntry.timestamp, timeRange) then
                table.insert(filteredLogs, logEntry)
            end
        end
        logsToExport = filteredLogs
    end
    
    local exportResult = {
        success = true,
        format = format,
        recordCount = #logsToExport,
        exportTimestamp = 0,
        compressionEnabled = compression
    }
    
    -- Format conversion would happen here
    if format == "JSON" then
        exportResult.data = json.encode(logsToExport)
    elseif format == "CSV" then
        exportResult.data = LogAggregator._convertToCSV(logsToExport)
    else
        return { success = false, error = "Unsupported export format: " .. format }
    end
    
    -- Compression would happen here if enabled
    if compression then
        -- Placeholder for compression logic
        exportResult.compressed = true
    end
    
    print("[LogAggregator] Log export completed - " .. #logsToExport .. " logs in " .. format .. " format")
    return exportResult
end

-- Get aggregation summary
function LogAggregator.getAggregationSummary()
    return {
        totalLogs = #LogAggregator.logEntries,
        logsByLevel = LogAggregator.statistics.logsByLevel,
        correlatedLogs = LogAggregator.statistics.correlatedLogs,
        streamingSubscribers = LogAggregator.statistics.streamingSubscribers,
        lastLogTime = LogAggregator.statistics.lastLogTime,
        configuration = LogAggregator.config
    }
end

-- Get log aggregation statistics
function LogAggregator.getStatistics()
    return LogAggregator.statistics
end

-- Private helper functions

function LogAggregator._trackLogCorrelation(logEntry)
    local correlationId = logEntry.correlationId
    
    if not LogAggregator.correlationMap[correlationId] then
        LogAggregator.correlationMap[correlationId] = {}
    end
    
    table.insert(LogAggregator.correlationMap[correlationId], logEntry)
    LogAggregator.statistics.correlatedLogs = LogAggregator.statistics.correlatedLogs + 1
end

function LogAggregator._streamLogToSubscribers(logEntry)
    for subscriberId, subscription in pairs(LogAggregator.streamSubscriptions) do
        if LogAggregator._matchesSubscription(logEntry, subscription) then
            table.insert(subscription.buffer, logEntry)
            
            -- Manage buffer size
            if #subscription.buffer > subscription.bufferSize then
                table.remove(subscription.buffer, 1)
            end
        end
    end
end

function LogAggregator._manageLogSize()
    -- Remove old logs if exceeding max entries
    if #LogAggregator.logEntries > LogAggregator.config.maxLogEntries then
        table.remove(LogAggregator.logEntries, 1)
    end
    
    -- Remove logs older than retention period
    local currentTime = 0
    local retentionThreshold = currentTime - (LogAggregator.config.logRetentionHours * 3600)
    
    local i = 1
    while i <= #LogAggregator.logEntries do
        if LogAggregator.logEntries[i].timestamp < retentionThreshold then
            table.remove(LogAggregator.logEntries, i)
            LogAggregator.statistics.archivedLogCount = LogAggregator.statistics.archivedLogCount + 1
        else
            break -- Logs are ordered by timestamp, so we can break here
        end
    end
end

function LogAggregator._matchesFilters(logEntry, filters)
    if not filters then return true end
    
    -- Time range filter
    if filters.timeRange and not LogAggregator._inTimeRange(logEntry.timestamp, filters.timeRange) then
        return false
    end
    
    -- Log level filter
    if filters.logLevel then
        local levels = {}
        for level in string.gmatch(filters.logLevel, "([^,]+)") do
            levels[level] = true
        end
        if not levels[logEntry.level] then
            return false
        end
    end
    
    -- Component filter
    if filters.component and logEntry.component ~= filters.component then
        return false
    end
    
    -- Process ID filter
    if filters.processId and logEntry.processId ~= filters.processId then
        return false
    end
    
    return true
end

function LogAggregator._matchesSubscription(logEntry, subscription)
    if subscription.logLevel then
        local levels = {}
        for level in string.gmatch(subscription.logLevel, "([^,]+)") do
            levels[level] = true
        end
        if not levels[logEntry.level] then
            return false
        end
    end
    
    if subscription.component and logEntry.component ~= subscription.component then
        return false
    end
    
    if subscription.processId and logEntry.processId ~= subscription.processId then
        return false
    end
    
    return true
end

function LogAggregator._inTimeRange(timestamp, timeRange)
    if not timeRange then return true end
    
    local startTime = timeRange.start or 0
    local endTime = timeRange.finish or 0
    
    return timestamp >= startTime and timestamp <= endTime
end

function LogAggregator._findChildCorrelations(parentCorrelationId)
    -- Simplified child correlation detection
    local childIds = {}
    
    for correlationId, logs in pairs(LogAggregator.correlationMap) do
        if string.find(correlationId, parentCorrelationId, 1, true) and 
           correlationId ~= parentCorrelationId then
            table.insert(childIds, correlationId)
        end
    end
    
    return childIds
end

function LogAggregator._analyzeErrorRate(timeRange, processId)
    local errorLogs = LogAggregator.getErrorLogs(1000, {
        timeRange = timeRange,
        processId = processId
    })
    
    local allLogs = LogAggregator.getRecentLogs(10000, {
        timeRange = timeRange,
        processId = processId
    })
    
    local errorRate = #allLogs > 0 and (#errorLogs / #allLogs) * 100 or 0
    
    return {
        errorRate = errorRate,
        totalErrors = #errorLogs,
        totalLogs = #allLogs,
        trend = "STABLE" -- Simplified trend analysis
    }
end

function LogAggregator._analyzeLogVolume(timeRange, processId)
    local logs = LogAggregator.getRecentLogs(10000, {
        timeRange = timeRange,
        processId = processId
    })
    
    return {
        totalVolume = #logs,
        averagePerHour = #logs / ((timeRange and (timeRange.finish - timeRange.start) / 3600) or 1),
        trend = "STABLE" -- Simplified trend analysis
    }
end

function LogAggregator._analyzeComponentActivity(timeRange, processId)
    local logs = LogAggregator.getRecentLogs(10000, {
        timeRange = timeRange,
        processId = processId
    })
    
    local componentActivity = {}
    
    for _, logEntry in ipairs(logs) do
        local component = logEntry.component or "UNKNOWN"
        componentActivity[component] = (componentActivity[component] or 0) + 1
    end
    
    return componentActivity
end

function LogAggregator._extractErrorType(errorMessage)
    -- Simple error type extraction
    if string.find(string.lower(errorMessage), "timeout") then
        return "TIMEOUT"
    elseif string.find(string.lower(errorMessage), "connection") then
        return "CONNECTION"
    elseif string.find(string.lower(errorMessage), "authentication") then
        return "AUTHENTICATION"
    else
        return "GENERAL"
    end
end

function LogAggregator._convertToCSV(logs)
    local csv = "timestamp,level,component,processId,message\n"
    
    for _, log in ipairs(logs) do
        csv = csv .. string.format("%s,%s,%s,%s,\"%s\"\n",
            log.timestamp,
            log.level,
            log.component,
            log.processId,
            string.gsub(log.message, "\"", "\"\"") -- Escape quotes
        )
    end
    
    return csv
end

function LogAggregator._getTableSize(tbl)
    local count = 0
    for _ in pairs(tbl) do
        count = count + 1
    end
    return count
end


-- ===== END MODULE: admin.components.log-aggregator =====


-- ===== MODULE: admin.components.alert-manager =====
-- File: ao-processes/admin/components/alert-manager.lua
-- Original require: local AlertManager = require("admin.components.alert-manager")

-- Alert Manager Component
-- Provides alert generation, management, and notification capabilities for the admin system


-- ===== MODULE: game-logic.process-coordination.message-correlator =====
-- File: ao-processes/game-logic/process-coordination/message-correlator.lua
-- Original require: local MessageCorrelator = require("game-logic.process-coordination.message-correlator")


-- ===== END MODULE: game-logic.process-coordination.message-correlator =====


-- ===== MODULE: game-logic.process-coordination.message-router =====
-- File: ao-processes/game-logic/process-coordination/message-router.lua
-- Original require: local MessageRouter = require("game-logic.process-coordination.message-router")


-- ===== END MODULE: game-logic.process-coordination.message-router =====


local AlertManager = {
    -- Active alerts storage
    activeAlerts = {},
    
    -- Alert history
    alertHistory = {},
    
    -- Notification channels and subscriptions
    notificationChannels = {},
    alertSubscriptions = {},
    
    -- Alert configuration
    config = {
        maxActiveAlerts = 1000,
        alertRetentionHours = 72,
        escalationTimeoutMinutes = 30,
        notificationRetryAttempts = 3,
        alertSeverityLevels = {
            INFO = 1,
            WARNING = 2,
            ERROR = 3,
            CRITICAL = 4,
            FATAL = 5
        },
        autoAcknowledgeTimeoutMinutes = 60,
        alertCooldownMinutes = 5
    },
    
    -- Alert types and their default configurations
    ALERT_TYPES = {
        HEALTH_CHECK_FAILED = {
            name = "HEALTH_CHECK_FAILED",
            defaultSeverity = "WARNING",
            autoEscalate = true,
            escalationTime = 900 -- 15 minutes
        },
        PERFORMANCE_DEGRADATION = {
            name = "PERFORMANCE_DEGRADATION",
            defaultSeverity = "WARNING",
            autoEscalate = true,
            escalationTime = 600 -- 10 minutes
        },
        SYSTEM_ERROR = {
            name = "SYSTEM_ERROR",
            defaultSeverity = "ERROR",
            autoEscalate = true,
            escalationTime = 300 -- 5 minutes
        },
        ADMIN_COMMAND = {
            name = "ADMIN_COMMAND",
            defaultSeverity = "INFO",
            autoEscalate = false,
            escalationTime = 0
        },
        PROCESS_LIFECYCLE = {
            name = "PROCESS_LIFECYCLE",
            defaultSeverity = "WARNING",
            autoEscalate = true,
            escalationTime = 600 -- 10 minutes
        },
        MAINTENANCE_MODE = {
            name = "MAINTENANCE_MODE",
            defaultSeverity = "INFO",
            autoEscalate = false,
            escalationTime = 0
        },
        SECURITY_ALERT = {
            name = "SECURITY_ALERT",
            defaultSeverity = "CRITICAL",
            autoEscalate = true,
            escalationTime = 180 -- 3 minutes
        }
    },
    
    -- Alert statistics
    statistics = {
        totalAlertsGenerated = 0,
        alertsBySeverity = {
            INFO = 0,
            WARNING = 0,
            ERROR = 0,
            CRITICAL = 0,
            FATAL = 0
        },
        alertsByType = {},
        alertsAcknowledged = 0,
        alertsAutoResolved = 0,
        escalatedAlerts = 0,
        notificationsSent = 0,
        lastAlertTime = 0
    }
}

-- Initialize alert management system
function AlertManager.initialize()
    AlertManager.activeAlerts = {}
    AlertManager.alertHistory = {}
    AlertManager.notificationChannels = {}
    AlertManager.alertSubscriptions = {}
    AlertManager.statistics = {
        totalAlertsGenerated = 0,
        alertsBySeverity = {
            INFO = 0,
            WARNING = 0,
            ERROR = 0,
            CRITICAL = 0,
            FATAL = 0
        },
        alertsByType = {},
        alertsAcknowledged = 0,
        alertsAutoResolved = 0,
        escalatedAlerts = 0,
        notificationsSent = 0,
        lastAlertTime = 0
    }
    
    -- Initialize default notification channels
    AlertManager._initializeDefaultChannels()
    
    print("[AlertManager] Alert management system initialized")
end

-- Generate new alert
function AlertManager.generateAlert(alertData)
    if not alertData or not alertData.type then
        return { success = false, error = "Alert type is required" }
    end
    
    local alertType = alertData.type
    local alertConfig = AlertManager.ALERT_TYPES[alertType]
    if not alertConfig then
        return { success = false, error = "Unknown alert type: " .. alertType }
    end
    
    local timestamp = 0
    local alertId = MessageCorrelator.generateId()
    
    -- Check for alert cooldown (avoid spam)
    if AlertManager._isInCooldown(alertType, alertData.source) then
        return { success = false, error = "Alert is in cooldown period" }
    end
    
    local alert = {
        id = alertId,
        type = alertType,
        severity = alertData.severity or alertConfig.defaultSeverity,
        message = alertData.message,
        details = alertData.details or {},
        source = alertData.source or "SYSTEM",
        processId = alertData.processId,
        timestamp = timestamp,
        status = "ACTIVE",
        acknowledgedBy = nil,
        acknowledgedAt = nil,
        resolvedAt = nil,
        escalatedAt = nil,
        escalationLevel = 0,
        notificationsSent = 0,
        correlationId = alertData.correlationId
    }
    
    -- Add to active alerts
    AlertManager.activeAlerts[alertId] = alert
    
    -- Update statistics
    AlertManager.statistics.totalAlertsGenerated = AlertManager.statistics.totalAlertsGenerated + 1
    AlertManager.statistics.alertsBySeverity[alert.severity] = 
        (AlertManager.statistics.alertsBySeverity[alert.severity] or 0) + 1
    AlertManager.statistics.alertsByType[alertType] = 
        (AlertManager.statistics.alertsByType[alertType] or 0) + 1
    AlertManager.statistics.lastAlertTime = timestamp
    
    -- Send notifications
    AlertManager._sendAlertNotifications(alert)
    
    -- Schedule escalation if applicable
    if alertConfig.autoEscalate and alertConfig.escalationTime > 0 then
        AlertManager._scheduleEscalation(alertId, alertConfig.escalationTime)
    end
    
    -- Schedule auto-acknowledge if configured
    if AlertManager.config.autoAcknowledgeTimeoutMinutes > 0 then
        AlertManager._scheduleAutoAcknowledge(alertId, AlertManager.config.autoAcknowledgeTimeoutMinutes * 60)
    end
    
    print("[AlertManager] Alert generated: " .. alertType .. " (" .. alert.severity .. ") - " .. alertId)
    
    return { success = true, alertId = alertId, alert = alert }
end

-- Acknowledge alert
function AlertManager.acknowledgeAlert(alertId, acknowledgingUser)
    local alert = AlertManager.activeAlerts[alertId]
    if not alert then
        return { success = false, error = "Alert not found: " .. alertId }
    end
    
    if alert.status == "ACKNOWLEDGED" then
        return { success = false, error = "Alert already acknowledged" }
    end
    
    alert.status = "ACKNOWLEDGED"
    alert.acknowledgedBy = acknowledgingUser
    alert.acknowledgedAt = 0
    
    AlertManager.statistics.alertsAcknowledged = AlertManager.statistics.alertsAcknowledged + 1
    
    -- Send acknowledgment notification
    AlertManager._sendAcknowledgmentNotification(alert, acknowledgingUser)
    
    print("[AlertManager] Alert acknowledged: " .. alertId .. " by " .. (acknowledgingUser or "system"))
    
    return { success = true, alertId = alertId }
end

-- Clear/resolve alert
function AlertManager.clearAlert(alertId, resolvingUser)
    local alert = AlertManager.activeAlerts[alertId]
    if not alert then
        return { success = false, error = "Alert not found: " .. alertId }
    end
    
    alert.status = "RESOLVED"
    alert.resolvedAt = 0
    alert.resolvedBy = resolvingUser
    
    -- Move to history
    table.insert(AlertManager.alertHistory, alert)
    AlertManager.activeAlerts[alertId] = nil
    
    -- Send resolution notification
    AlertManager._sendResolutionNotification(alert, resolvingUser)
    
    -- Manage history size
    AlertManager._manageAlertHistory()
    
    print("[AlertManager] Alert resolved: " .. alertId .. " by " .. (resolvingUser or "system"))
    
    return { success = true, alertId = alertId }
end

-- Get recent alerts with optional filtering
function AlertManager.getRecentAlerts(limit, severity)
    local recentAlerts = {}
    local count = 0
    local maxLimit = limit or 50
    
    -- First, get active alerts
    for alertId, alert in pairs(AlertManager.activeAlerts) do
        if count >= maxLimit then break end
        
        if not severity or alert.severity == severity then
            table.insert(recentAlerts, alert)
            count = count + 1
        end
    end
    
    -- Then, get from history (most recent first)
    for i = #AlertManager.alertHistory, 1, -1 do
        if count >= maxLimit then break end
        
        local alert = AlertManager.alertHistory[i]
        if not severity or alert.severity == severity then
            table.insert(recentAlerts, alert)
            count = count + 1
        end
    end
    
    -- Sort by timestamp (most recent first)
    table.sort(recentAlerts, function(a, b) return a.timestamp > b.timestamp end)
    
    return recentAlerts
end

-- Get count of active alerts
function AlertManager.getActiveAlertCount()
    local count = 0
    for _ in pairs(AlertManager.activeAlerts) do
        count = count + 1
    end
    return count
end

-- Update alert thresholds
function AlertManager.updateAlertThresholds(thresholds)
    if not thresholds or type(thresholds) ~= "table" then
        return { success = false, error = "Invalid threshold configuration" }
    end
    
    for alertType, config in pairs(thresholds) do
        if AlertManager.ALERT_TYPES[alertType] then
            for key, value in pairs(config) do
                AlertManager.ALERT_TYPES[alertType][key] = value
            end
        end
    end
    
    print("[AlertManager] Alert thresholds updated")
    return { success = true, thresholds = AlertManager.ALERT_TYPES }
end

-- Configure notification channels
function AlertManager.configureNotifications(notificationConfig)
    if not notificationConfig or type(notificationConfig) ~= "table" then
        return { success = false, error = "Invalid notification configuration" }
    end
    
    for channelName, channelConfig in pairs(notificationConfig) do
        AlertManager.notificationChannels[channelName] = {
            name = channelName,
            type = channelConfig.type or "LOG",
            enabled = channelConfig.enabled ~= false,
            severityFilter = channelConfig.severityFilter,
            typeFilter = channelConfig.typeFilter,
            endpoint = channelConfig.endpoint,
            configuration = channelConfig.configuration or {}
        }
    end
    
    print("[AlertManager] Notification channels configured")
    return { success = true, channels = AlertManager.notificationChannels }
end

-- Process health results for alert generation
function AlertManager.processHealthResults(healthResults)
    if not healthResults or not healthResults.processResults then
        return
    end
    
    for processId, result in pairs(healthResults.processResults) do
        if result.healthStatus == "UNHEALTHY" or result.healthStatus == "OFFLINE" then
            AlertManager.generateAlert({
                type = "HEALTH_CHECK_FAILED",
                severity = result.healthStatus == "OFFLINE" and "CRITICAL" or "WARNING",
                message = "Process health check failed: " .. processId,
                processId = processId,
                details = {
                    healthStatus = result.healthStatus,
                    consecutiveFailures = result.consecutiveFailures,
                    lastCheck = result.lastCheck,
                    processType = result.processType
                },
                source = "HEALTH_MONITOR"
            })
        end
    end
end

-- Process performance metrics for alert generation  
function AlertManager.processPerformanceMetrics(performanceMetrics)
    if not performanceMetrics or not performanceMetrics.status then
        return
    end
    
    if performanceMetrics.status == "CRITICAL" or performanceMetrics.status == "POOR" then
        AlertManager.generateAlert({
            type = "PERFORMANCE_DEGRADATION", 
            severity = performanceMetrics.status == "CRITICAL" and "CRITICAL" or "WARNING",
            message = "System performance degradation detected",
            details = {
                performanceStatus = performanceMetrics.status,
                bottlenecks = performanceMetrics.bottlenecks or {},
                systemMetrics = performanceMetrics.systemMetrics
            },
            source = "PERFORMANCE_MONITOR"
        })
    end
end

-- Get alert management statistics
function AlertManager.getStatistics()
    return {
        statistics = AlertManager.statistics,
        activeAlertCount = AlertManager.getActiveAlertCount(),
        historyCount = #AlertManager.alertHistory,
        notificationChannelCount = AlertManager._getTableSize(AlertManager.notificationChannels),
        subscriberCount = AlertManager._getTableSize(AlertManager.alertSubscriptions),
        configuration = AlertManager.config
    }
end

-- Private helper functions

function AlertManager._initializeDefaultChannels()
    -- Initialize system log channel
    AlertManager.notificationChannels["system-log"] = {
        name = "system-log",
        type = "LOG",
        enabled = true,
        severityFilter = nil, -- All severities
        typeFilter = nil, -- All types
        endpoint = nil,
        configuration = {}
    }
    
    -- Initialize admin console channel
    AlertManager.notificationChannels["admin-console"] = {
        name = "admin-console",
        type = "CONSOLE",
        enabled = true,
        severityFilter = "WARNING,ERROR,CRITICAL,FATAL",
        typeFilter = nil,
        endpoint = nil,
        configuration = {}
    }
end

function AlertManager._sendAlertNotifications(alert)
    for channelName, channel in pairs(AlertManager.notificationChannels) do
        if channel.enabled and AlertManager._shouldNotifyChannel(alert, channel) then
            local notificationResult = AlertManager._sendNotification(alert, channel)
            
            if notificationResult.success then
                alert.notificationsSent = alert.notificationsSent + 1
                AlertManager.statistics.notificationsSent = AlertManager.statistics.notificationsSent + 1
            end
        end
    end
end

function AlertManager._shouldNotifyChannel(alert, channel)
    -- Check severity filter
    if channel.severityFilter then
        local severityMatch = false
        for severity in string.gmatch(channel.severityFilter, "([^,]+)") do
            if alert.severity == severity then
                severityMatch = true
                break
            end
        end
        if not severityMatch then
            return false
        end
    end
    
    -- Check type filter
    if channel.typeFilter then
        local typeMatch = false
        for alertType in string.gmatch(channel.typeFilter, "([^,]+)") do
            if alert.type == alertType then
                typeMatch = true
                break
            end
        end
        if not typeMatch then
            return false
        end
    end
    
    return true
end

function AlertManager._sendNotification(alert, channel)
    if channel.type == "LOG" then
        print("[ALERT:" .. alert.severity .. "] " .. alert.message .. " (" .. alert.id .. ")")
        return { success = true }
    elseif channel.type == "CONSOLE" then
        -- Would send to admin console interface
        return { success = true }
    elseif channel.type == "MESSAGE" then
        -- Would send via message routing
        local notificationMessage = {
            correlation = {
                id = MessageCorrelator.generateId(),
                requestType = "ALERT_NOTIFICATION"
            },
            alert = alert,
            channel = channel.name
        }
        
        local routingResult = MessageRouter.routeMessage(
            "ALERT_NOTIFICATION",
            notificationMessage,
            "BROADCAST"
        )
        
        return routingResult
    else
        return { success = false, error = "Unknown notification type: " .. channel.type }
    end
end

function AlertManager._sendAcknowledgmentNotification(alert, user)
    print("[ALERT:ACK] Alert acknowledged: " .. alert.id .. " by " .. (user or "system"))
end

function AlertManager._sendResolutionNotification(alert, user)
    print("[ALERT:RESOLVED] Alert resolved: " .. alert.id .. " by " .. (user or "system"))
end

function AlertManager._scheduleEscalation(alertId, escalationTimeSeconds)
    -- Placeholder for escalation scheduling
    -- In a real implementation, this would integrate with a scheduler
    print("[AlertManager] Escalation scheduled for alert " .. alertId .. " in " .. escalationTimeSeconds .. " seconds")
end

function AlertManager._scheduleAutoAcknowledge(alertId, timeoutSeconds)
    -- Placeholder for auto-acknowledge scheduling
    -- In a real implementation, this would integrate with a scheduler
    print("[AlertManager] Auto-acknowledge scheduled for alert " .. alertId .. " in " .. timeoutSeconds .. " seconds")
end

function AlertManager._isInCooldown(alertType, source)
    local cooldownTime = AlertManager.config.alertCooldownMinutes * 60
    local currentTime = 0
    
    -- Simple cooldown check - in production this would be more sophisticated
    for alertId, alert in pairs(AlertManager.activeAlerts) do
        if alert.type == alertType and alert.source == source and 
           (currentTime - alert.timestamp) < cooldownTime then
            return true
        end
    end
    
    return false
end

function AlertManager._manageAlertHistory()
    -- Remove old alerts from history
    local maxHistoryEntries = AlertManager.config.alertRetentionHours
    if #AlertManager.alertHistory > maxHistoryEntries then
        table.remove(AlertManager.alertHistory, 1)
    end
    
    -- Remove alerts older than retention period
    local currentTime = 0
    local retentionThreshold = currentTime - (AlertManager.config.alertRetentionHours * 3600)
    
    local i = 1
    while i <= #AlertManager.alertHistory do
        if AlertManager.alertHistory[i].timestamp < retentionThreshold then
            table.remove(AlertManager.alertHistory, i)
        else
            break -- History is ordered by timestamp
        end
    end
end

function AlertManager._getTableSize(tbl)
    local count = 0
    for _ in pairs(tbl) do
        count = count + 1
    end
    return count
end


-- ===== END MODULE: admin.components.alert-manager =====


-- ===== MODULE: admin.components.maintenance-coordinator =====
-- File: ao-processes/admin/components/maintenance-coordinator.lua
-- Original require: local MaintenanceCoordinator = require("admin.components.maintenance-coordinator")

-- Maintenance Coordinator Component
-- Coordinates maintenance operations, deployments, and system-wide operational procedures


-- ===== MODULE: game-logic.process-coordination.message-correlator =====
-- File: ao-processes/game-logic/process-coordination/message-correlator.lua
-- Original require: local MessageCorrelator = require("game-logic.process-coordination.message-correlator")


-- ===== END MODULE: game-logic.process-coordination.message-correlator =====


-- ===== MODULE: game-logic.process-coordination.message-router =====
-- File: ao-processes/game-logic/process-coordination/message-router.lua
-- Original require: local MessageRouter = require("game-logic.process-coordination.message-router")


-- ===== END MODULE: game-logic.process-coordination.message-router =====


-- ===== MODULE: game-logic.process-coordination.process-authenticator =====
-- File: ao-processes/game-logic/process-coordination/process-authenticator.lua
-- Original require: local ProcessAuthenticator = require("game-logic.process-coordination.process-authenticator")


-- ===== END MODULE: game-logic.process-coordination.process-authenticator =====


local MaintenanceCoordinator = {
    -- Maintenance state
    maintenanceState = {
        maintenanceMode = false,
        maintenanceReason = nil,
        maintenanceStartTime = nil,
        maintenanceEndTime = nil,
        affectedProcesses = {}
    },
    
    -- Active maintenance operations
    activeOperations = {},
    
    -- Operation history
    operationHistory = {},
    
    -- Maintenance configuration
    config = {
        maxConcurrentOperations = 5,
        operationTimeoutMinutes = 60,
        gracefulShutdownTimeoutSeconds = 30,
        stateBackupEnabled = true,
        rollbackRetentionHours = 24,
        dependencyCheckEnabled = true
    },
    
    -- Operation types
    OPERATION_TYPES = {
        DEPLOYMENT = "DEPLOYMENT",
        UPDATE = "UPDATE",
        ROLLBACK = "ROLLBACK",
        SCALING = "SCALING",
        MIGRATION = "MIGRATION",
        RESTART = "RESTART",
        SHUTDOWN = "SHUTDOWN",
        BACKUP = "BACKUP",
        RESTORE = "RESTORE"
    },
    
    -- Operation statuses
    OPERATION_STATUS = {
        PENDING = "PENDING",
        RUNNING = "RUNNING",
        COMPLETED = "COMPLETED",
        FAILED = "FAILED",
        CANCELLED = "CANCELLED",
        ROLLED_BACK = "ROLLED_BACK"
    },
    
    -- Process dependencies
    processDependencies = {
        ["coordinator-process"] = {},
        ["battle-process"] = {"coordinator-process"},
        ["pokemon-process"] = {"coordinator-process"},
        ["shop-process"] = {"coordinator-process"},
        ["security-process"] = {"coordinator-process"},
        ["admin-process"] = {}
    },
    
    -- Statistics
    statistics = {
        totalOperations = 0,
        successfulOperations = 0,
        failedOperations = 0,
        rolledBackOperations = 0,
        maintenanceModeActivations = 0,
        averageOperationTime = 0
    }
}

-- Initialize maintenance coordination system
function MaintenanceCoordinator.initialize()
    MaintenanceCoordinator.activeOperations = {}
    MaintenanceCoordinator.operationHistory = {}
    MaintenanceCoordinator.maintenanceState = {
        maintenanceMode = false,
        maintenanceReason = nil,
        maintenanceStartTime = nil,
        maintenanceEndTime = nil,
        affectedProcesses = {}
    }
    MaintenanceCoordinator.statistics = {
        totalOperations = 0,
        successfulOperations = 0,
        failedOperations = 0,
        rolledBackOperations = 0,
        maintenanceModeActivations = 0,
        averageOperationTime = 0
    }
    print("[MaintenanceCoordinator] Maintenance coordination system initialized")
end

-- Set system maintenance mode
function MaintenanceCoordinator.setMaintenanceMode(enabled, reason)
    local previousMode = MaintenanceCoordinator.maintenanceState.maintenanceMode
    local currentTime = 0
    
    MaintenanceCoordinator.maintenanceState.maintenanceMode = enabled
    MaintenanceCoordinator.maintenanceState.maintenanceReason = reason or "Maintenance mode toggle"
    
    if enabled and not previousMode then
        -- Entering maintenance mode
        MaintenanceCoordinator.maintenanceState.maintenanceStartTime = currentTime
        MaintenanceCoordinator.maintenanceState.maintenanceEndTime = nil
        MaintenanceCoordinator.statistics.maintenanceModeActivations = 
            MaintenanceCoordinator.statistics.maintenanceModeActivations + 1
        
        -- Notify all processes about maintenance mode
        local result = MaintenanceCoordinator._notifyProcesses("MAINTENANCE_MODE_ENABLED", {
            reason = reason,
            startTime = currentTime
        })
        
        print("[MaintenanceCoordinator] Maintenance mode ENABLED - Reason: " .. (reason or "Unknown"))
        return { success = result.success, mode = "enabled" }
        
    elseif not enabled and previousMode then
        -- Exiting maintenance mode
        MaintenanceCoordinator.maintenanceState.maintenanceEndTime = currentTime
        local duration = currentTime - MaintenanceCoordinator.maintenanceState.maintenanceStartTime
        
        -- Notify all processes about maintenance mode end
        local result = MaintenanceCoordinator._notifyProcesses("MAINTENANCE_MODE_DISABLED", {
            reason = "Maintenance completed",
            endTime = currentTime,
            duration = duration
        })
        
        print("[MaintenanceCoordinator] Maintenance mode DISABLED - Duration: " .. duration .. "s")
        return { success = result.success, mode = "disabled", duration = duration }
    else
        -- No change in mode
        return { success = true, mode = enabled and "enabled" or "disabled" }
    end
end

-- Coordinate deployment across processes
function MaintenanceCoordinator.coordinateDeployment(deploymentRequest)
    local deploymentPlan = deploymentRequest.deploymentPlan
    local coordinationMode = deploymentRequest.coordinationMode or "SEQUENTIAL"
    local rollbackOnFailure = deploymentRequest.rollbackOnFailure ~= false
    local adminUserId = deploymentRequest.adminUserId
    
    local operationId = MessageCorrelator.generateId()
    local operation = {
        id = operationId,
        type = MaintenanceCoordinator.OPERATION_TYPES.DEPLOYMENT,
        status = MaintenanceCoordinator.OPERATION_STATUS.PENDING,
        coordinationMode = coordinationMode,
        deploymentPlan = deploymentPlan,
        rollbackOnFailure = rollbackOnFailure,
        adminUserId = adminUserId,
        startTime = 0,
        results = {},
        rollbackData = {}
    }
    
    -- Register operation
    MaintenanceCoordinator.activeOperations[operationId] = operation
    MaintenanceCoordinator.statistics.totalOperations = MaintenanceCoordinator.statistics.totalOperations + 1
    
    -- Execute deployment coordination
    local coordinationResult = {}
    if coordinationMode == "SEQUENTIAL" then
        coordinationResult = MaintenanceCoordinator._executeSequentialDeployment(operation)
    elseif coordinationMode == "PARALLEL" then
        coordinationResult = MaintenanceCoordinator._executeParallelDeployment(operation)
    elseif coordinationMode == "DEPENDENCY_AWARE" then
        coordinationResult = MaintenanceCoordinator._executeDependencyAwareDeployment(operation)
    else
        coordinationResult = { success = false, error = "Unsupported coordination mode: " .. coordinationMode }
    end
    
    -- Update operation status
    operation.status = coordinationResult.success and 
        MaintenanceCoordinator.OPERATION_STATUS.COMPLETED or 
        MaintenanceCoordinator.OPERATION_STATUS.FAILED
    operation.completionTime = 0
    operation.results = coordinationResult.results
    
    -- Handle rollback on failure
    if not coordinationResult.success and rollbackOnFailure then
        local rollbackResult = MaintenanceCoordinator._executeDeploymentRollback(operation)
        if rollbackResult.success then
            operation.status = MaintenanceCoordinator.OPERATION_STATUS.ROLLED_BACK
        end
    end
    
    -- Update statistics and move to history
    MaintenanceCoordinator._completeOperation(operation)
    
    return {
        success = coordinationResult.success,
        operationId = operationId,
        status = operation.status,
        results = coordinationResult.results,
        affectedProcesses = operation.deploymentPlan.targetProcesses,
        rollbackAvailable = rollbackOnFailure and coordinationResult.success,
        error = coordinationResult.error
    }
end

-- Execute rollback operation
function MaintenanceCoordinator.executeRollback(rollbackRequest)
    local operation = rollbackRequest.operation
    local targetProcesses = rollbackRequest.targetProcesses
    local rollbackPoint = rollbackRequest.rollbackPoint
    local reason = rollbackRequest.reason or "Manual rollback"
    local adminUserId = rollbackRequest.adminUserId
    
    local operationId = MessageCorrelator.generateId()
    local rollbackOperation = {
        id = operationId,
        type = MaintenanceCoordinator.OPERATION_TYPES.ROLLBACK,
        status = MaintenanceCoordinator.OPERATION_STATUS.RUNNING,
        targetProcesses = targetProcesses,
        rollbackPoint = rollbackPoint,
        reason = reason,
        adminUserId = adminUserId,
        startTime = 0,
        results = {}
    }
    
    -- Register operation
    MaintenanceCoordinator.activeOperations[operationId] = rollbackOperation
    MaintenanceCoordinator.statistics.totalOperations = MaintenanceCoordinator.statistics.totalOperations + 1
    
    -- Execute rollback
    local rollbackResults = {}
    local successCount = 0
    
    for _, processId in ipairs(targetProcesses) do
        local processResult = MaintenanceCoordinator._rollbackProcess(processId, rollbackPoint, reason)
        rollbackResults[processId] = processResult
        
        if processResult.success then
            successCount = successCount + 1
        end
    end
    
    -- Update operation status
    rollbackOperation.status = successCount == #targetProcesses and 
        MaintenanceCoordinator.OPERATION_STATUS.COMPLETED or 
        MaintenanceCoordinator.OPERATION_STATUS.FAILED
    rollbackOperation.completionTime = 0
    rollbackOperation.results = rollbackResults
    
    -- Update statistics and move to history
    MaintenanceCoordinator._completeOperation(rollbackOperation)
    
    return {
        success = successCount == #targetProcesses,
        operationId = operationId,
        status = rollbackOperation.status,
        results = rollbackResults,
        affectedProcesses = targetProcesses,
        stateRestoration = successCount > 0
    }
end

-- Coordinate graceful shutdown
function MaintenanceCoordinator.coordinateGracefulShutdown(shutdownRequest)
    local targetProcesses = shutdownRequest.targetProcesses
    local shutdownOrder = shutdownRequest.shutdownOrder or "DEPENDENCY_AWARE"
    local gracePeriodSeconds = shutdownRequest.gracePeriodSeconds or MaintenanceCoordinator.config.gracefulShutdownTimeoutSeconds
    local statePreservation = shutdownRequest.statePreservation ~= false
    local adminUserId = shutdownRequest.adminUserId
    
    local operationId = MessageCorrelator.generateId()
    local shutdownOperation = {
        id = operationId,
        type = MaintenanceCoordinator.OPERATION_TYPES.SHUTDOWN,
        status = MaintenanceCoordinator.OPERATION_STATUS.RUNNING,
        targetProcesses = targetProcesses,
        shutdownOrder = shutdownOrder,
        gracePeriodSeconds = gracePeriodSeconds,
        statePreservation = statePreservation,
        adminUserId = adminUserId,
        startTime = 0,
        results = {}
    }
    
    -- Register operation
    MaintenanceCoordinator.activeOperations[operationId] = shutdownOperation
    MaintenanceCoordinator.statistics.totalOperations = MaintenanceCoordinator.statistics.totalOperations + 1
    
    -- Determine shutdown order
    local orderedProcesses = MaintenanceCoordinator._determineShutdownOrder(targetProcesses, shutdownOrder)
    
    -- Execute graceful shutdown
    local shutdownResults = {}
    local successCount = 0
    
    for _, processId in ipairs(orderedProcesses) do
        local processResult = MaintenanceCoordinator._shutdownProcess(processId, gracePeriodSeconds, statePreservation)
        shutdownResults[processId] = processResult
        
        if processResult.success then
            successCount = successCount + 1
        else
            -- If shutdown fails, we might need to force shutdown
            print("[MaintenanceCoordinator] Graceful shutdown failed for " .. processId .. ", considering force shutdown")
        end
    end
    
    -- Update operation status
    shutdownOperation.status = successCount == #orderedProcesses and 
        MaintenanceCoordinator.OPERATION_STATUS.COMPLETED or 
        MaintenanceCoordinator.OPERATION_STATUS.FAILED
    shutdownOperation.completionTime = 0
    shutdownOperation.results = shutdownResults
    shutdownOperation.executionOrder = orderedProcesses
    
    -- Update statistics and move to history
    MaintenanceCoordinator._completeOperation(shutdownOperation)
    
    return {
        success = successCount == #orderedProcesses,
        operationId = operationId,
        status = shutdownOperation.status,
        results = shutdownResults,
        executionOrder = orderedProcesses,
        statePreserved = statePreservation
    }
end

-- Deploy processes
function MaintenanceCoordinator.deployProcesses(deploymentRequest)
    -- Implementation for process deployment
    return { success = true, deployedProcesses = deploymentRequest.targetProcesses }
end

-- Update processes
function MaintenanceCoordinator.updateProcesses(updateRequest)
    -- Implementation for process updates
    return { success = true, updatedProcesses = updateRequest.targetProcesses }
end

-- Rollback processes
function MaintenanceCoordinator.rollbackProcesses(rollbackRequest)
    -- Implementation for process rollback
    return { success = true, rolledBackProcesses = rollbackRequest.targetProcesses }
end

-- Scale processes
function MaintenanceCoordinator.scaleProcesses(scalingRequest)
    -- Implementation for process scaling
    return { success = true, scaledProcesses = scalingRequest.targetProcesses }
end

-- Migrate processes
function MaintenanceCoordinator.migrateProcesses(migrationRequest)
    -- Implementation for process migration
    return { success = true, migratedProcesses = migrationRequest.targetProcesses }
end

-- Get deployment status
function MaintenanceCoordinator.getDeploymentStatus(deploymentId)
    local operation = MaintenanceCoordinator.activeOperations[deploymentId]
    if operation then
        return {
            operationId = operation.id,
            type = operation.type,
            status = operation.status,
            startTime = operation.startTime,
            results = operation.results
        }
    end
    
    -- Check history
    for _, historicalOp in ipairs(MaintenanceCoordinator.operationHistory) do
        if historicalOp.id == deploymentId then
            return historicalOp
        end
    end
    
    return nil
end

-- Get active deployments
function MaintenanceCoordinator.getActiveDeployments()
    local activeDeployments = {}
    for operationId, operation in pairs(MaintenanceCoordinator.activeOperations) do
        table.insert(activeDeployments, {
            operationId = operationId,
            type = operation.type,
            status = operation.status,
            startTime = operation.startTime
        })
    end
    return activeDeployments
end

-- Get recent deployments
function MaintenanceCoordinator.getRecentDeployments(limit)
    local recentDeployments = {}
    local count = 0
    local maxLimit = limit or 10
    
    for i = #MaintenanceCoordinator.operationHistory, 1, -1 do
        if count >= maxLimit then break end
        table.insert(recentDeployments, MaintenanceCoordinator.operationHistory[i])
        count = count + 1
    end
    
    return recentDeployments
end

-- Get system deployment health
function MaintenanceCoordinator.getSystemDeploymentHealth()
    return {
        maintenanceMode = MaintenanceCoordinator.maintenanceState.maintenanceMode,
        activeOperations = MaintenanceCoordinator._getTableSize(MaintenanceCoordinator.activeOperations),
        statistics = MaintenanceCoordinator.statistics
    }
end

-- Private helper functions

function MaintenanceCoordinator._notifyProcesses(notificationType, data)
    local notificationMessage = {
        correlation = {
            id = MessageCorrelator.generateId(),
            requestType = notificationType
        },
        maintenanceNotification = {
            type = notificationType,
            data = data,
            timestamp = 0
        }
    }
    
    local routingResult = MessageRouter.routeMessage(
        notificationType,
        notificationMessage,
        "BROADCAST"
    )
    
    return routingResult
end

function MaintenanceCoordinator._executeSequentialDeployment(operation)
    local results = {}
    local successCount = 0
    
    for _, processId in ipairs(operation.deploymentPlan.targetProcesses) do
        local deployResult = MaintenanceCoordinator._deployToProcess(processId, operation.deploymentPlan)
        results[processId] = deployResult
        
        if deployResult.success then
            successCount = successCount + 1
        else
            -- Stop on first failure in sequential mode
            break
        end
    end
    
    return {
        success = successCount == #operation.deploymentPlan.targetProcesses,
        results = results,
        successCount = successCount
    }
end

function MaintenanceCoordinator._executeParallelDeployment(operation)
    local results = {}
    local successCount = 0
    
    -- In parallel mode, we would deploy to all processes simultaneously
    -- For this implementation, we'll simulate parallel execution
    for _, processId in ipairs(operation.deploymentPlan.targetProcesses) do
        local deployResult = MaintenanceCoordinator._deployToProcess(processId, operation.deploymentPlan)
        results[processId] = deployResult
        
        if deployResult.success then
            successCount = successCount + 1
        end
    end
    
    return {
        success = successCount == #operation.deploymentPlan.targetProcesses,
        results = results,
        successCount = successCount
    }
end

function MaintenanceCoordinator._executeDependencyAwareDeployment(operation)
    local targetProcesses = operation.deploymentPlan.targetProcesses
    local orderedProcesses = MaintenanceCoordinator._resolveDependencyOrder(targetProcesses)
    
    local results = {}
    local successCount = 0
    
    for _, processId in ipairs(orderedProcesses) do
        local deployResult = MaintenanceCoordinator._deployToProcess(processId, operation.deploymentPlan)
        results[processId] = deployResult
        
        if deployResult.success then
            successCount = successCount + 1
        else
            -- Stop on failure in dependency-aware mode
            print("[MaintenanceCoordinator] Deployment failed for " .. processId .. 
                  ", stopping dependency-aware deployment")
            break
        end
    end
    
    return {
        success = successCount == #orderedProcesses,
        results = results,
        successCount = successCount,
        executionOrder = orderedProcesses
    }
end

function MaintenanceCoordinator._deployToProcess(processId, deploymentPlan)
    -- Simulate deployment to process
    local deployMessage = {
        correlation = {
            id = MessageCorrelator.generateId(),
            requestType = "DEPLOYMENT"
        },
        deployment = {
            processId = processId,
            deploymentConfig = deploymentPlan.config,
            validationRequired = deploymentPlan.validation
        }
    }
    
    local routingResult = MessageRouter.routeMessage(
        "DEPLOYMENT",
        deployMessage,
        "DIRECT_ROUTE"
    )
    
    return {
        success = routingResult.success,
        processId = processId,
        deploymentTime = 0,
        error = routingResult.error
    }
end

function MaintenanceCoordinator._executeDeploymentRollback(operation)
    -- Implementation for deployment rollback
    return { success = true, rolledBackProcesses = operation.deploymentPlan.targetProcesses }
end

function MaintenanceCoordinator._rollbackProcess(processId, rollbackPoint, reason)
    -- Simulate process rollback
    return {
        success = true,
        processId = processId,
        rollbackPoint = rollbackPoint,
        rollbackTime = 0
    }
end

function MaintenanceCoordinator._determineShutdownOrder(targetProcesses, shutdownOrder)
    if shutdownOrder == "DEPENDENCY_AWARE" then
        return MaintenanceCoordinator._resolveDependencyOrder(targetProcesses, true) -- reverse for shutdown
    else
        return targetProcesses
    end
end

function MaintenanceCoordinator._resolveDependencyOrder(processes, reverse)
    -- Simple dependency resolution
    local orderedProcesses = {}
    local processed = {}
    
    local function addProcessWithDependencies(processId)
        if processed[processId] then
            return
        end
        
        local dependencies = MaintenanceCoordinator.processDependencies[processId] or {}
        for _, depId in ipairs(dependencies) do
            if not processed[depId] and MaintenanceCoordinator._containsProcess(processes, depId) then
                addProcessWithDependencies(depId)
            end
        end
        
        table.insert(orderedProcesses, processId)
        processed[processId] = true
    end
    
    for _, processId in ipairs(processes) do
        addProcessWithDependencies(processId)
    end
    
    if reverse then
        -- Reverse order for shutdown (dependents before dependencies)
        local reversedOrder = {}
        for i = #orderedProcesses, 1, -1 do
            table.insert(reversedOrder, orderedProcesses[i])
        end
        return reversedOrder
    end
    
    return orderedProcesses
end

function MaintenanceCoordinator._shutdownProcess(processId, gracePeriod, statePreservation)
    -- Simulate graceful process shutdown
    local shutdownMessage = {
        correlation = {
            id = MessageCorrelator.generateId(),
            requestType = "GRACEFUL_SHUTDOWN"
        },
        shutdown = {
            processId = processId,
            gracePeriodSeconds = gracePeriod,
            statePreservation = statePreservation
        }
    }
    
    local routingResult = MessageRouter.routeMessage(
        "GRACEFUL_SHUTDOWN",
        shutdownMessage,
        "DIRECT_ROUTE"
    )
    
    return {
        success = routingResult.success,
        processId = processId,
        shutdownTime = 0,
        statePreserved = statePreservation,
        error = routingResult.error
    }
end

function MaintenanceCoordinator._completeOperation(operation)
    local duration = operation.completionTime - operation.startTime
    
    -- Update statistics
    if operation.status == MaintenanceCoordinator.OPERATION_STATUS.COMPLETED then
        MaintenanceCoordinator.statistics.successfulOperations = MaintenanceCoordinator.statistics.successfulOperations + 1
    elseif operation.status == MaintenanceCoordinator.OPERATION_STATUS.FAILED then
        MaintenanceCoordinator.statistics.failedOperations = MaintenanceCoordinator.statistics.failedOperations + 1
    elseif operation.status == MaintenanceCoordinator.OPERATION_STATUS.ROLLED_BACK then
        MaintenanceCoordinator.statistics.rolledBackOperations = MaintenanceCoordinator.statistics.rolledBackOperations + 1
    end
    
    -- Update average operation time
    local currentAvg = MaintenanceCoordinator.statistics.averageOperationTime
    local totalOps = MaintenanceCoordinator.statistics.totalOperations
    if totalOps <= 1 then
        MaintenanceCoordinator.statistics.averageOperationTime = duration
    else
        MaintenanceCoordinator.statistics.averageOperationTime = 
            ((currentAvg * (totalOps - 1)) + duration) / totalOps
    end
    
    -- Move to history
    table.insert(MaintenanceCoordinator.operationHistory, operation)
    MaintenanceCoordinator.activeOperations[operation.id] = nil
    
    -- Manage history size
    if #MaintenanceCoordinator.operationHistory > 100 then
        table.remove(MaintenanceCoordinator.operationHistory, 1)
    end
end

function MaintenanceCoordinator._containsProcess(processes, processId)
    for _, id in ipairs(processes) do
        if id == processId then
            return true
        end
    end
    return false
end

function MaintenanceCoordinator._getTableSize(tbl)
    local count = 0
    for _ in pairs(tbl) do
        count = count + 1
    end
    return count
end


-- ===== END MODULE: admin.components.maintenance-coordinator =====


-- Process information for discovery
local PROCESS_INFO = {
    type = "ADMIN",
    version = "1.0.0",
    capabilities = {
        "system-monitoring",
        "health-tracking",
        "administrative-commands",
        "process-lifecycle-management",
        "performance-aggregation",
        "log-aggregation",
        "alert-management",
        "maintenance-coordination",
        "elevated-privileges"
    },
    description = "Administrative and monitoring process with elevated system privileges",
    endpoints = {
        "ADMIN_COMMAND",
        "HEALTH_MONITORING",
        "PERFORMANCE_QUERY",
        "LOG_AGGREGATION",
        "ALERT_MANAGEMENT",
        "MAINTENANCE_MODE",
        "PROCESS_LIFECYCLE"
    }
}

-- Global admin process state
local adminState = {
    initialized = false,
    privilegeLevel = "ADMIN",
    monitoredProcesses = {},
    activeCommands = {},
    maintenanceMode = false,
    healthStatus = "HEALTHY",
    alertsEnabled = true,
    aggregationInterval = 30, -- seconds
    lastHealthCheck = 0,
    systemMetrics = {
        overallHealth = "HEALTHY",
        processCount = 0,
        alertCount = 0,
        performanceStatus = "NORMAL"
    }
}

-- Expose globals for health checks
AdminHandlers = {
    HealthMonitor = HealthMonitor,
    AdminCommandProcessor = AdminCommandProcessor,
    PerformanceAggregator = PerformanceAggregator,
    LogAggregator = LogAggregator,
    AlertManager = AlertManager,
    MaintenanceCoordinator = MaintenanceCoordinator
}

-- Initialize admin process
local function initialize()
    print("[Admin] Initializing administrative process...")
    
    -- Initialize process coordination foundation
    MessageCorrelator.initialize()
    ProcessAuthenticator.initialize()
    MessageRouter.initialize()
    BackwardCompatibility.initialize()
    PerformanceMonitor.initialize()
    
    -- Initialize admin-specific components
    HealthMonitor.initialize()
    AdminCommandProcessor.initialize()
    PerformanceAggregator.initialize()
    LogAggregator.initialize()
    AlertManager.initialize()
    MaintenanceCoordinator.initialize()
    
    -- Register this process with elevated privileges
    local authResult = ProcessAuthenticator.registerProcess(
        ao.id or "admin-process",
        PROCESS_INFO.type,
        ao.id or "admin-wallet-address", -- Wallet address (using process ID as placeholder)
        PROCESS_INFO.capabilities
    )
    
    if authResult then
        print("[Admin] Process registered with ADMIN privileges")
    else
        print("[Admin] ERROR: Failed to register with ADMIN privileges")
        adminState.healthStatus = "DEGRADED"
    end
    
    adminState.initialized = true
    adminState.startTime = 0
    adminState.lastHealthCheck = 0
    
    -- Start background monitoring
    startBackgroundMonitoring()
    
    print("[Admin] Administrative process initialized")
    print("[Admin] Process ID: " .. (ao.id or "unknown"))
    print("[Admin] Privilege Level: " .. adminState.privilegeLevel)
    print("[Admin] Capabilities: " .. table.concat(PROCESS_INFO.capabilities, ", "))
end

-- Background monitoring function
local function startBackgroundMonitoring()
    -- This would normally be handled by a scheduler, but we'll implement
    -- periodic health checks through message handlers
    print("[Admin] Background monitoring system started")
    print("[Admin] Health check interval: " .. adminState.aggregationInterval .. " seconds")
end

-- Process information handler for discovery
Handlers.add(
    "admin-process-info",
    Handlers.utils.hasMatchingTag("Action", "Info"),
    function(msg)
        local processInfo = {
            process = PROCESS_INFO,
            state = {
                initialized = adminState.initialized,
                privilegeLevel = adminState.privilegeLevel,
                healthStatus = adminState.healthStatus,
                maintenanceMode = adminState.maintenanceMode,
                alertsEnabled = adminState.alertsEnabled,
                uptime = adminState.startTime and (0 - adminState.startTime) or 0,
                monitoredProcesses = _getTableSize(adminState.monitoredProcesses),
                activeCommands = _getTableSize(adminState.activeCommands)
            },
            systemMetrics = adminState.systemMetrics,
            statistics = {
                messageCorrelator = MessageCorrelator.getStatistics(),
                messageRouter = MessageRouter.getRoutingStatistics(),
                performanceMonitor = PerformanceMonitor.getMetrics(),
                healthMonitor = HealthMonitor.getStatistics(),
                alertManager = AlertManager.getStatistics()
            }
        }
        
        ao.send({
            Target = msg.From,
            Tags = { Action = "Info-Response" },
            Data = json.encode(processInfo)
        })
    end
)

-- Health check handler with comprehensive system status
Handlers.add(
    "admin-health-check",
    Handlers.utils.hasMatchingTag("Action", "HEALTH_CHECK"),
    function(msg)
        local healthInfo = {
            status = adminState.healthStatus,
            timestamp = msg.Timestamp,
            uptime = adminState.startTime and (0 - adminState.startTime) or 0,
            processId = ao.id or "unknown",
            version = PROCESS_INFO.version,
            privilegeLevel = adminState.privilegeLevel,
            systemMetrics = adminState.systemMetrics,
            components = {
                messageCorrelator = "HEALTHY",
                processAuthenticator = "HEALTHY",
                messageRouter = "HEALTHY",
                healthMonitor = "HEALTHY",
                adminCommandProcessor = "HEALTHY",
                performanceAggregator = "HEALTHY",
                logAggregator = "HEALTHY",
                alertManager = adminState.alertsEnabled and "HEALTHY" or "DISABLED",
                maintenanceCoordinator = "HEALTHY"
            },
            maintenanceMode = adminState.maintenanceMode,
            alertsEnabled = adminState.alertsEnabled
        }
        
        ao.send({
            Target = msg.From,
            Tags = {
                Action = "HEALTH_RESPONSE",
                CorrelationId = msg.Tags.CorrelationId or "health-check"
            },
            Data = json.encode(healthInfo)
        })
    end
)

-- System status query handler
Handlers.add(
    "system-status",
    Handlers.utils.hasMatchingTag("Action", "SYSTEM_STATUS"),
    function(msg)
        -- Authenticate admin request
        local authResult = ProcessAuthenticator.validateMessage(msg, "ADMIN")
        if not authResult.valid then
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "ERROR_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "system-status"
                },
                Data = json.encode({
                    success = false,
                    error = "Insufficient privileges for system status query",
                    requiredLevel = "ADMIN"
                })
            })
            return
        end
        
        local systemStatus = {
            timestamp = msg.Timestamp,
            overallHealth = adminState.systemMetrics.overallHealth,
            processCount = adminState.systemMetrics.processCount,
            alertCount = adminState.systemMetrics.alertCount,
            performanceStatus = adminState.systemMetrics.performanceStatus,
            maintenanceMode = adminState.maintenanceMode,
            monitoredProcesses = HealthMonitor.getProcessSummary(),
            recentAlerts = AlertManager.getRecentAlerts(10),
            performanceMetrics = PerformanceAggregator.getSystemMetrics(),
            logSummary = LogAggregator.getLogSummary()
        }
        
        ao.send({
            Target = msg.From,
            Tags = {
                Action = "SYSTEM_STATUS_RESPONSE",
                CorrelationId = msg.Tags.CorrelationId or "system-status"
            },
            Data = json.encode({
                success = true,
                systemStatus = systemStatus
            })
        })
    end
)

-- Maintenance mode toggle handler
Handlers.add(
    "maintenance-mode",
    Handlers.utils.hasMatchingTag("Action", "MAINTENANCE_MODE"),
    function(msg)
        -- Authenticate admin request
        local authResult = ProcessAuthenticator.validateMessage(msg, "ADMIN")
        if not authResult.valid then
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "ERROR_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "maintenance-mode"
                },
                Data = json.encode({
                    success = false,
                    error = "Insufficient privileges for maintenance mode control",
                    requiredLevel = "ADMIN"
                })
            })
            return
        end
        
        local requestData = json.decode(msg.Data)
        if not requestData then
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "ERROR_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "maintenance-mode"
                },
                Data = json.encode({
                    success = false,
                    error = "Invalid request data"
                })
            })
            return
        end
        
        local previousMode = adminState.maintenanceMode
        local newMode = requestData.enabled or false
        
        -- Coordinate maintenance mode with maintenance coordinator
        local coordinationResult = MaintenanceCoordinator.setMaintenanceMode(newMode, requestData.reason)
        
        if coordinationResult.success then
            adminState.maintenanceMode = newMode
            
            -- Log maintenance mode change
            LogAggregator.logEvent({
                level = "INFO",
                component = "MaintenanceMode",
                message = "Maintenance mode " .. (newMode and "enabled" or "disabled"),
                adminUserId = authResult.userId,
                reason = requestData.reason
            })
            
            -- Send alert about maintenance mode change
            if adminState.alertsEnabled then
                AlertManager.generateAlert({
                    type = "MAINTENANCE_MODE",
                    severity = "INFO",
                    message = "System maintenance mode " .. (newMode and "enabled" or "disabled"),
                    details = {
                        previousMode = previousMode,
                        newMode = newMode,
                        reason = requestData.reason,
                        adminUserId = authResult.userId
                    }
                })
            end
            
            print("[Admin] Maintenance mode " .. (newMode and "enabled" or "disabled") .. 
                  " by " .. (authResult.userId or "unknown"))
        end
        
        ao.send({
            Target = msg.From,
            Tags = {
                Action = "MAINTENANCE_MODE_RESPONSE",
                CorrelationId = msg.Tags.CorrelationId or "maintenance-mode"
            },
            Data = json.encode({
                success = coordinationResult.success,
                previousMode = previousMode,
                newMode = adminState.maintenanceMode,
                timestamp = msg.Timestamp,
                error = coordinationResult.error
            })
        })
    end
)

-- Periodic health check trigger handler
Handlers.add(
    "periodic-health-check",
    Handlers.utils.hasMatchingTag("Action", "PERIODIC_HEALTH_CHECK"),
    function(msg)
        local currentTime = 0
        
        -- Check if enough time has passed since last health check
        if currentTime - adminState.lastHealthCheck >= adminState.aggregationInterval then
            adminState.lastHealthCheck = currentTime
            
            -- Trigger comprehensive system health check
            local healthResults = HealthMonitor.performSystemHealthCheck()
            local performanceMetrics = PerformanceAggregator.collectSystemMetrics()
            
            -- Update system metrics
            adminState.systemMetrics.overallHealth = healthResults.overallHealth
            adminState.systemMetrics.processCount = healthResults.processCount
            adminState.systemMetrics.performanceStatus = performanceMetrics.status
            
            -- Generate alerts if needed
            if adminState.alertsEnabled then
                AlertManager.processHealthResults(healthResults)
                AlertManager.processPerformanceMetrics(performanceMetrics)
            end
            
            print("[Admin] Periodic health check completed: " .. healthResults.overallHealth)
        end
        
        ao.send({
            Target = msg.From,
            Tags = {
                Action = "HEALTH_CHECK_RESPONSE",
                CorrelationId = msg.Tags.CorrelationId or "periodic-health-check"
            },
            Data = json.encode({
                success = true,
                lastCheckTime = adminState.lastHealthCheck,
                nextCheckDue = adminState.lastHealthCheck + adminState.aggregationInterval
            })
        })
    end
)

-- Error handler
Handlers.add(
    "admin-error-handler",
    function(msg)
        -- Catch-all error handler for unhandled messages
        return not (msg.Tags.Action and (
            msg.Tags.Action == "ADMIN_COMMAND" or
            msg.Tags.Action == "HEALTH_MONITORING" or
            msg.Tags.Action == "PERFORMANCE_QUERY" or
            msg.Tags.Action == "LOG_AGGREGATION" or
            msg.Tags.Action == "ALERT_MANAGEMENT" or
            msg.Tags.Action == "MAINTENANCE_MODE" or
            msg.Tags.Action == "PROCESS_LIFECYCLE" or
            msg.Tags.Action == "Info" or
            msg.Tags.Action == "HEALTH_CHECK" or
            msg.Tags.Action == "SYSTEM_STATUS" or
            msg.Tags.Action == "PERIODIC_HEALTH_CHECK"
        ))
    end,
    function(msg)
        print("[Admin] Unhandled message: Action=" .. (msg.Tags.Action or "nil"))
        
        -- Log unhandled message
        LogAggregator.logEvent({
            level = "WARN",
            component = "MessageHandler",
            message = "Unhandled message received",
            action = msg.Tags.Action,
            from = msg.From
        })
        
        if msg.From and msg.Tags.Action then
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "ERROR_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "unknown"
                },
                Data = json.encode({
                    success = false,
                    error = "Unsupported action",
                    action = msg.Tags.Action
                })
            })
        end
    end
)

-- Private helper functions

local function _getTableSize(tbl)
    local count = 0
    for _ in pairs(tbl) do
        count = count + 1
    end
    return count
end

-- Load admin-specific handlers

-- ===== MODULE: admin.handlers.admin-monitoring-handler =====
-- File: ao-processes/admin/handlers/admin-monitoring-handler.lua
-- Original require: require("admin.handlers.admin-monitoring-handler")

-- Admin Monitoring Handler
-- Handles health and performance monitoring operations for the administrative process


-- ===== MODULE: game-logic.process-coordination.message-correlator =====
-- File: ao-processes/game-logic/process-coordination/message-correlator.lua
-- Original require: local MessageCorrelator = require("game-logic.process-coordination.message-correlator")


-- ===== END MODULE: game-logic.process-coordination.message-correlator =====


-- ===== MODULE: game-logic.process-coordination.process-authenticator =====
-- File: ao-processes/game-logic/process-coordination/process-authenticator.lua
-- Original require: local ProcessAuthenticator = require("game-logic.process-coordination.process-authenticator")


-- ===== END MODULE: game-logic.process-coordination.process-authenticator =====


-- ===== MODULE: admin.components.health-monitor =====
-- File: ao-processes/admin/components/health-monitor.lua
-- Original require: local HealthMonitor = require("admin.components.health-monitor")


-- ===== END MODULE: admin.components.health-monitor =====


-- ===== MODULE: admin.components.performance-aggregator =====
-- File: ao-processes/admin/components/performance-aggregator.lua
-- Original require: local PerformanceAggregator = require("admin.components.performance-aggregator")


-- ===== END MODULE: admin.components.performance-aggregator =====


-- ===== MODULE: admin.components.alert-manager =====
-- File: ao-processes/admin/components/alert-manager.lua
-- Original require: local AlertManager = require("admin.components.alert-manager")


-- ===== END MODULE: admin.components.alert-manager =====


-- Health monitoring query handler
Handlers.add(
    "health-monitoring-query",
    Handlers.utils.hasMatchingTag("Action", "HEALTH_MONITORING"),
    function(msg)
        -- Authenticate monitoring request
        local authResult = ProcessAuthenticator.validateMessage(msg, "ELEVATED")
        if not authResult.valid then
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "ERROR_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "health-monitoring"
                },
                Data = json.encode({
                    success = false,
                    error = "Insufficient privileges for health monitoring",
                    requiredLevel = "ELEVATED"
                })
            })
            return
        end
        
        local queryData = json.decode(msg.Data)
        local correlationId = MessageCorrelator.generateId()
        
        local queryType = queryData and queryData.queryType or "FULL_HEALTH"
        local targetProcessId = queryData and queryData.processId
        local includePerformance = queryData and queryData.includePerformance or true
        local includeLogs = queryData and queryData.includeLogs or false
        
        local healthResults = {}
        
        if targetProcessId then
            -- Query specific process health
            local processHealth = HealthMonitor.getProcessHealth(targetProcessId)
            if processHealth then
                healthResults[targetProcessId] = processHealth
                
                if includePerformance then
                    healthResults[targetProcessId].performanceMetrics = 
                        PerformanceAggregator.getProcessMetrics(targetProcessId)
                end
            else
                ao.send({
                    Target = msg.From,
                    Tags = {
                        Action = "HEALTH_MONITORING_RESPONSE",
                        CorrelationId = msg.Tags.CorrelationId or "health-monitoring"
                    },
                    Data = json.encode({
                        success = false,
                        error = "Process not found or not monitored: " .. targetProcessId
                    })
                })
                return
            end
        else
            -- Query all monitored processes
            if queryType == "FULL_HEALTH" or queryType == "STATUS_ONLY" then
                healthResults = HealthMonitor.getAllProcessHealth()
                
                if includePerformance and queryType == "FULL_HEALTH" then
                    for processId in pairs(healthResults) do
                        healthResults[processId].performanceMetrics = 
                            PerformanceAggregator.getProcessMetrics(processId)
                    end
                end
            elseif queryType == "METRICS_ONLY" then
                healthResults = PerformanceAggregator.getAllProcessMetrics()
            end
        end
        
        local responseData = {
            success = true,
            correlationId = correlationId,
            timestamp = msg.Timestamp,
            queryType = queryType,
            healthResults = healthResults,
            systemSummary = {
                totalMonitoredProcesses = HealthMonitor.getMonitoredProcessCount(),
                overallHealthStatus = HealthMonitor.getOverallHealthStatus(),
                activeAlerts = AlertManager.getActiveAlertCount(),
                performanceStatus = PerformanceAggregator.getSystemPerformanceStatus()
            }
        }
        
        ao.send({
            Target = msg.From,
            Tags = {
                Action = "HEALTH_MONITORING_RESPONSE",
                CorrelationId = msg.Tags.CorrelationId or "health-monitoring"
            },
            Data = json.encode(responseData)
        })
        
        print("[AdminMonitoringHandler] Health monitoring query processed for " .. msg.From)
    end
)

-- Performance monitoring query handler
Handlers.add(
    "performance-query",
    Handlers.utils.hasMatchingTag("Action", "PERFORMANCE_QUERY"),
    function(msg)
        -- Authenticate performance query
        local authResult = ProcessAuthenticator.validateMessage(msg, "ELEVATED")
        if not authResult.valid then
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "ERROR_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "performance-query"
                },
                Data = json.encode({
                    success = false,
                    error = "Insufficient privileges for performance monitoring",
                    requiredLevel = "ELEVATED"
                })
            })
            return
        end
        
        local queryData = json.decode(msg.Data)
        local metricType = queryData and queryData.metricType or "ALL"
        local timeRange = queryData and queryData.timeRange
        local targetProcessId = queryData and queryData.processId
        
        local performanceData = {}
        
        if targetProcessId then
            -- Get metrics for specific process
            performanceData[targetProcessId] = PerformanceAggregator.getProcessMetrics(
                targetProcessId, metricType, timeRange
            )
        else
            -- Get system-wide metrics
            performanceData = PerformanceAggregator.getSystemMetrics(metricType, timeRange)
        end
        
        local responseData = {
            success = true,
            timestamp = msg.Timestamp,
            metricType = metricType,
            timeRange = timeRange,
            performanceData = performanceData,
            systemAnalysis = {
                bottlenecks = PerformanceAggregator.identifyBottlenecks(),
                trends = PerformanceAggregator.getTrendAnalysis(timeRange),
                recommendations = PerformanceAggregator.getOptimizationRecommendations()
            }
        }
        
        ao.send({
            Target = msg.From,
            Tags = {
                Action = "PERFORMANCE_QUERY_RESPONSE",
                CorrelationId = msg.Tags.CorrelationId or "performance-query"
            },
            Data = json.encode(responseData)
        })
        
        print("[AdminMonitoringHandler] Performance query processed for " .. msg.From)
    end
)

-- Alert management handler
Handlers.add(
    "alert-management",
    Handlers.utils.hasMatchingTag("Action", "ALERT_MANAGEMENT"),
    function(msg)
        -- Authenticate alert management request
        local authResult = ProcessAuthenticator.validateMessage(msg, "ADMIN")
        if not authResult.valid then
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "ERROR_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "alert-management"
                },
                Data = json.encode({
                    success = false,
                    error = "Insufficient privileges for alert management",
                    requiredLevel = "ADMIN"
                })
            })
            return
        end
        
        local alertData = json.decode(msg.Data)
        if not alertData or not alertData.operation then
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "ERROR_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "alert-management"
                },
                Data = json.encode({
                    success = false,
                    error = "Operation parameter is required"
                })
            })
            return
        end
        
        local operation = alertData.operation
        local result = {}
        
        if operation == "GET_ALERTS" then
            local alertCount = alertData.count or 50
            local severity = alertData.severity
            result = {
                alerts = AlertManager.getRecentAlerts(alertCount, severity),
                totalActiveAlerts = AlertManager.getActiveAlertCount()
            }
        elseif operation == "UPDATE_THRESHOLDS" then
            local thresholds = alertData.thresholds
            if thresholds then
                result = AlertManager.updateAlertThresholds(thresholds)
            else
                result = { success = false, error = "Thresholds parameter is required" }
            end
        elseif operation == "ACKNOWLEDGE_ALERT" then
            local alertId = alertData.alertId
            if alertId then
                result = AlertManager.acknowledgeAlert(alertId, authResult.userId)
            else
                result = { success = false, error = "Alert ID is required" }
            end
        elseif operation == "CLEAR_ALERT" then
            local alertId = alertData.alertId
            if alertId then
                result = AlertManager.clearAlert(alertId, authResult.userId)
            else
                result = { success = false, error = "Alert ID is required" }
            end
        elseif operation == "CONFIGURE_NOTIFICATIONS" then
            local notificationConfig = alertData.notificationConfig
            if notificationConfig then
                result = AlertManager.configureNotifications(notificationConfig)
            else
                result = { success = false, error = "Notification configuration is required" }
            end
        else
            result = { success = false, error = "Unsupported operation: " .. operation }
        end
        
        ao.send({
            Target = msg.From,
            Tags = {
                Action = "ALERT_MANAGEMENT_RESPONSE",
                CorrelationId = msg.Tags.CorrelationId or "alert-management"
            },
            Data = json.encode({
                success = result.success ~= false,
                operation = operation,
                result = result,
                timestamp = 0
            })
        })
        
        print("[AdminMonitoringHandler] Alert management operation '" .. operation .. "' processed")
    end
)

-- Health threshold configuration handler
Handlers.add(
    "health-threshold-config",
    Handlers.utils.hasMatchingTag("Action", "HEALTH_THRESHOLD_CONFIG"),
    function(msg)
        -- Authenticate threshold configuration
        local authResult = ProcessAuthenticator.validateMessage(msg, "ADMIN")
        if not authResult.valid then
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "ERROR_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "health-threshold-config"
                },
                Data = json.encode({
                    success = false,
                    error = "Insufficient privileges for threshold configuration",
                    requiredLevel = "ADMIN"
                })
            })
            return
        end
        
        local configData = json.decode(msg.Data)
        if not configData then
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "ERROR_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "health-threshold-config"
                },
                Data = json.encode({
                    success = false,
                    error = "Configuration data is required"
                })
            })
            return
        end
        
        local result = {}
        
        if configData.healthThresholds then
            result.healthUpdate = HealthMonitor.updateThresholds(configData.healthThresholds)
        end
        
        if configData.performanceThresholds then
            result.performanceUpdate = PerformanceAggregator.updateThresholds(configData.performanceThresholds)
        end
        
        if configData.alertThresholds then
            result.alertUpdate = AlertManager.updateAlertThresholds(configData.alertThresholds)
        end
        
        ao.send({
            Target = msg.From,
            Tags = {
                Action = "HEALTH_THRESHOLD_CONFIG_RESPONSE",
                CorrelationId = msg.Tags.CorrelationId or "health-threshold-config"
            },
            Data = json.encode({
                success = true,
                configurationResults = result,
                timestamp = 0
            })
        })
        
        print("[AdminMonitoringHandler] Health threshold configuration updated by " .. 
              (authResult.userId or "unknown"))
    end
)

-- Monitoring statistics handler
Handlers.add(
    "monitoring-statistics",
    Handlers.utils.hasMatchingTag("Action", "MONITORING_STATISTICS"),
    function(msg)
        -- Authenticate statistics request
        local authResult = ProcessAuthenticator.validateMessage(msg, "ELEVATED")
        if not authResult.valid then
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "ERROR_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "monitoring-statistics"
                },
                Data = json.encode({
                    success = false,
                    error = "Insufficient privileges for monitoring statistics",
                    requiredLevel = "ELEVATED"
                })
            })
            return
        end
        
        local statistics = {
            healthMonitoring = HealthMonitor.getStatistics(),
            performanceAggregation = PerformanceAggregator.getStatistics(),
            alertManagement = AlertManager.getStatistics(),
            systemOverview = {
                monitoredProcessCount = HealthMonitor.getMonitoredProcessCount(),
                overallHealthStatus = HealthMonitor.getOverallHealthStatus(),
                activeAlertCount = AlertManager.getActiveAlertCount(),
                performanceStatus = PerformanceAggregator.getSystemPerformanceStatus(),
                uptimeSeconds = 0 - (0 - 3600) -- Placeholder uptime calculation
            }
        }
        
        ao.send({
            Target = msg.From,
            Tags = {
                Action = "MONITORING_STATISTICS_RESPONSE",
                CorrelationId = msg.Tags.CorrelationId or "monitoring-statistics"
            },
            Data = json.encode({
                success = true,
                statistics = statistics,
                timestamp = 0
            })
        })
        
        print("[AdminMonitoringHandler] Monitoring statistics provided to " .. msg.From)
    end
)


-- ===== END MODULE: admin.handlers.admin-monitoring-handler =====


-- ===== MODULE: admin.handlers.admin-command-handler =====
-- File: ao-processes/admin/handlers/admin-command-handler.lua
-- Original require: require("admin.handlers.admin-command-handler")

-- Admin Command Handler
-- Handles administrative command execution across distributed processes


-- ===== MODULE: game-logic.process-coordination.message-correlator =====
-- File: ao-processes/game-logic/process-coordination/message-correlator.lua
-- Original require: local MessageCorrelator = require("game-logic.process-coordination.message-correlator")


-- ===== END MODULE: game-logic.process-coordination.message-correlator =====


-- ===== MODULE: game-logic.process-coordination.process-authenticator =====
-- File: ao-processes/game-logic/process-coordination/process-authenticator.lua
-- Original require: local ProcessAuthenticator = require("game-logic.process-coordination.process-authenticator")


-- ===== END MODULE: game-logic.process-coordination.process-authenticator =====


-- ===== MODULE: game-logic.process-coordination.message-router =====
-- File: ao-processes/game-logic/process-coordination/message-router.lua
-- Original require: local MessageRouter = require("game-logic.process-coordination.message-router")


-- ===== END MODULE: game-logic.process-coordination.message-router =====


-- ===== MODULE: admin.components.admin-command-processor =====
-- File: ao-processes/admin/components/admin-command-processor.lua
-- Original require: local AdminCommandProcessor = require("admin.components.admin-command-processor")


-- ===== END MODULE: admin.components.admin-command-processor =====


-- ===== MODULE: admin.components.log-aggregator =====
-- File: ao-processes/admin/components/log-aggregator.lua
-- Original require: local LogAggregator = require("admin.components.log-aggregator")


-- ===== END MODULE: admin.components.log-aggregator =====


-- ===== MODULE: admin.components.alert-manager =====
-- File: ao-processes/admin/components/alert-manager.lua
-- Original require: local AlertManager = require("admin.components.alert-manager")


-- ===== END MODULE: admin.components.alert-manager =====


-- Administrative command execution handler
Handlers.add(
    "admin-command",
    Handlers.utils.hasMatchingTag("Action", "ADMIN_COMMAND"),
    function(msg)
        -- Authenticate admin command
        local authResult = ProcessAuthenticator.validateMessage(msg, "ADMIN")
        if not authResult.valid then
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "ERROR_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "admin-command"
                },
                Data = json.encode({
                    success = false,
                    error = "Insufficient privileges for administrative commands",
                    requiredLevel = "ADMIN"
                })
            })
            return
        end
        
        local commandData = json.decode(msg.Data)
        if not commandData or not commandData.adminCommand then
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "ERROR_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "admin-command"
                },
                Data = json.encode({
                    success = false,
                    error = "Administrative command data is required"
                })
            })
            return
        end
        
        local adminCommand = commandData.adminCommand
        local correlationId = MessageCorrelator.generateId()
        
        -- Validate command structure
        if not adminCommand.commandType then
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "ERROR_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "admin-command"
                },
                Data = json.encode({
                    success = false,
                    error = "Command type is required"
                })
            })
            return
        end
        
        local commandType = adminCommand.commandType
        local targetProcesses = adminCommand.targetProcesses or {}
        local executionMode = adminCommand.executionMode or "IMMEDIATE"
        local commandParams = adminCommand.commandParams or {}
        
        -- Log command execution attempt
        LogAggregator.logEvent({
            level = "INFO",
            component = "AdminCommand",
            message = "Administrative command initiated: " .. commandType,
            adminUserId = authResult.userId,
            correlationId = correlationId,
            targetProcesses = targetProcesses,
            executionMode = executionMode
        })
        
        -- Execute administrative command
        local executionResult = AdminCommandProcessor.executeCommand({
            commandId = correlationId,
            commandType = commandType,
            targetProcesses = targetProcesses,
            executionMode = executionMode,
            commandParams = commandParams,
            adminUserId = authResult.userId,
            correlationId = correlationId
        })
        
        -- Generate alert for critical commands
        local criticalCommands = {"SHUTDOWN", "RESTART", "MAINTENANCE", "ROLLBACK"}
        local isCritical = false
        for _, criticalCmd in ipairs(criticalCommands) do
            if commandType == criticalCmd then
                isCritical = true
                break
            end
        end
        
        if isCritical then
            AlertManager.generateAlert({
                type = "ADMIN_COMMAND",
                severity = "WARNING",
                message = "Critical administrative command executed: " .. commandType,
                details = {
                    commandType = commandType,
                    targetProcesses = targetProcesses,
                    adminUserId = authResult.userId,
                    executionResult = executionResult.success and "SUCCESS" or "FAILED"
                }
            })
        end
        
        -- Send command execution result
        ao.send({
            Target = msg.From,
            Tags = {
                Action = "ADMIN_COMMAND_RESPONSE",
                CorrelationId = msg.Tags.CorrelationId or "admin-command"
            },
            Data = json.encode({
                success = executionResult.success,
                commandId = correlationId,
                commandType = commandType,
                executionStatus = executionResult.status,
                affectedProcesses = executionResult.affectedProcesses,
                executionDetails = executionResult.details,
                rollbackAvailable = executionResult.rollbackAvailable,
                timestamp = msg.Timestamp,
                error = executionResult.error
            })
        })
        
        print("[AdminCommandHandler] Command '" .. commandType .. "' executed by " .. 
              (authResult.userId or "unknown") .. " - Status: " .. (executionResult.status or "UNKNOWN"))
    end
)

-- Command status query handler
Handlers.add(
    "command-status-query",
    Handlers.utils.hasMatchingTag("Action", "COMMAND_STATUS_QUERY"),
    function(msg)
        -- Authenticate status query
        local authResult = ProcessAuthenticator.validateMessage(msg, "ELEVATED")
        if not authResult.valid then
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "ERROR_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "command-status-query"
                },
                Data = json.encode({
                    success = false,
                    error = "Insufficient privileges for command status query",
                    requiredLevel = "ELEVATED"
                })
            })
            return
        end
        
        local queryData = json.decode(msg.Data)
        local commandId = queryData and queryData.commandId
        
        if commandId then
            -- Get status for specific command
            local commandStatus = AdminCommandProcessor.getCommandStatus(commandId)
            
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "COMMAND_STATUS_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "command-status-query"
                },
                Data = json.encode({
                    success = true,
                    commandId = commandId,
                    commandStatus = commandStatus,
                    timestamp = 0
                })
            })
        else
            -- Get all active commands
            local activeCommands = AdminCommandProcessor.getActiveCommands()
            local recentCommands = AdminCommandProcessor.getRecentCommands(20)
            
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "COMMAND_STATUS_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "command-status-query"
                },
                Data = json.encode({
                    success = true,
                    activeCommands = activeCommands,
                    recentCommands = recentCommands,
                    timestamp = 0
                })
            })
        end
        
        print("[AdminCommandHandler] Command status query processed for " .. msg.From)
    end
)

-- Command rollback handler
Handlers.add(
    "command-rollback",
    Handlers.utils.hasMatchingTag("Action", "COMMAND_ROLLBACK"),
    function(msg)
        -- Authenticate rollback request
        local authResult = ProcessAuthenticator.validateMessage(msg, "ADMIN")
        if not authResult.valid then
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "ERROR_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "command-rollback"
                },
                Data = json.encode({
                    success = false,
                    error = "Insufficient privileges for command rollback",
                    requiredLevel = "ADMIN"
                })
            })
            return
        end
        
        local rollbackData = json.decode(msg.Data)
        if not rollbackData or not rollbackData.commandId then
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "ERROR_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "command-rollback"
                },
                Data = json.encode({
                    success = false,
                    error = "Command ID is required for rollback"
                })
            })
            return
        end
        
        local commandId = rollbackData.commandId
        local rollbackReason = rollbackData.reason or "Manual rollback request"
        
        -- Log rollback attempt
        LogAggregator.logEvent({
            level = "WARN",
            component = "AdminCommand",
            message = "Command rollback initiated",
            adminUserId = authResult.userId,
            commandId = commandId,
            reason = rollbackReason
        })
        
        -- Execute rollback
        local rollbackResult = AdminCommandProcessor.rollbackCommand(commandId, {
            adminUserId = authResult.userId,
            reason = rollbackReason
        })
        
        -- Generate alert for rollback
        AlertManager.generateAlert({
            type = "COMMAND_ROLLBACK",
            severity = rollbackResult.success and "INFO" or "ERROR",
            message = "Administrative command rollback " .. (rollbackResult.success and "completed" or "failed"),
            details = {
                commandId = commandId,
                reason = rollbackReason,
                adminUserId = authResult.userId,
                rollbackResult = rollbackResult.success and "SUCCESS" or "FAILED"
            }
        })
        
        ao.send({
            Target = msg.From,
            Tags = {
                Action = "COMMAND_ROLLBACK_RESPONSE",
                CorrelationId = msg.Tags.CorrelationId or "command-rollback"
            },
            Data = json.encode({
                success = rollbackResult.success,
                commandId = commandId,
                rollbackStatus = rollbackResult.status,
                rollbackDetails = rollbackResult.details,
                affectedProcesses = rollbackResult.affectedProcesses,
                timestamp = msg.Timestamp,
                error = rollbackResult.error
            })
        })
        
        print("[AdminCommandHandler] Rollback for command '" .. commandId .. "' " .. 
              (rollbackResult.success and "completed" or "failed"))
    end
)

-- Process shutdown command handler
Handlers.add(
    "process-shutdown",
    Handlers.utils.hasMatchingTag("Action", "PROCESS_SHUTDOWN"),
    function(msg)
        -- Authenticate shutdown command
        local authResult = ProcessAuthenticator.validateMessage(msg, "ADMIN")
        if not authResult.valid then
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "ERROR_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "process-shutdown"
                },
                Data = json.encode({
                    success = false,
                    error = "Insufficient privileges for process shutdown",
                    requiredLevel = "ADMIN"
                })
            })
            return
        end
        
        local shutdownData = json.decode(msg.Data)
        if not shutdownData or not shutdownData.targetProcesses then
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "ERROR_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "process-shutdown"
                },
                Data = json.encode({
                    success = false,
                    error = "Target processes are required"
                })
            })
            return
        end
        
        local targetProcesses = shutdownData.targetProcesses
        local gracefulShutdown = shutdownData.gracefulShutdown ~= false
        local shutdownReason = shutdownData.reason or "Administrative shutdown"
        
        -- Execute shutdown command
        local shutdownResult = AdminCommandProcessor.executeCommand({
            commandType = "SHUTDOWN",
            targetProcesses = targetProcesses,
            commandParams = {
                gracefulShutdown = gracefulShutdown,
                reason = shutdownReason,
                statePreservation = shutdownData.statePreservation
            },
            adminUserId = authResult.userId
        })
        
        ao.send({
            Target = msg.From,
            Tags = {
                Action = "PROCESS_SHUTDOWN_RESPONSE",
                CorrelationId = msg.Tags.CorrelationId or "process-shutdown"
            },
            Data = json.encode({
                success = shutdownResult.success,
                shutdownStatus = shutdownResult.status,
                affectedProcesses = shutdownResult.affectedProcesses,
                timestamp = msg.Timestamp,
                error = shutdownResult.error
            })
        })
        
        print("[AdminCommandHandler] Process shutdown executed for " .. #targetProcesses .. " processes")
    end
)

-- Process restart command handler
Handlers.add(
    "process-restart",
    Handlers.utils.hasMatchingTag("Action", "PROCESS_RESTART"),
    function(msg)
        -- Authenticate restart command
        local authResult = ProcessAuthenticator.validateMessage(msg, "ADMIN")
        if not authResult.valid then
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "ERROR_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "process-restart"
                },
                Data = json.encode({
                    success = false,
                    error = "Insufficient privileges for process restart",
                    requiredLevel = "ADMIN"
                })
            })
            return
        end
        
        local restartData = json.decode(msg.Data)
        if not restartData or not restartData.targetProcesses then
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "ERROR_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "process-restart"
                },
                Data = json.encode({
                    success = false,
                    error = "Target processes are required"
                })
            })
            return
        end
        
        local targetProcesses = restartData.targetProcesses
        local restartReason = restartData.reason or "Administrative restart"
        
        -- Execute restart command
        local restartResult = AdminCommandProcessor.executeCommand({
            commandType = "RESTART",
            targetProcesses = targetProcesses,
            commandParams = {
                reason = restartReason,
                stateRestore = restartData.stateRestore,
                configUpdate = restartData.configUpdate
            },
            adminUserId = authResult.userId
        })
        
        ao.send({
            Target = msg.From,
            Tags = {
                Action = "PROCESS_RESTART_RESPONSE",
                CorrelationId = msg.Tags.CorrelationId or "process-restart"
            },
            Data = json.encode({
                success = restartResult.success,
                restartStatus = restartResult.status,
                affectedProcesses = restartResult.affectedProcesses,
                timestamp = msg.Timestamp,
                error = restartResult.error
            })
        })
        
        print("[AdminCommandHandler] Process restart executed for " .. #targetProcesses .. " processes")
    end
)


-- ===== END MODULE: admin.handlers.admin-command-handler =====


-- ===== MODULE: admin.handlers.admin-deployment-handler =====
-- File: ao-processes/admin/handlers/admin-deployment-handler.lua
-- Original require: require("admin.handlers.admin-deployment-handler")

-- Admin Deployment Handler
-- Handles process lifecycle management, deployment coordination, and rollback operations


-- ===== MODULE: game-logic.process-coordination.message-correlator =====
-- File: ao-processes/game-logic/process-coordination/message-correlator.lua
-- Original require: local MessageCorrelator = require("game-logic.process-coordination.message-correlator")


-- ===== END MODULE: game-logic.process-coordination.message-correlator =====


-- ===== MODULE: game-logic.process-coordination.process-authenticator =====
-- File: ao-processes/game-logic/process-coordination/process-authenticator.lua
-- Original require: local ProcessAuthenticator = require("game-logic.process-coordination.process-authenticator")


-- ===== END MODULE: game-logic.process-coordination.process-authenticator =====


-- ===== MODULE: game-logic.process-coordination.message-router =====
-- File: ao-processes/game-logic/process-coordination/message-router.lua
-- Original require: local MessageRouter = require("game-logic.process-coordination.message-router")


-- ===== END MODULE: game-logic.process-coordination.message-router =====


-- ===== MODULE: admin.components.maintenance-coordinator =====
-- File: ao-processes/admin/components/maintenance-coordinator.lua
-- Original require: local MaintenanceCoordinator = require("admin.components.maintenance-coordinator")


-- ===== END MODULE: admin.components.maintenance-coordinator =====


-- ===== MODULE: admin.components.log-aggregator =====
-- File: ao-processes/admin/components/log-aggregator.lua
-- Original require: local LogAggregator = require("admin.components.log-aggregator")


-- ===== END MODULE: admin.components.log-aggregator =====


-- ===== MODULE: admin.components.alert-manager =====
-- File: ao-processes/admin/components/alert-manager.lua
-- Original require: local AlertManager = require("admin.components.alert-manager")


-- ===== END MODULE: admin.components.alert-manager =====


-- Private helper functions (forward declared)

local function handleProcessDeployment(targetProcesses, params, adminUserId)
    return MaintenanceCoordinator.deployProcesses({
        targetProcesses = targetProcesses,
        deploymentConfig = params.deploymentConfig,
        validationSteps = params.validationSteps,
        rollbackOnFailure = params.rollbackOnFailure,
        adminUserId = adminUserId
    })
end

local function handleProcessUpdate(targetProcesses, params, adminUserId)
    return MaintenanceCoordinator.updateProcesses({
        targetProcesses = targetProcesses,
        updateConfig = params.updateConfig,
        updateStrategy = params.updateStrategy or "ROLLING",
        validationRequired = params.validationRequired,
        adminUserId = adminUserId
    })
end

local function handleProcessRollback(targetProcesses, params, adminUserId)
    return MaintenanceCoordinator.rollbackProcesses({
        targetProcesses = targetProcesses,
        rollbackPoint = params.rollbackPoint,
        rollbackStrategy = params.rollbackStrategy or "IMMEDIATE",
        stateRestoration = params.stateRestoration,
        adminUserId = adminUserId
    })
end

local function handleProcessScaling(targetProcesses, params, adminUserId)
    return MaintenanceCoordinator.scaleProcesses({
        targetProcesses = targetProcesses,
        scalingAction = params.scalingAction, -- SCALE_UP, SCALE_DOWN, AUTO_SCALE
        targetCapacity = params.targetCapacity,
        scalingPolicy = params.scalingPolicy,
        adminUserId = adminUserId
    })
end

local function handleProcessMigration(targetProcesses, params, adminUserId)
    return MaintenanceCoordinator.migrateProcesses({
        targetProcesses = targetProcesses,
        migrationPlan = params.migrationPlan,
        migrationStrategy = params.migrationStrategy or "BLUE_GREEN",
        dataTransferRequired = params.dataTransferRequired,
        adminUserId = adminUserId
    })
end

-- Process lifecycle management handler
Handlers.add(
    "process-lifecycle",
    Handlers.utils.hasMatchingTag("Action", "PROCESS_LIFECYCLE"),
    function(msg)
        -- Authenticate lifecycle management request
        local authResult = ProcessAuthenticator.validateMessage(msg, "ADMIN")
        if not authResult.valid then
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "ERROR_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "process-lifecycle"
                },
                Data = json.encode({
                    success = false,
                    error = "Insufficient privileges for process lifecycle management",
                    requiredLevel = "ADMIN"
                })
            })
            return
        end
        
        local lifecycleData = json.decode(msg.Data)
        if not lifecycleData or not lifecycleData.operation then
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "ERROR_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "process-lifecycle"
                },
                Data = json.encode({
                    success = false,
                    error = "Lifecycle operation is required"
                })
            })
            return
        end
        
        local operation = lifecycleData.operation
        local targetProcesses = lifecycleData.targetProcesses or {}
        local operationParams = lifecycleData.operationParams or {}
        local correlationId = MessageCorrelator.generateId()
        
        -- Log lifecycle operation
        LogAggregator.logEvent({
            level = "INFO",
            component = "ProcessLifecycle",
            message = "Process lifecycle operation initiated: " .. operation,
            adminUserId = authResult.userId,
            correlationId = correlationId,
            targetProcesses = targetProcesses,
            operation = operation
        })
        
        local result = {}
        
        if operation == "DEPLOY" then
            result = handleProcessDeployment(targetProcesses, operationParams, authResult.userId)
        elseif operation == "UPDATE" then
            result = handleProcessUpdate(targetProcesses, operationParams, authResult.userId)
        elseif operation == "ROLLBACK" then
            result = handleProcessRollback(targetProcesses, operationParams, authResult.userId)
        elseif operation == "SCALE" then
            result = handleProcessScaling(targetProcesses, operationParams, authResult.userId)
        elseif operation == "MIGRATE" then
            result = handleProcessMigration(targetProcesses, operationParams, authResult.userId)
        else
            result = { success = false, error = "Unsupported lifecycle operation: " .. operation }
        end
        
        -- Generate alert for critical operations
        local criticalOperations = {"DEPLOY", "ROLLBACK", "MIGRATE"}
        local isCritical = false
        for _, criticalOp in ipairs(criticalOperations) do
            if operation == criticalOp then
                isCritical = true
                break
            end
        end
        
        if isCritical then
            AlertManager.generateAlert({
                type = "PROCESS_LIFECYCLE",
                severity = result.success and "INFO" or "ERROR",
                message = "Process lifecycle operation " .. (result.success and "completed" or "failed") .. ": " .. operation,
                details = {
                    operation = operation,
                    targetProcesses = targetProcesses,
                    adminUserId = authResult.userId,
                    result = result.success and "SUCCESS" or "FAILED"
                }
            })
        end
        
        ao.send({
            Target = msg.From,
            Tags = {
                Action = "PROCESS_LIFECYCLE_RESPONSE",
                CorrelationId = msg.Tags.CorrelationId or "process-lifecycle"
            },
            Data = json.encode({
                success = result.success,
                operation = operation,
                correlationId = correlationId,
                operationResult = result,
                timestamp = 0
            })
        })
        
        print("[AdminDeploymentHandler] Lifecycle operation '" .. operation .. "' " .. 
              (result.success and "completed" or "failed"))
    end
)

-- Deployment coordination handler
Handlers.add(
    "deployment-coordination",
    Handlers.utils.hasMatchingTag("Action", "DEPLOYMENT_COORDINATION"),
    function(msg)
        -- Authenticate deployment coordination
        local authResult = ProcessAuthenticator.validateMessage(msg, "ADMIN")
        if not authResult.valid then
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "ERROR_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "deployment-coordination"
                },
                Data = json.encode({
                    success = false,
                    error = "Insufficient privileges for deployment coordination",
                    requiredLevel = "ADMIN"
                })
            })
            return
        end
        
        local deploymentData = json.decode(msg.Data)
        if not deploymentData then
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "ERROR_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "deployment-coordination"
                },
                Data = json.encode({
                    success = false,
                    error = "Deployment data is required"
                })
            })
            return
        end
        
        local deploymentPlan = deploymentData.deploymentPlan
        local coordinationMode = deploymentData.coordinationMode or "SEQUENTIAL"
        local rollbackOnFailure = deploymentData.rollbackOnFailure ~= false
        
        -- Coordinate deployment across processes
        local coordinationResult = MaintenanceCoordinator.coordinateDeployment({
            deploymentPlan = deploymentPlan,
            coordinationMode = coordinationMode,
            rollbackOnFailure = rollbackOnFailure,
            adminUserId = authResult.userId
        })
        
        ao.send({
            Target = msg.From,
            Tags = {
                Action = "DEPLOYMENT_COORDINATION_RESPONSE",
                CorrelationId = msg.Tags.CorrelationId or "deployment-coordination"
            },
            Data = json.encode({
                success = coordinationResult.success,
                deploymentStatus = coordinationResult.status,
                deploymentResults = coordinationResult.results,
                affectedProcesses = coordinationResult.affectedProcesses,
                rollbackAvailable = coordinationResult.rollbackAvailable,
                timestamp = msg.Timestamp,
                error = coordinationResult.error
            })
        })
        
        print("[AdminDeploymentHandler] Deployment coordination " .. 
              (coordinationResult.success and "completed" or "failed"))
    end
)

-- Rollback management handler
Handlers.add(
    "rollback-management",
    Handlers.utils.hasMatchingTag("Action", "ROLLBACK_MANAGEMENT"),
    function(msg)
        -- Authenticate rollback management
        local authResult = ProcessAuthenticator.validateMessage(msg, "ADMIN")
        if not authResult.valid then
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "ERROR_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "rollback-management"
                },
                Data = json.encode({
                    success = false,
                    error = "Insufficient privileges for rollback management",
                    requiredLevel = "ADMIN"
                })
            })
            return
        end
        
        local rollbackData = json.decode(msg.Data)
        if not rollbackData or not rollbackData.rollbackOperation then
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "ERROR_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "rollback-management"
                },
                Data = json.encode({
                    success = false,
                    error = "Rollback operation is required"
                })
            })
            return
        end
        
        local rollbackOperation = rollbackData.rollbackOperation
        local targetProcesses = rollbackData.targetProcesses
        local rollbackPoint = rollbackData.rollbackPoint
        local rollbackReason = rollbackData.reason or "Administrative rollback"
        
        -- Execute rollback operation
        local rollbackResult = MaintenanceCoordinator.executeRollback({
            operation = rollbackOperation,
            targetProcesses = targetProcesses,
            rollbackPoint = rollbackPoint,
            reason = rollbackReason,
            adminUserId = authResult.userId
        })
        
        -- Generate critical alert for rollback
        AlertManager.generateAlert({
            type = "SYSTEM_ROLLBACK",
            severity = "CRITICAL",
            message = "System rollback " .. (rollbackResult.success and "completed" or "failed"),
            details = {
                operation = rollbackOperation,
                targetProcesses = targetProcesses,
                rollbackPoint = rollbackPoint,
                reason = rollbackReason,
                adminUserId = authResult.userId
            }
        })
        
        ao.send({
            Target = msg.From,
            Tags = {
                Action = "ROLLBACK_MANAGEMENT_RESPONSE",
                CorrelationId = msg.Tags.CorrelationId or "rollback-management"
            },
            Data = json.encode({
                success = rollbackResult.success,
                rollbackStatus = rollbackResult.status,
                rollbackResults = rollbackResult.results,
                affectedProcesses = rollbackResult.affectedProcesses,
                stateRestoration = rollbackResult.stateRestoration,
                timestamp = msg.Timestamp,
                error = rollbackResult.error
            })
        })
        
        print("[AdminDeploymentHandler] Rollback management " .. 
              (rollbackResult.success and "completed" or "failed"))
    end
)

-- Graceful shutdown coordination handler
Handlers.add(
    "graceful-shutdown",
    Handlers.utils.hasMatchingTag("Action", "GRACEFUL_SHUTDOWN"),
    function(msg)
        -- Authenticate shutdown coordination
        local authResult = ProcessAuthenticator.validateMessage(msg, "ADMIN")
        if not authResult.valid then
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "ERROR_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "graceful-shutdown"
                },
                Data = json.encode({
                    success = false,
                    error = "Insufficient privileges for graceful shutdown",
                    requiredLevel = "ADMIN"
                })
            })
            return
        end
        
        local shutdownData = json.decode(msg.Data)
        local targetProcesses = shutdownData and shutdownData.targetProcesses or {}
        local shutdownOrder = shutdownData and shutdownData.shutdownOrder or "DEPENDENCY_AWARE"
        local gracePeriod = shutdownData and shutdownData.gracePeriodSeconds or 30
        local statePreservation = shutdownData and shutdownData.statePreservation ~= false
        
        -- Coordinate graceful shutdown
        local shutdownResult = MaintenanceCoordinator.coordinateGracefulShutdown({
            targetProcesses = targetProcesses,
            shutdownOrder = shutdownOrder,
            gracePeriodSeconds = gracePeriod,
            statePreservation = statePreservation,
            adminUserId = authResult.userId
        })
        
        ao.send({
            Target = msg.From,
            Tags = {
                Action = "GRACEFUL_SHUTDOWN_RESPONSE",
                CorrelationId = msg.Tags.CorrelationId or "graceful-shutdown"
            },
            Data = json.encode({
                success = shutdownResult.success,
                shutdownStatus = shutdownResult.status,
                shutdownResults = shutdownResult.results,
                shutdownOrder = shutdownResult.executionOrder,
                statePreserved = shutdownResult.statePreserved,
                timestamp = msg.Timestamp,
                error = shutdownResult.error
            })
        })
        
        print("[AdminDeploymentHandler] Graceful shutdown coordination " .. 
              (shutdownResult.success and "completed" or "failed"))
    end
)

-- Deployment status query handler
Handlers.add(
    "deployment-status",
    Handlers.utils.hasMatchingTag("Action", "DEPLOYMENT_STATUS"),
    function(msg)
        -- Authenticate status query
        local authResult = ProcessAuthenticator.validateMessage(msg, "ELEVATED")
        if not authResult.valid then
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "ERROR_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "deployment-status"
                },
                Data = json.encode({
                    success = false,
                    error = "Insufficient privileges for deployment status",
                    requiredLevel = "ELEVATED"
                })
            })
            return
        end
        
        local statusData = json.decode(msg.Data)
        local deploymentId = statusData and statusData.deploymentId
        
        local deploymentStatus = {}
        
        if deploymentId then
            -- Get specific deployment status
            deploymentStatus = MaintenanceCoordinator.getDeploymentStatus(deploymentId)
        else
            -- Get all deployment statuses
            deploymentStatus = {
                activeDeployments = MaintenanceCoordinator.getActiveDeployments(),
                recentDeployments = MaintenanceCoordinator.getRecentDeployments(10),
                systemDeploymentHealth = MaintenanceCoordinator.getSystemDeploymentHealth()
            }
        end
        
        ao.send({
            Target = msg.From,
            Tags = {
                Action = "DEPLOYMENT_STATUS_RESPONSE",
                CorrelationId = msg.Tags.CorrelationId or "deployment-status"
            },
            Data = json.encode({
                success = true,
                deploymentStatus = deploymentStatus,
                timestamp = 0
            })
        })
        
        print("[AdminDeploymentHandler] Deployment status query processed")
    end
)


-- ===== END MODULE: admin.handlers.admin-deployment-handler =====


-- ===== MODULE: admin.handlers.admin-logging-handler =====
-- File: ao-processes/admin/handlers/admin-logging-handler.lua
-- Original require: require("admin.handlers.admin-logging-handler")

-- Admin Logging Handler
-- Handles log aggregation, correlation, and analysis across distributed processes


-- ===== MODULE: game-logic.process-coordination.message-correlator =====
-- File: ao-processes/game-logic/process-coordination/message-correlator.lua
-- Original require: local MessageCorrelator = require("game-logic.process-coordination.message-correlator")


-- ===== END MODULE: game-logic.process-coordination.message-correlator =====


-- ===== MODULE: game-logic.process-coordination.process-authenticator =====
-- File: ao-processes/game-logic/process-coordination/process-authenticator.lua
-- Original require: local ProcessAuthenticator = require("game-logic.process-coordination.process-authenticator")


-- ===== END MODULE: game-logic.process-coordination.process-authenticator =====


-- ===== MODULE: admin.components.log-aggregator =====
-- File: ao-processes/admin/components/log-aggregator.lua
-- Original require: local LogAggregator = require("admin.components.log-aggregator")


-- ===== END MODULE: admin.components.log-aggregator =====


-- ===== MODULE: admin.components.alert-manager =====
-- File: ao-processes/admin/components/alert-manager.lua
-- Original require: local AlertManager = require("admin.components.alert-manager")


-- ===== END MODULE: admin.components.alert-manager =====


-- Log aggregation query handler
Handlers.add(
    "log-aggregation",
    Handlers.utils.hasMatchingTag("Action", "LOG_AGGREGATION"),
    function(msg)
        -- Authenticate log aggregation request
        local authResult = ProcessAuthenticator.validateMessage(msg, "ELEVATED")
        if not authResult.valid then
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "ERROR_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "log-aggregation"
                },
                Data = json.encode({
                    success = false,
                    error = "Insufficient privileges for log aggregation",
                    requiredLevel = "ELEVATED"
                })
            })
            return
        end
        
        local queryData = json.decode(msg.Data)
        local queryType = queryData and queryData.queryType or "RECENT_LOGS"
        local timeRange = queryData and queryData.timeRange
        local logLevel = queryData and queryData.logLevel
        local component = queryData and queryData.component
        local processId = queryData and queryData.processId
        local correlationId = queryData and queryData.correlationId
        local limit = queryData and queryData.limit or 100
        
        local logResults = {}
        
        if queryType == "RECENT_LOGS" then
            logResults = LogAggregator.getRecentLogs(limit, {
                timeRange = timeRange,
                logLevel = logLevel,
                component = component,
                processId = processId
            })
        elseif queryType == "CORRELATED_LOGS" then
            if not correlationId then
                ao.send({
                    Target = msg.From,
                    Tags = {
                        Action = "ERROR_RESPONSE",
                        CorrelationId = msg.Tags.CorrelationId or "log-aggregation"
                    },
                    Data = json.encode({
                        success = false,
                        error = "Correlation ID is required for correlated logs query"
                    })
                })
                return
            end
            logResults = LogAggregator.getCorrelatedLogs(correlationId, {
                timeRange = timeRange,
                includeChildren = queryData.includeChildren
            })
        elseif queryType == "ERROR_LOGS" then
            logResults = LogAggregator.getErrorLogs(limit, {
                timeRange = timeRange,
                component = component,
                processId = processId
            })
        elseif queryType == "SEARCH_LOGS" then
            local searchQuery = queryData.searchQuery
            if not searchQuery then
                ao.send({
                    Target = msg.From,
                    Tags = {
                        Action = "ERROR_RESPONSE",
                        CorrelationId = msg.Tags.CorrelationId or "log-aggregation"
                    },
                    Data = json.encode({
                        success = false,
                        error = "Search query is required for log search"
                    })
                })
                return
            end
            logResults = LogAggregator.searchLogs(searchQuery, {
                timeRange = timeRange,
                limit = limit,
                caseSensitive = queryData.caseSensitive
            })
        else
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "ERROR_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "log-aggregation"
                },
                Data = json.encode({
                    success = false,
                    error = "Unsupported query type: " .. queryType
                })
            })
            return
        end
        
        ao.send({
            Target = msg.From,
            Tags = {
                Action = "LOG_AGGREGATION_RESPONSE",
                CorrelationId = msg.Tags.CorrelationId or "log-aggregation"
            },
            Data = json.encode({
                success = true,
                queryType = queryType,
                logResults = logResults,
                totalResults = #logResults,
                aggregationSummary = LogAggregator.getAggregationSummary(),
                timestamp = 0
            })
        })
        
        print("[AdminLoggingHandler] Log aggregation query processed: " .. queryType)
    end
)

-- Log streaming handler
Handlers.add(
    "log-streaming",
    Handlers.utils.hasMatchingTag("Action", "LOG_STREAMING"),
    function(msg)
        -- Authenticate log streaming request
        local authResult = ProcessAuthenticator.validateMessage(msg, "ELEVATED")
        if not authResult.valid then
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "ERROR_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "log-streaming"
                },
                Data = json.encode({
                    success = false,
                    error = "Insufficient privileges for log streaming",
                    requiredLevel = "ELEVATED"
                })
            })
            return
        end
        
        local streamData = json.decode(msg.Data)
        local operation = streamData and streamData.operation or "SUBSCRIBE"
        
        if operation == "SUBSCRIBE" then
            local streamConfig = {
                subscriberId = msg.From,
                logLevel = streamData.logLevel,
                component = streamData.component,
                processId = streamData.processId,
                includeCorrelation = streamData.includeCorrelation,
                bufferSize = streamData.bufferSize or 50
            }
            
            local subscriptionResult = LogAggregator.subscribeToLogStream(streamConfig)
            
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "LOG_STREAMING_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "log-streaming"
                },
                Data = json.encode({
                    success = subscriptionResult.success,
                    operation = "SUBSCRIBE",
                    subscriptionId = subscriptionResult.subscriptionId,
                    streamConfig = streamConfig,
                    timestamp = 0
                })
            })
            
        elseif operation == "UNSUBSCRIBE" then
            local unsubscribeResult = LogAggregator.unsubscribeFromLogStream(msg.From)
            
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "LOG_STREAMING_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "log-streaming"
                },
                Data = json.encode({
                    success = unsubscribeResult.success,
                    operation = "UNSUBSCRIBE",
                    timestamp = 0
                })
            })
            
        elseif operation == "STATUS" then
            local streamStatus = LogAggregator.getStreamStatus(msg.From)
            
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "LOG_STREAMING_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "log-streaming"
                },
                Data = json.encode({
                    success = true,
                    operation = "STATUS",
                    streamStatus = streamStatus,
                    timestamp = 0
                })
            })
        else
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "ERROR_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "log-streaming"
                },
                Data = json.encode({
                    success = false,
                    error = "Unsupported streaming operation: " .. operation
                })
            })
        end
        
        print("[AdminLoggingHandler] Log streaming operation processed: " .. operation)
    end
)

-- Log analysis handler
Handlers.add(
    "log-analysis",
    Handlers.utils.hasMatchingTag("Action", "LOG_ANALYSIS"),
    function(msg)
        -- Authenticate log analysis request
        local authResult = ProcessAuthenticator.validateMessage(msg, "ELEVATED")
        if not authResult.valid then
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "ERROR_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "log-analysis"
                },
                Data = json.encode({
                    success = false,
                    error = "Insufficient privileges for log analysis",
                    requiredLevel = "ELEVATED"
                })
            })
            return
        end
        
        local analysisData = json.decode(msg.Data)
        local analysisType = analysisData and analysisData.analysisType or "TREND_ANALYSIS"
        local timeRange = analysisData and analysisData.timeRange
        local processId = analysisData and analysisData.processId
        
        local analysisResults = {}
        
        if analysisType == "TREND_ANALYSIS" then
            analysisResults = LogAggregator.performTrendAnalysis({
                timeRange = timeRange,
                processId = processId,
                metricTypes = analysisData.metricTypes
            })
        elseif analysisType == "ERROR_ANALYSIS" then
            analysisResults = LogAggregator.performErrorAnalysis({
                timeRange = timeRange,
                processId = processId,
                groupByError = analysisData.groupByError,
                includeStackTraces = analysisData.includeStackTraces
            })
        elseif analysisType == "PERFORMANCE_ANALYSIS" then
            analysisResults = LogAggregator.performPerformanceAnalysis({
                timeRange = timeRange,
                processId = processId,
                analysisMetrics = analysisData.analysisMetrics
            })
        elseif analysisType == "CORRELATION_ANALYSIS" then
            local correlationId = analysisData.correlationId
            if not correlationId then
                ao.send({
                    Target = msg.From,
                    Tags = {
                        Action = "ERROR_RESPONSE",
                        CorrelationId = msg.Tags.CorrelationId or "log-analysis"
                    },
                    Data = json.encode({
                        success = false,
                        error = "Correlation ID is required for correlation analysis"
                    })
                })
                return
            end
            analysisResults = LogAggregator.performCorrelationAnalysis({
                correlationId = correlationId,
                timeRange = timeRange,
                includeMetrics = analysisData.includeMetrics
            })
        else
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "ERROR_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "log-analysis"
                },
                Data = json.encode({
                    success = false,
                    error = "Unsupported analysis type: " .. analysisType
                })
            })
            return
        end
        
        ao.send({
            Target = msg.From,
            Tags = {
                Action = "LOG_ANALYSIS_RESPONSE",
                CorrelationId = msg.Tags.CorrelationId or "log-analysis"
            },
            Data = json.encode({
                success = true,
                analysisType = analysisType,
                analysisResults = analysisResults,
                analysisMetadata = {
                    timeRange = timeRange,
                    processId = processId,
                    generatedAt = 0
                },
                timestamp = 0
            })
        })
        
        print("[AdminLoggingHandler] Log analysis completed: " .. analysisType)
    end
)

-- Log configuration handler
Handlers.add(
    "log-configuration",
    Handlers.utils.hasMatchingTag("Action", "LOG_CONFIGURATION"),
    function(msg)
        -- Authenticate log configuration request
        local authResult = ProcessAuthenticator.validateMessage(msg, "ADMIN")
        if not authResult.valid then
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "ERROR_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "log-configuration"
                },
                Data = json.encode({
                    success = false,
                    error = "Insufficient privileges for log configuration",
                    requiredLevel = "ADMIN"
                })
            })
            return
        end
        
        local configData = json.decode(msg.Data)
        if not configData then
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "ERROR_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "log-configuration"
                },
                Data = json.encode({
                    success = false,
                    error = "Configuration data is required"
                })
            })
            return
        end
        
        local configResult = {}
        
        if configData.retentionPolicy then
            configResult.retentionUpdate = LogAggregator.updateRetentionPolicy(configData.retentionPolicy)
        end
        
        if configData.aggregationSettings then
            configResult.aggregationUpdate = LogAggregator.updateAggregationSettings(configData.aggregationSettings)
        end
        
        if configData.correlationSettings then
            configResult.correlationUpdate = LogAggregator.updateCorrelationSettings(configData.correlationSettings)
        end
        
        if configData.alertRules then
            configResult.alertRulesUpdate = LogAggregator.updateLogAlertRules(configData.alertRules)
        end
        
        -- Log the configuration change
        LogAggregator.logEvent({
            level = "INFO",
            component = "LogConfiguration",
            message = "Log aggregation configuration updated",
            adminUserId = authResult.userId,
            configChanges = configData
        })
        
        ao.send({
            Target = msg.From,
            Tags = {
                Action = "LOG_CONFIGURATION_RESPONSE",
                CorrelationId = msg.Tags.CorrelationId or "log-configuration"
            },
            Data = json.encode({
                success = true,
                configurationResults = configResult,
                timestamp = 0
            })
        })
        
        print("[AdminLoggingHandler] Log configuration updated by " .. (authResult.userId or "unknown"))
    end
)

-- Log export handler
Handlers.add(
    "log-export",
    Handlers.utils.hasMatchingTag("Action", "LOG_EXPORT"),
    function(msg)
        -- Authenticate log export request
        local authResult = ProcessAuthenticator.validateMessage(msg, "ADMIN")
        if not authResult.valid then
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "ERROR_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "log-export"
                },
                Data = json.encode({
                    success = false,
                    error = "Insufficient privileges for log export",
                    requiredLevel = "ADMIN"
                })
            })
            return
        end
        
        local exportData = json.decode(msg.Data)
        if not exportData then
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "ERROR_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "log-export"
                },
                Data = json.encode({
                    success = false,
                    error = "Export parameters are required"
                })
            })
            return
        end
        
        local exportFormat = exportData.format or "JSON"
        local timeRange = exportData.timeRange
        local filters = exportData.filters or {}
        local compressionEnabled = exportData.compression ~= false
        
        -- Execute log export
        local exportResult = LogAggregator.exportLogs({
            format = exportFormat,
            timeRange = timeRange,
            filters = filters,
            compression = compressionEnabled,
            includeMetadata = exportData.includeMetadata,
            adminUserId = authResult.userId
        })
        
        -- Generate alert for log export
        AlertManager.generateAlert({
            type = "LOG_EXPORT",
            severity = "INFO",
            message = "Log export " .. (exportResult.success and "completed" or "failed"),
            details = {
                format = exportFormat,
                timeRange = timeRange,
                recordCount = exportResult.recordCount,
                adminUserId = authResult.userId
            }
        })
        
        ao.send({
            Target = msg.From,
            Tags = {
                Action = "LOG_EXPORT_RESPONSE",
                CorrelationId = msg.Tags.CorrelationId or "log-export"
            },
            Data = json.encode({
                success = exportResult.success,
                exportFormat = exportFormat,
                exportResults = exportResult,
                timestamp = msg.Timestamp,
                error = exportResult.error
            })
        })
        
        print("[AdminLoggingHandler] Log export " .. (exportResult.success and "completed" or "failed") .. 
              " - Format: " .. exportFormat)
    end
)

-- Log statistics handler
Handlers.add(
    "log-statistics",
    Handlers.utils.hasMatchingTag("Action", "LOG_STATISTICS"),
    function(msg)
        -- Authenticate log statistics request
        local authResult = ProcessAuthenticator.validateMessage(msg, "ELEVATED")
        if not authResult.valid then
            ao.send({
                Target = msg.From,
                Tags = {
                    Action = "ERROR_RESPONSE",
                    CorrelationId = msg.Tags.CorrelationId or "log-statistics"
                },
                Data = json.encode({
                    success = false,
                    error = "Insufficient privileges for log statistics",
                    requiredLevel = "ELEVATED"
                })
            })
            return
        end
        
        local statistics = {
            aggregationStatistics = LogAggregator.getAggregationStatistics(),
            volumeStatistics = LogAggregator.getVolumeStatistics(),
            errorStatistics = LogAggregator.getErrorStatistics(),
            correlationStatistics = LogAggregator.getCorrelationStatistics(),
            streamingStatistics = LogAggregator.getStreamingStatistics(),
            retentionStatistics = LogAggregator.getRetentionStatistics()
        }
        
        ao.send({
            Target = msg.From,
            Tags = {
                Action = "LOG_STATISTICS_RESPONSE",
                CorrelationId = msg.Tags.CorrelationId or "log-statistics"
            },
            Data = json.encode({
                success = true,
                statistics = statistics,
                timestamp = 0
            })
        })
        
        print("[AdminLoggingHandler] Log statistics provided to " .. msg.From)
    end
)


-- ===== END MODULE: admin.handlers.admin-logging-handler =====


-- Initialize process on load
initialize()

